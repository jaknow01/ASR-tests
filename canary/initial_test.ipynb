{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5de4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When runing on server and GPUs are clogged\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ad4019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnowakowski/ASR-tests/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2026-01-08 11:12:08 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.\n",
      "OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.\n",
      "No exporters were provided. This means that no telemetry data will be collected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 11:12:15 nemo_logging:393] Tokenizer CanaryBPETokenizer initialized with 16384 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:12:15 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    skip_missing_manifest_entries: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    prompt_format: canary2\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.01\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: true\n",
      "    max_tps: null\n",
      "    bucket_duration_bins: null\n",
      "    bucket_batch_size: null\n",
      "    num_buckets: null\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2026-01-08 11:12:15 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    prompt_format: canary2\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: true\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 11:12:15 nemo_logging:393] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting class at nemo.collections.asr.modules.transformer.get_nemo_transformer: Located non-class of type 'function' while loading 'nemo.collections.asr.modules.transformer.get_nemo_transformer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 11:12:31 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 16384 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:12:35 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    skip_missing_manifest_entries: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    text_field: answer\n",
      "    batch_duration: null\n",
      "    max_tps: null\n",
      "    use_bucketing: true\n",
      "    bucket_duration_bins: null\n",
      "    bucket_batch_size: null\n",
      "    num_buckets: null\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2026-01-08 11:12:35 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 11:12:35 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2026-01-08 11:12:50 nemo_logging:393] Model EncDecCTCModelBPE was successfully restored from /home/jnowakowski/.cache/huggingface/hub/models--nvidia--canary-1b-v2/snapshots/87bc52657add533cd0156b3fc1aef027280754bf/canary-1b-v2.nemo.\n",
      "[NeMo I 2026-01-08 11:12:54 nemo_logging:393] Model EncDecMultiTaskModel was successfully restored from /home/jnowakowski/.cache/huggingface/hub/models--nvidia--canary-1b-v2/snapshots/87bc52657add533cd0156b3fc1aef027280754bf/canary-1b-v2.nemo.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.models import ASRModel\n",
    "asr_ast_model = ASRModel.from_pretrained(model_name=\"nvidia/canary-1b-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba7d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:   nemo v1.0.1\n",
      "Cache: /home/jnowakowski/audb/nemo/1.0.1/d3b62a9b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "import audb\n",
    "db = audb.load(\"nemo\", version=\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d6695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: nemo\n",
      "description: 'NEMO is a polish dataset with emotional speech. It contains over 3 hours\n",
      "  of emotional speech in 6 categories: anger, fear, happiness, sadness, surprise and\n",
      "  neutral. The audios were created by nine speakers.'\n",
      "source: https://aclanthology.org/2024.lrec-main.1059\n",
      "usage: research\n",
      "languages: [pol]\n",
      "author: Christop, Iwona\n",
      "license: CC-BY-NC-SA-4.0\n",
      "license_url: https://creativecommons.org/licenses/by-nc-sa/4.0/\n",
      "schemes:\n",
      "  age: {dtype: int}\n",
      "  emotion:\n",
      "    dtype: str\n",
      "    labels: [anger, sadness, surprise, happiness, fear, neutral]\n",
      "  gender:\n",
      "    dtype: str\n",
      "    labels: [male, female]\n",
      "  normalized_text:\n",
      "    dtype: str\n",
      "    labels: [ucho wykrywa dźwięki o różnej częstotliwości, interesuje mnie historia\n",
      "        polski, człowiek zaczyna umierać już w momencie narodzin, kupiłem nową szafę\n",
      "        do sypialni, mleko jest źródłem wapnia i innych składników odżywczych, „ród\n",
      "        smoka” to serial telewizyjny, strzelec to znak zodiaku następujący po skorpionie,\n",
      "      myślmy pozytywnie i skupmy się na dobrych rzeczach w naszym życiu, otrzymałem\n",
      "        piękną pocztówkę z widokiem na góry, nie waśńmy się ze sobą, aby upiec ciasto\n",
      "        muszę kupić mączkę, egipcjanie uważali ibisy za święte, postanowiłem wynająć\n",
      "        samochód na wakacje, w wolnym czasie lubię czytać książki, moja ciocia jest\n",
      "        bardzo pomocna, ten pomysł trąci brakiem realizmu, woda w basenie jest bardzo\n",
      "        ciepła, gorzka czekolada jest idealna na deser, dokarmcie koty wychodząc z\n",
      "        domu, piesek wszedł do rzeki żeby popływać, relaksujące piosnki poprawiają\n",
      "        nastrój, jedz inaczej aby polepszyć swoje zdrowie, na złamaną kończynę często\n",
      "        zakłada się gips, żołwica to dawne określenie na siostrę męża, niania odegrała\n",
      "        w moim życiu ważną rolę, ten miesiąc minął bardzo szybko, do dzisiejszego\n",
      "        obiadu potrzebuje małego garnczka, dziunia nie jesteś moim szefem, lubię czytać\n",
      "        przed snem, piłka nożna to moja pasja, woda jest podstawowym składnikiem życia\n",
      "        na ziemi, podczas medytacji można wejść w trans, twoje słowo ma dla mnie wielkie\n",
      "        znaczenie, podczas remontu odkryliśmy starodawny mur, dopełniacz jest jednym\n",
      "        z przypadków gramatycznych w języku polskim, nie zachowuj się jak żigolak,\n",
      "      w bankach można założyć konto osobiste oszczędnościowe lub kredytowe, baza wojskowa\n",
      "        jest strategicznym punktem dla armii, miłość jest jednym z najpiękniejszych\n",
      "        uczuć, chcę przeczytać ten artykuł jeszcze raz, kupiłem nowy słownik języka\n",
      "        hiszpańskiego, sziwa oznacza żałobę po zmarłym, tęsknota to uczucie które\n",
      "        każdy z nas zna, zawsze stawiam przed rzeczownikami właściwy rodzajnik, rtęć\n",
      "        jest jednym z pierwiastków chemicznych, w muzeum można zobaczyć szkielet dinozaura,\n",
      "      bastion był kiedyś ważnym elementem obrony miasta, po operacji nie mam żadnych\n",
      "        blizn, moim ulubionym sosem do pizzy jest sos czosnkowy, czerwiec kojarzy\n",
      "        się z zakończeniem roku szkolnego, w niedzielę szkoła jest zamknięta, dzieci\n",
      "        muszą dużo jeść, miasto tętni życiem nawet w nocy, na targach rzemieślniczych\n",
      "        można zobaczyć wiele unikatowych produktów, mój teść zawsze służy radą, przez\n",
      "        most na rzece można szybko dotrzeć do miasta, każdy taniec ma swój własny\n",
      "        rytm, kwiecień to czwarty miesiąc w roku, zima to czas jeżdżenia na sankach,\n",
      "      w parku rośnie ogromne drzewo, chodźmy w tango, chodzę do szkoły prawie codziennie,\n",
      "      pan janek jest naszym nowym sąsiadem, zupa pomidorowa to moje ulubione danie,\n",
      "      w grudniu często pada śnieg, w dzieciństwie uwielbiałem klechdy, moja teściowa\n",
      "        czasem przyjeżdża do nas w weekend, kontrświadczenie za udzieloną pożyczkę\n",
      "        było bardzo wysokie, jabłko jest bogatym źródłem witamin i składników odżywczych,\n",
      "      marzec kojarzy się z wiosennymi promieniami słońca, zamek w malborku jest jednym\n",
      "        z najpiękniejszych w polsce, moje dziecko umie już mówić kilka słów, niektórzy\n",
      "        powiedzą że to państwo z kartonu, przyjaciel to ktoś kto zawsze jest po mojej\n",
      "        stronie, moja wizja na przyszłość jest jasna i wyraźna, chorał gregoriański\n",
      "        jest wykonywany podczas uroczystych nabożeństw, ten źrebak jest wychowany\n",
      "        zgodnie z najlepszymi standardami, król był bardzo sprawiedliwym człowiekiem,\n",
      "      racja ten pomysł jest najlepszy, w lipcu wyjeżdżam z rodziną na wakacje nad\n",
      "        morze, kitel to strój który noszą lekarze, sporadycznie chodzę na siłownię,\n",
      "      moja dziewczyna świętuje urodziny w sobotę, przestań go judzić, ta liczba wydaje\n",
      "        się być błędna sprawdź jeszcze raz, w październiku zaczyna się jesień, podczas\n",
      "        wakacji udało mi się zobaczyć delfiny, ten dżin potrafi spełniać życzenia,\n",
      "      pamiętaj że nadzieja umiera ostatnia, życie jest pełne niespodzianek]\n",
      "  raw_text:\n",
      "    dtype: str\n",
      "    labels: [Ucho wykrywa dźwięki o różnej częstotliwości., Interesuje mnie historia\n",
      "        Polski., Człowiek zaczyna umierać już w momencie narodzin., Kupiłem nową szafę\n",
      "        do sypialni., Mleko jest źródłem wapnia i innych składników odżywczych., „Ród\n",
      "        smoka” to serial telewizyjny., Strzelec to znak zodiaku następujący po Skorpionie.,\n",
      "      Myślmy pozytywnie i skupmy się na dobrych rzeczach w naszym życiu., Otrzymałem\n",
      "        piękną pocztówkę z widokiem na góry., Nie waśńmy się ze sobą., 'Aby upiec\n",
      "        ciasto, muszę kupić mączkę.', Egipcjanie uważali ibisy za święte., Postanowiłem\n",
      "        wynająć samochód na wakacje., W wolnym czasie lubię czytać książki., Moja\n",
      "        ciocia jest bardzo pomocna., Ten pomysł trąci brakiem realizmu., Woda w basenie\n",
      "        jest bardzo ciepła., Gorzka czekolada jest idealna na deser., Dokarmcie koty\n",
      "        wychodząc z domu., Piesek wszedł do rzeki żeby popływać., Relaksujące piosnki\n",
      "        poprawiają nastrój., Jedz inaczej aby polepszyć swoje zdrowie., Na złamaną\n",
      "        kończynę często zakłada się gips., „Żołwica” to dawne określenie na siostrę\n",
      "        męża., Niania odegrała w moim życiu ważną rolę., Ten miesiąc minął bardzo\n",
      "        szybko., Do dzisiejszego obiadu potrzebuje małego garnczka., 'Dziunia, nie\n",
      "        jesteś moim szefem.', Lubię czytać przed snem., Piłka nożna to moja pasja.,\n",
      "      Woda jest podstawowym składnikiem życia na Ziemi., Podczas medytacji można wejść\n",
      "        w trans., Twoje słowo ma dla mnie wielkie znaczenie., Podczas remontu odkryliśmy\n",
      "        starodawny mur., Dopełniacz jest jednym z przypadków gramatycznych w języku\n",
      "        polskim., Nie zachowuj się jak żigolak., 'W bankach można założyć konto osobiste,\n",
      "        oszczędnościowe lub kredytowe.', Baza wojskowa jest strategicznym punktem\n",
      "        dla armii., Miłość jest jednym z najpiękniejszych uczuć., Chcę przeczytać\n",
      "        ten artykuł jeszcze raz., Kupiłem nowy słownik języka hiszpańskiego., Sziwa\n",
      "        oznacza żałobę po zmarłym., 'Tęsknota to uczucie, które każdy z nas zna.',\n",
      "      Zawsze stawiam przed rzeczownikami właściwy rodzajnik., Rtęć jest jednym z pierwiastków\n",
      "        chemicznych., W muzeum można zobaczyć szkielet dinozaura., Bastion był kiedyś\n",
      "        ważnym elementem obrony miasta., Po operacji nie mam żadnych blizn., Moim\n",
      "        ulubionym sosem do pizzy jest sos czosnkowy., Czerwiec kojarzy się z zakończeniem\n",
      "        roku szkolnego., W niedzielę szkoła jest zamknięta., Dzieci muszą dużo jeść.,\n",
      "      'Miasto tętni życiem, nawet w nocy.', Na targach rzemieślniczych można zobaczyć\n",
      "        wiele unikatowych produktów., Mój teść zawsze służy radą., Przez most na rzece\n",
      "        można szybko dotrzeć do miasta., Każdy taniec ma swój własny rytm., Kwiecień\n",
      "        to czwarty miesiąc w roku., Zima to czas jeżdżenia na sankach., W parku rośnie\n",
      "        ogromne drzewo., Chodźmy w tango., Chodzę do szkoły prawie codziennie., Pan\n",
      "        Janek jest naszym nowym sąsiadem., Zupa pomidorowa to moje ulubione danie.,\n",
      "      W grudniu często pada śnieg., W dzieciństwie uwielbiałem klechdy., Moja teściowa\n",
      "        czasem przyjeżdża do nas w weekend., Kontrświadczenie za udzieloną pożyczkę\n",
      "        było bardzo wysokie., Jabłko jest bogatym źródłem witamin i składników odżywczych.,\n",
      "      Marzec kojarzy się z wiosennymi promieniami słońca., Zamek w Malborku jest jednym\n",
      "        z najpiękniejszych w Polsce., Moje dziecko umie już mówić kilka słów., 'Niektórzy\n",
      "        powiedzą, że to państwo z kartonu.', 'Przyjaciel to ktoś, kto zawsze jest\n",
      "        po mojej stronie.', Moja wizja na przyszłość jest jasna i wyraźna., Chorał\n",
      "        gregoriański jest wykonywany podczas uroczystych nabożeństw., Ten źrebak jest\n",
      "        wychowany zgodnie z najlepszymi standardami., Król był bardzo sprawiedliwym\n",
      "        człowiekiem., 'Racja, ten pomysł jest najlepszy.', W lipcu wyjeżdżam z rodziną\n",
      "        na wakacje nad morze., 'Kitel to strój, który noszą lekarze.', Sporadycznie\n",
      "        chodzę na siłownię., Moja dziewczyna świętuje urodziny w sobotę., Przestań\n",
      "        go judzić., 'Ta liczba wydaje się być błędna, sprawdź jeszcze raz.', W październiku\n",
      "        zaczyna się jesień., Podczas wakacji udało mi się zobaczyć delfiny., Ten dżin\n",
      "        potrafi spełniać życzenia., 'Pamiętaj, że nadzieja umiera ostatnia.', Życie\n",
      "        jest pełne niespodzianek.]\n",
      "  sentence: {dtype: int, labels: sentence}\n",
      "  speaker: {dtype: object, labels: speaker}\n",
      "tables:\n",
      "  emotion.categories.test.gold_standard:\n",
      "    type: filewise\n",
      "    columns:\n",
      "      emotion: {scheme_id: emotion}\n",
      "  files:\n",
      "    type: filewise\n",
      "    columns:\n",
      "      speaker: {scheme_id: speaker}\n",
      "      sentence: {scheme_id: sentence}\n",
      "misc_tables:\n",
      "  sentence:\n",
      "    levels: {sentence: int}\n",
      "    columns:\n",
      "      raw_text: {scheme_id: raw_text}\n",
      "      normalized_text: {scheme_id: normalized_text}\n",
      "  speaker:\n",
      "    levels: {speaker: object}\n",
      "    columns:\n",
      "      gender: {scheme_id: gender}\n",
      "      age: {scheme_id: age}\n",
      "audb:\n",
      "  root: /home/jnowakowski/audb/nemo/1.0.1/d3b62a9b\n",
      "  version: 1.0.1\n",
      "  flavor: {bit_depth: null, channels: null, format: null, mixdown: false, sampling_rate: null}\n",
      "  complete: true\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4aca11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jnowakowski/audb/nemo/1.0.1/d3b62a9b\n",
      "Liczba plików WAV: 4481\n",
      "[PosixPath('/home/jnowakowski/audb/nemo/1.0.1/d3b62a9b/audios/IC0_neutral_23.wav'), PosixPath('/home/jnowakowski/audb/nemo/1.0.1/d3b62a9b/audios/IC0_sadness_20.wav'), PosixPath('/home/jnowakowski/audb/nemo/1.0.1/d3b62a9b/audios/EB0_anger_57.wav'), PosixPath('/home/jnowakowski/audb/nemo/1.0.1/d3b62a9b/audios/TP0_sadness_52.wav'), PosixPath('/home/jnowakowski/audb/nemo/1.0.1/d3b62a9b/audios/KD0_surprised_82.wav')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root = Path(db.root)\n",
    "\n",
    "# pliki audio zwykle są w katalogu 'audio' lub 'files'\n",
    "audio_files = list(root.rglob(\"*.wav\"))  # znajdź wszystkie WAV\n",
    "\n",
    "print(root)\n",
    "\n",
    "print(f\"Liczba plików WAV: {len(audio_files)}\")\n",
    "print(audio_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f740809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:28:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:28:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:02,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warszawa, jako niekwestionowany i wieloaspektowo rozwinięty ośrodek, który od stuleci pełni rolę zarówno głównego centrum naukowego z licznymi instytucjami badawczymi, jak i bogatego w dziedzictwo kulturowe miasta tętniącego wydarzeniami artystycznymi, politycznie wpływowego poprzez siedziby kluczowych organów państwowych, a równocześnie znaczącego ekonomicznie dzięki skupieniu przedsiębiorstw i rynków kapitałowych, jawi się jako metropolia o wyjątkowej złożoności funkcjonalnej i społecznej.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = asr_ast_model.transcribe(['../sample_audio.wav'], source_lang='pl', target_lang='pl')\n",
    "print(output[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b20422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                   raw_text  \\\n",
      "sentence                                                      \n",
      "64            Ucho wykrywa dźwięki o różnej częstotliwości.   \n",
      "13                         Interesuje mnie historia Polski.   \n",
      "70        Człowiek zaczyna umierać już w momencie narodzin.   \n",
      "10                          Kupiłem nową szafę do sypialni.   \n",
      "79        Mleko jest źródłem wapnia i innych składników ...   \n",
      "...                                                     ...   \n",
      "29                       W październiku zaczyna się jesień.   \n",
      "60           Podczas wakacji udało mi się zobaczyć delfiny.   \n",
      "26                      Ten dżin potrafi spełniać życzenia.   \n",
      "32                   Pamiętaj, że nadzieja umiera ostatnia.   \n",
      "7                           Życie jest pełne niespodzianek.   \n",
      "\n",
      "                                            normalized_text  \n",
      "sentence                                                     \n",
      "64             ucho wykrywa dźwięki o różnej częstotliwości  \n",
      "13                          interesuje mnie historia polski  \n",
      "70         człowiek zaczyna umierać już w momencie narodzin  \n",
      "10                           kupiłem nową szafę do sypialni  \n",
      "79        mleko jest źródłem wapnia i innych składników ...  \n",
      "...                                                     ...  \n",
      "29                        w październiku zaczyna się jesień  \n",
      "60            podczas wakacji udało mi się zobaczyć delfiny  \n",
      "26                       ten dżin potrafi spełniać życzenia  \n",
      "32                     pamiętaj że nadzieja umiera ostatnia  \n",
      "7                            życie jest pełne niespodzianek  \n",
      "\n",
      "[90 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = f\"{root}/db.sentence.pkl\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:  # rb = read binary\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "print(type(obj))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb05e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{root}/audios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5842eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 4481 plików WAV\n",
      "[1/4481] Przetwarzanie: EB0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/4481] Przetwarzanie: EB0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/4481] Przetwarzanie: EB0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/4481] Przetwarzanie: EB0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/4481] Przetwarzanie: EB0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/4481] Przetwarzanie: EB0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.15it/s]\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/4481] Przetwarzanie: EB0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.17it/s]\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/4481] Przetwarzanie: EB0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/4481] Przetwarzanie: EB0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/4481] Przetwarzanie: EB0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/4481] Przetwarzanie: EB0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.16it/s]\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/4481] Przetwarzanie: EB0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.49it/s]\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/4481] Przetwarzanie: EB0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/4481] Przetwarzanie: EB0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/4481] Przetwarzanie: EB0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.11it/s]\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/4481] Przetwarzanie: EB0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.15it/s]\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/4481] Przetwarzanie: EB0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/4481] Przetwarzanie: EB0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.58it/s]\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/4481] Przetwarzanie: EB0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.43it/s]\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/4481] Przetwarzanie: EB0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/4481] Przetwarzanie: EB0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/4481] Przetwarzanie: EB0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/4481] Przetwarzanie: EB0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.00it/s]\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/4481] Przetwarzanie: EB0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.62it/s]\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/4481] Przetwarzanie: EB0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.45it/s]\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/4481] Przetwarzanie: EB0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/4481] Przetwarzanie: EB0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.75it/s]\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/4481] Przetwarzanie: EB0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/4481] Przetwarzanie: EB0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/4481] Przetwarzanie: EB0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/4481] Przetwarzanie: EB0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/4481] Przetwarzanie: EB0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/4481] Przetwarzanie: EB0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/4481] Przetwarzanie: EB0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.02it/s]\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/4481] Przetwarzanie: EB0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36/4481] Przetwarzanie: EB0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/4481] Przetwarzanie: EB0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/4481] Przetwarzanie: EB0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39/4481] Przetwarzanie: EB0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/4481] Przetwarzanie: EB0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/4481] Przetwarzanie: EB0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.29it/s]\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42/4481] Przetwarzanie: EB0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/4481] Przetwarzanie: EB0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44/4481] Przetwarzanie: EB0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/4481] Przetwarzanie: EB0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46/4481] Przetwarzanie: EB0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/4481] Przetwarzanie: EB0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.75it/s]\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/4481] Przetwarzanie: EB0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.34it/s]\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49/4481] Przetwarzanie: EB0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.36it/s]\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/4481] Przetwarzanie: EB0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.80it/s]\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51/4481] Przetwarzanie: EB0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52/4481] Przetwarzanie: EB0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53/4481] Przetwarzanie: EB0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54/4481] Przetwarzanie: EB0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55/4481] Przetwarzanie: EB0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.96it/s]\n",
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/4481] Przetwarzanie: EB0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57/4481] Przetwarzanie: EB0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.54it/s]\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58/4481] Przetwarzanie: EB0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/4481] Przetwarzanie: EB0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/4481] Przetwarzanie: EB0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.16it/s]\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61/4481] Przetwarzanie: EB0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62/4481] Przetwarzanie: EB0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.19it/s]\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63/4481] Przetwarzanie: EB0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64/4481] Przetwarzanie: EB0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65/4481] Przetwarzanie: EB0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.36it/s]\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66/4481] Przetwarzanie: EB0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/4481] Przetwarzanie: EB0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68/4481] Przetwarzanie: EB0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69/4481] Przetwarzanie: EB0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.63it/s]\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70/4481] Przetwarzanie: EB0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71/4481] Przetwarzanie: EB0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/4481] Przetwarzanie: EB0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73/4481] Przetwarzanie: EB0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74/4481] Przetwarzanie: EB0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75/4481] Przetwarzanie: EB0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/4481] Przetwarzanie: EB0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77/4481] Przetwarzanie: EB0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.16it/s]\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78/4481] Przetwarzanie: EB0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.55it/s]\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79/4481] Przetwarzanie: EB0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80/4481] Przetwarzanie: EB0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.36it/s]\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81/4481] Przetwarzanie: EB0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82/4481] Przetwarzanie: EB0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83/4481] Przetwarzanie: EB0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84/4481] Przetwarzanie: EB0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.16it/s]\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85/4481] Przetwarzanie: EB0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86/4481] Przetwarzanie: EB0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87/4481] Przetwarzanie: EB0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.96it/s]\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88/4481] Przetwarzanie: EB0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.20it/s]\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/4481] Przetwarzanie: EB0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/4481] Przetwarzanie: EB0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.90it/s]\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91/4481] Przetwarzanie: EB0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.44it/s]\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92/4481] Przetwarzanie: EB0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93/4481] Przetwarzanie: EB0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/4481] Przetwarzanie: EB0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95/4481] Przetwarzanie: EB0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.64it/s]\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96/4481] Przetwarzanie: EB0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.14it/s]\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97/4481] Przetwarzanie: EB0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:33:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98/4481] Przetwarzanie: EB0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/4481] Przetwarzanie: EB0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/4481] Przetwarzanie: EB0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101/4481] Przetwarzanie: EB0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102/4481] Przetwarzanie: EB0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103/4481] Przetwarzanie: EB0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.02it/s]\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104/4481] Przetwarzanie: EB0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105/4481] Przetwarzanie: EB0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106/4481] Przetwarzanie: EB0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.22it/s]\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107/4481] Przetwarzanie: EB0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108/4481] Przetwarzanie: EB0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.63it/s]\n",
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109/4481] Przetwarzanie: EB0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.43it/s]\n",
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110/4481] Przetwarzanie: EB0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/4481] Przetwarzanie: EB0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112/4481] Przetwarzanie: EB0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113/4481] Przetwarzanie: EB0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.06it/s]\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114/4481] Przetwarzanie: EB0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115/4481] Przetwarzanie: EB0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116/4481] Przetwarzanie: EB0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117/4481] Przetwarzanie: EB0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118/4481] Przetwarzanie: EB0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.42it/s]\n",
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119/4481] Przetwarzanie: EB0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120/4481] Przetwarzanie: EB0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121/4481] Przetwarzanie: EB0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.37it/s]\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122/4481] Przetwarzanie: EB0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123/4481] Przetwarzanie: EB0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124/4481] Przetwarzanie: EB0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125/4481] Przetwarzanie: EB0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126/4481] Przetwarzanie: EB0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.11it/s]\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127/4481] Przetwarzanie: EB0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128/4481] Przetwarzanie: EB0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:33:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129/4481] Przetwarzanie: EB0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130/4481] Przetwarzanie: EB0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131/4481] Przetwarzanie: EB0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132/4481] Przetwarzanie: EB0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133/4481] Przetwarzanie: EB0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134/4481] Przetwarzanie: EB0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135/4481] Przetwarzanie: EB0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136/4481] Przetwarzanie: EB0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137/4481] Przetwarzanie: EB0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.79it/s]\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/4481] Przetwarzanie: EB0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139/4481] Przetwarzanie: EB0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140/4481] Przetwarzanie: EB0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141/4481] Przetwarzanie: EB0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142/4481] Przetwarzanie: EB0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143/4481] Przetwarzanie: EB0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144/4481] Przetwarzanie: EB0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145/4481] Przetwarzanie: EB0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/4481] Przetwarzanie: EB0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147/4481] Przetwarzanie: EB0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148/4481] Przetwarzanie: EB0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149/4481] Przetwarzanie: EB0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.82it/s]\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150/4481] Przetwarzanie: EB0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151/4481] Przetwarzanie: EB0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152/4481] Przetwarzanie: EB0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153/4481] Przetwarzanie: EB0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/4481] Przetwarzanie: EB0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155/4481] Przetwarzanie: EB0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156/4481] Przetwarzanie: EB0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157/4481] Przetwarzanie: EB0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158/4481] Przetwarzanie: EB0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159/4481] Przetwarzanie: EB0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160/4481] Przetwarzanie: EB0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161/4481] Przetwarzanie: EB0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162/4481] Przetwarzanie: EB0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.75it/s]\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163/4481] Przetwarzanie: EB0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164/4481] Przetwarzanie: EB0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165/4481] Przetwarzanie: EB0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166/4481] Przetwarzanie: EB0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.79it/s]\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167/4481] Przetwarzanie: EB0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.17it/s]\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168/4481] Przetwarzanie: EB0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169/4481] Przetwarzanie: EB0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170/4481] Przetwarzanie: EB0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171/4481] Przetwarzanie: EB0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.55it/s]\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172/4481] Przetwarzanie: EB0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.98it/s]\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173/4481] Przetwarzanie: EB0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.62it/s]\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174/4481] Przetwarzanie: EB0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.04it/s]\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/4481] Przetwarzanie: EB0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:34:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176/4481] Przetwarzanie: EB0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:34:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[177/4481] Przetwarzanie: EB0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:34:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178/4481] Przetwarzanie: EB0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179/4481] Przetwarzanie: EB0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180/4481] Przetwarzanie: EB0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181/4481] Przetwarzanie: EB0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/4481] Przetwarzanie: EB0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183/4481] Przetwarzanie: EB0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.04it/s]\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184/4481] Przetwarzanie: EB0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[185/4481] Przetwarzanie: EB0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.73it/s]\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186/4481] Przetwarzanie: EB0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187/4481] Przetwarzanie: EB0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.02it/s]\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/4481] Przetwarzanie: EB0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189/4481] Przetwarzanie: EB0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190/4481] Przetwarzanie: EB0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191/4481] Przetwarzanie: EB0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192/4481] Przetwarzanie: EB0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193/4481] Przetwarzanie: EB0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.64it/s]\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194/4481] Przetwarzanie: EB0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195/4481] Przetwarzanie: EB0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.96it/s]\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196/4481] Przetwarzanie: EB0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197/4481] Przetwarzanie: EB0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198/4481] Przetwarzanie: EB0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199/4481] Przetwarzanie: EB0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/4481] Przetwarzanie: EB0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201/4481] Przetwarzanie: EB0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.39it/s]\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202/4481] Przetwarzanie: EB0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203/4481] Przetwarzanie: EB0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204/4481] Przetwarzanie: EB0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205/4481] Przetwarzanie: EB0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.67it/s]\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206/4481] Przetwarzanie: EB0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.35it/s]\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207/4481] Przetwarzanie: EB0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.42it/s]\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208/4481] Przetwarzanie: EB0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209/4481] Przetwarzanie: EB0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210/4481] Przetwarzanie: EB0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211/4481] Przetwarzanie: EB0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212/4481] Przetwarzanie: EB0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213/4481] Przetwarzanie: EB0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214/4481] Przetwarzanie: EB0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.26it/s]\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[215/4481] Przetwarzanie: EB0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n",
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216/4481] Przetwarzanie: EB0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217/4481] Przetwarzanie: EB0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.13it/s]\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218/4481] Przetwarzanie: EB0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219/4481] Przetwarzanie: EB0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220/4481] Przetwarzanie: EB0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221/4481] Przetwarzanie: EB0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222/4481] Przetwarzanie: EB0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223/4481] Przetwarzanie: EB0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224/4481] Przetwarzanie: EB0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.55it/s]\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225/4481] Przetwarzanie: EB0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.48it/s]\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226/4481] Przetwarzanie: EB0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227/4481] Przetwarzanie: EB0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.94it/s]\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228/4481] Przetwarzanie: EB0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.56it/s]\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229/4481] Przetwarzanie: EB0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.65it/s]\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230/4481] Przetwarzanie: EB0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.00it/s]\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231/4481] Przetwarzanie: EB0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232/4481] Przetwarzanie: EB0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233/4481] Przetwarzanie: EB0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234/4481] Przetwarzanie: EB0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.79it/s]\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235/4481] Przetwarzanie: EB0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.95it/s]\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236/4481] Przetwarzanie: EB0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.39it/s]\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237/4481] Przetwarzanie: EB0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238/4481] Przetwarzanie: EB0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239/4481] Przetwarzanie: EB0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.04it/s]\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240/4481] Przetwarzanie: EB0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[241/4481] Przetwarzanie: EB0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242/4481] Przetwarzanie: EB0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.97it/s]\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243/4481] Przetwarzanie: EB0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244/4481] Przetwarzanie: EB0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245/4481] Przetwarzanie: EB0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246/4481] Przetwarzanie: EB0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247/4481] Przetwarzanie: EB0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248/4481] Przetwarzanie: EB0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249/4481] Przetwarzanie: EB0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250/4481] Przetwarzanie: EB0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251/4481] Przetwarzanie: EB0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252/4481] Przetwarzanie: EB0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253/4481] Przetwarzanie: EB0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254/4481] Przetwarzanie: EB0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255/4481] Przetwarzanie: EB0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256/4481] Przetwarzanie: EB0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257/4481] Przetwarzanie: EB0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258/4481] Przetwarzanie: EB0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259/4481] Przetwarzanie: EB0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260/4481] Przetwarzanie: EB0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.44it/s]\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261/4481] Przetwarzanie: EB0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.10it/s]\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262/4481] Przetwarzanie: EB0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263/4481] Przetwarzanie: EB0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264/4481] Przetwarzanie: EB0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.06it/s]\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[265/4481] Przetwarzanie: EB0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266/4481] Przetwarzanie: EB0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[267/4481] Przetwarzanie: EB0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[268/4481] Przetwarzanie: EB0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.34it/s]\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269/4481] Przetwarzanie: EB0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270/4481] Przetwarzanie: EB0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[271/4481] Przetwarzanie: EB0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[272/4481] Przetwarzanie: EB0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273/4481] Przetwarzanie: EB0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274/4481] Przetwarzanie: EB0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275/4481] Przetwarzanie: EB0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.63it/s]\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[276/4481] Przetwarzanie: EB0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[277/4481] Przetwarzanie: EB0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.22it/s]\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[278/4481] Przetwarzanie: EB0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[279/4481] Przetwarzanie: EB0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280/4481] Przetwarzanie: EB0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281/4481] Przetwarzanie: EB0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282/4481] Przetwarzanie: EB0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[283/4481] Przetwarzanie: EB0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284/4481] Przetwarzanie: EB0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285/4481] Przetwarzanie: EB0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286/4481] Przetwarzanie: EB0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.66it/s]\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[287/4481] Przetwarzanie: EB0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288/4481] Przetwarzanie: EB0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289/4481] Przetwarzanie: EB0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290/4481] Przetwarzanie: EB0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[291/4481] Przetwarzanie: EB0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292/4481] Przetwarzanie: EB0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293/4481] Przetwarzanie: EB0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[294/4481] Przetwarzanie: EB0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295/4481] Przetwarzanie: EB0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[296/4481] Przetwarzanie: EB0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[297/4481] Przetwarzanie: EB0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:34:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298/4481] Przetwarzanie: EB0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[299/4481] Przetwarzanie: EB0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300/4481] Przetwarzanie: EB0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.75it/s]\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[301/4481] Przetwarzanie: EB0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[302/4481] Przetwarzanie: EB0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[303/4481] Przetwarzanie: EB0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304/4481] Przetwarzanie: EB0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[305/4481] Przetwarzanie: EB0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306/4481] Przetwarzanie: EB0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[307/4481] Przetwarzanie: EB0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.99it/s]\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308/4481] Przetwarzanie: EB0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309/4481] Przetwarzanie: EB0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310/4481] Przetwarzanie: EB0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311/4481] Przetwarzanie: EB0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[312/4481] Przetwarzanie: EB0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313/4481] Przetwarzanie: EB0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314/4481] Przetwarzanie: EB0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[315/4481] Przetwarzanie: EB0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316/4481] Przetwarzanie: EB0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[317/4481] Przetwarzanie: EB0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[318/4481] Przetwarzanie: EB0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[319/4481] Przetwarzanie: EB0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320/4481] Przetwarzanie: EB0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321/4481] Przetwarzanie: EB0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[322/4481] Przetwarzanie: EB0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[323/4481] Przetwarzanie: EB0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[324/4481] Przetwarzanie: EB0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[325/4481] Przetwarzanie: EB0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[326/4481] Przetwarzanie: EB0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[327/4481] Przetwarzanie: EB0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328/4481] Przetwarzanie: EB0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329/4481] Przetwarzanie: EB0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330/4481] Przetwarzanie: EB0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331/4481] Przetwarzanie: EB0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332/4481] Przetwarzanie: EB0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[333/4481] Przetwarzanie: EB0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[334/4481] Przetwarzanie: EB0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.65it/s]\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335/4481] Przetwarzanie: EB0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[336/4481] Przetwarzanie: EB0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.38it/s]\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[337/4481] Przetwarzanie: EB0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[338/4481] Przetwarzanie: EB0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[339/4481] Przetwarzanie: EB0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340/4481] Przetwarzanie: EB0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.60it/s]\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[341/4481] Przetwarzanie: EB0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[342/4481] Przetwarzanie: EB0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.64it/s]\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[343/4481] Przetwarzanie: EB0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[344/4481] Przetwarzanie: EB0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345/4481] Przetwarzanie: EB0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[346/4481] Przetwarzanie: EB0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[347/4481] Przetwarzanie: EB0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[348/4481] Przetwarzanie: EB0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.78it/s]\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[349/4481] Przetwarzanie: EB0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350/4481] Przetwarzanie: EB0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[351/4481] Przetwarzanie: EB0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[352/4481] Przetwarzanie: EB0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[353/4481] Przetwarzanie: EB0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[354/4481] Przetwarzanie: EB0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355/4481] Przetwarzanie: EB0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356/4481] Przetwarzanie: EB0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[357/4481] Przetwarzanie: EB0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[358/4481] Przetwarzanie: EB0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[359/4481] Przetwarzanie: EB0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360/4481] Przetwarzanie: EB0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[361/4481] Przetwarzanie: EB0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[362/4481] Przetwarzanie: EB0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[363/4481] Przetwarzanie: EB0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[364/4481] Przetwarzanie: EB0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[365/4481] Przetwarzanie: EB0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  9.04it/s]\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[366/4481] Przetwarzanie: EB0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[367/4481] Przetwarzanie: EB0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.12it/s]\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[368/4481] Przetwarzanie: EB0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[369/4481] Przetwarzanie: EB0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370/4481] Przetwarzanie: EB0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[371/4481] Przetwarzanie: EB0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[372/4481] Przetwarzanie: EB0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[373/4481] Przetwarzanie: EB0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[374/4481] Przetwarzanie: EB0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375/4481] Przetwarzanie: EB0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[376/4481] Przetwarzanie: EB0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[377/4481] Przetwarzanie: EB0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[378/4481] Przetwarzanie: EB0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[379/4481] Przetwarzanie: EB0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[380/4481] Przetwarzanie: EB0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.64it/s]\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381/4481] Przetwarzanie: EB0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[382/4481] Przetwarzanie: EB0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[383/4481] Przetwarzanie: EB0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.98it/s]\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384/4481] Przetwarzanie: EB0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[385/4481] Przetwarzanie: EB0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[386/4481] Przetwarzanie: EB0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387/4481] Przetwarzanie: EB0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[388/4481] Przetwarzanie: EB0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[389/4481] Przetwarzanie: EB0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.54it/s]\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390/4481] Przetwarzanie: EB0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.98it/s]\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[391/4481] Przetwarzanie: EB0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[392/4481] Przetwarzanie: EB0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[393/4481] Przetwarzanie: EB0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394/4481] Przetwarzanie: EB0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395/4481] Przetwarzanie: EB0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396/4481] Przetwarzanie: EB0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.56it/s]\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[397/4481] Przetwarzanie: EB0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398/4481] Przetwarzanie: EB0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.55it/s]\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[399/4481] Przetwarzanie: EB0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400/4481] Przetwarzanie: EB0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[401/4481] Przetwarzanie: EB0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.46it/s]\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[402/4481] Przetwarzanie: EB0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[403/4481] Przetwarzanie: EB0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[404/4481] Przetwarzanie: EB0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[405/4481] Przetwarzanie: EB0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.53it/s]\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[406/4481] Przetwarzanie: EB0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.64it/s]\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407/4481] Przetwarzanie: EB0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.59it/s]\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[408/4481] Przetwarzanie: EB0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.37it/s]\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[409/4481] Przetwarzanie: EB0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[410/4481] Przetwarzanie: EB0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[411/4481] Przetwarzanie: EB0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[412/4481] Przetwarzanie: EB0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.45it/s]\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[413/4481] Przetwarzanie: EB0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[414/4481] Przetwarzanie: EB0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415/4481] Przetwarzanie: EB0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416/4481] Przetwarzanie: EB0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.44it/s]\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[417/4481] Przetwarzanie: EB0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[418/4481] Przetwarzanie: EB0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419/4481] Przetwarzanie: EB0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.70it/s]\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:34:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[420/4481] Przetwarzanie: EB0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[421/4481] Przetwarzanie: EB0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.98it/s]\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422/4481] Przetwarzanie: EB0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[423/4481] Przetwarzanie: EB0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424/4481] Przetwarzanie: EB0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425/4481] Przetwarzanie: EB0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.52it/s]\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426/4481] Przetwarzanie: EB0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.38it/s]\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427/4481] Przetwarzanie: EB0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[428/4481] Przetwarzanie: EB0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429/4481] Przetwarzanie: EB0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[430/4481] Przetwarzanie: EB0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[431/4481] Przetwarzanie: EB0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[432/4481] Przetwarzanie: EB0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[433/4481] Przetwarzanie: EB0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[434/4481] Przetwarzanie: EB0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[435/4481] Przetwarzanie: EB0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436/4481] Przetwarzanie: EB0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[437/4481] Przetwarzanie: EB0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[438/4481] Przetwarzanie: EB0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439/4481] Przetwarzanie: EB0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[440/4481] Przetwarzanie: EB0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[441/4481] Przetwarzanie: EB0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442/4481] Przetwarzanie: EB0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[443/4481] Przetwarzanie: EB0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[444/4481] Przetwarzanie: EB0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445/4481] Przetwarzanie: EB0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446/4481] Przetwarzanie: EB0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[447/4481] Przetwarzanie: EB0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[448/4481] Przetwarzanie: EB0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[449/4481] Przetwarzanie: EB0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450/4481] Przetwarzanie: EB0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.90it/s]\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[451/4481] Przetwarzanie: EB0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[452/4481] Przetwarzanie: EB0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[453/4481] Przetwarzanie: EB0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[454/4481] Przetwarzanie: EB0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[455/4481] Przetwarzanie: EB0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.75it/s]\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[456/4481] Przetwarzanie: EB0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[457/4481] Przetwarzanie: EB0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[458/4481] Przetwarzanie: EB0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[459/4481] Przetwarzanie: EB0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460/4481] Przetwarzanie: EB0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[461/4481] Przetwarzanie: EB0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[462/4481] Przetwarzanie: EB0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.15it/s]\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[463/4481] Przetwarzanie: EB0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.47it/s]\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[464/4481] Przetwarzanie: EB0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.34it/s]\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[465/4481] Przetwarzanie: EB0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[466/4481] Przetwarzanie: EB0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.14it/s]\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[467/4481] Przetwarzanie: EB0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[468/4481] Przetwarzanie: EB0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[469/4481] Przetwarzanie: EB0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[470/4481] Przetwarzanie: EB0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.65it/s]\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[471/4481] Przetwarzanie: EB0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[472/4481] Przetwarzanie: EB0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[473/4481] Przetwarzanie: EB0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.64it/s]\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[474/4481] Przetwarzanie: EB0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[475/4481] Przetwarzanie: EB0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[476/4481] Przetwarzanie: EB0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[477/4481] Przetwarzanie: EB0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[478/4481] Przetwarzanie: EB0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479/4481] Przetwarzanie: EB0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480/4481] Przetwarzanie: EB0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[481/4481] Przetwarzanie: EB0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[482/4481] Przetwarzanie: EB0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[483/4481] Przetwarzanie: EB0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[484/4481] Przetwarzanie: EB0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.15it/s]\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[485/4481] Przetwarzanie: EB0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[486/4481] Przetwarzanie: EB0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487/4481] Przetwarzanie: EB0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[488/4481] Przetwarzanie: EB0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[489/4481] Przetwarzanie: EB0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[490/4481] Przetwarzanie: EB0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[491/4481] Przetwarzanie: EB0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[492/4481] Przetwarzanie: EB0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[493/4481] Przetwarzanie: EB0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[494/4481] Przetwarzanie: EB0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[495/4481] Przetwarzanie: EB0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[496/4481] Przetwarzanie: EB0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[497/4481] Przetwarzanie: EB0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[498/4481] Przetwarzanie: EB0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[499/4481] Przetwarzanie: EB0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500/4481] Przetwarzanie: EB0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[501/4481] Przetwarzanie: EB0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[502/4481] Przetwarzanie: EB0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[503/4481] Przetwarzanie: EB0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[504/4481] Przetwarzanie: EB0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[505/4481] Przetwarzanie: EB0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.45it/s]\n",
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[506/4481] Przetwarzanie: EB0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[507/4481] Przetwarzanie: EB0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[508/4481] Przetwarzanie: EB0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.80it/s]\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[509/4481] Przetwarzanie: EB0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510/4481] Przetwarzanie: EB0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[511/4481] Przetwarzanie: EB0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512/4481] Przetwarzanie: EB0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[513/4481] Przetwarzanie: EB0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[514/4481] Przetwarzanie: EB0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[515/4481] Przetwarzanie: EB0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[516/4481] Przetwarzanie: EB0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[517/4481] Przetwarzanie: EB0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[518/4481] Przetwarzanie: EB0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[519/4481] Przetwarzanie: EB0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520/4481] Przetwarzanie: EB0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:35:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[521/4481] Przetwarzanie: EB0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[522/4481] Przetwarzanie: EB0_surprised_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[523/4481] Przetwarzanie: EB0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[524/4481] Przetwarzanie: EB0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[525/4481] Przetwarzanie: EB0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[526/4481] Przetwarzanie: EB0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.20it/s]\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[527/4481] Przetwarzanie: EB0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[528/4481] Przetwarzanie: EB0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[529/4481] Przetwarzanie: EB0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[530/4481] Przetwarzanie: EB0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[531/4481] Przetwarzanie: EB0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.99it/s]\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[532/4481] Przetwarzanie: EB0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[533/4481] Przetwarzanie: EB0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.08it/s]\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[534/4481] Przetwarzanie: EB0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.06it/s]\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[535/4481] Przetwarzanie: EB0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.99it/s]\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[536/4481] Przetwarzanie: EB0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[537/4481] Przetwarzanie: EB0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.22it/s]\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[538/4481] Przetwarzanie: EB0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.63it/s]\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[539/4481] Przetwarzanie: EB0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[540/4481] Przetwarzanie: IC0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.66it/s]\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[541/4481] Przetwarzanie: IC0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[542/4481] Przetwarzanie: IC0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.37it/s]\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[543/4481] Przetwarzanie: IC0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.02it/s]\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[544/4481] Przetwarzanie: IC0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.74it/s]\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[545/4481] Przetwarzanie: IC0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[546/4481] Przetwarzanie: IC0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[547/4481] Przetwarzanie: IC0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[548/4481] Przetwarzanie: IC0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[549/4481] Przetwarzanie: IC0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550/4481] Przetwarzanie: IC0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[551/4481] Przetwarzanie: IC0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.61it/s]\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[552/4481] Przetwarzanie: IC0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[553/4481] Przetwarzanie: IC0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[554/4481] Przetwarzanie: IC0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555/4481] Przetwarzanie: IC0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[556/4481] Przetwarzanie: IC0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[557/4481] Przetwarzanie: IC0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[558/4481] Przetwarzanie: IC0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[559/4481] Przetwarzanie: IC0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[560/4481] Przetwarzanie: IC0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.48it/s]\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[561/4481] Przetwarzanie: IC0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[562/4481] Przetwarzanie: IC0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.94it/s]\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[563/4481] Przetwarzanie: IC0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[564/4481] Przetwarzanie: IC0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[565/4481] Przetwarzanie: IC0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[566/4481] Przetwarzanie: IC0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[567/4481] Przetwarzanie: IC0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[568/4481] Przetwarzanie: IC0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[569/4481] Przetwarzanie: IC0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[570/4481] Przetwarzanie: IC0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[571/4481] Przetwarzanie: IC0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[572/4481] Przetwarzanie: IC0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[573/4481] Przetwarzanie: IC0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[574/4481] Przetwarzanie: IC0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[575/4481] Przetwarzanie: IC0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[576/4481] Przetwarzanie: IC0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[577/4481] Przetwarzanie: IC0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[578/4481] Przetwarzanie: IC0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[579/4481] Przetwarzanie: IC0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[580/4481] Przetwarzanie: IC0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[581/4481] Przetwarzanie: IC0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[582/4481] Przetwarzanie: IC0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[583/4481] Przetwarzanie: IC0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[584/4481] Przetwarzanie: IC0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.50it/s]\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[585/4481] Przetwarzanie: IC0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586/4481] Przetwarzanie: IC0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[587/4481] Przetwarzanie: IC0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.39it/s]\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[588/4481] Przetwarzanie: IC0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[589/4481] Przetwarzanie: IC0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.74it/s]\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[590/4481] Przetwarzanie: IC0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[591/4481] Przetwarzanie: IC0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[592/4481] Przetwarzanie: IC0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[593/4481] Przetwarzanie: IC0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.75it/s]\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[594/4481] Przetwarzanie: IC0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.93it/s]\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[595/4481] Przetwarzanie: IC0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.66it/s]\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[596/4481] Przetwarzanie: IC0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[597/4481] Przetwarzanie: IC0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[598/4481] Przetwarzanie: IC0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[599/4481] Przetwarzanie: IC0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600/4481] Przetwarzanie: IC0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[601/4481] Przetwarzanie: IC0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[602/4481] Przetwarzanie: IC0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[603/4481] Przetwarzanie: IC0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.33it/s]\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[604/4481] Przetwarzanie: IC0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[605/4481] Przetwarzanie: IC0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[606/4481] Przetwarzanie: IC0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[607/4481] Przetwarzanie: IC0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[608/4481] Przetwarzanie: IC0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[609/4481] Przetwarzanie: IC0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[610/4481] Przetwarzanie: IC0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[611/4481] Przetwarzanie: IC0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[612/4481] Przetwarzanie: IC0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.45it/s]\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[613/4481] Przetwarzanie: IC0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[614/4481] Przetwarzanie: IC0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[615/4481] Przetwarzanie: IC0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[616/4481] Przetwarzanie: IC0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[617/4481] Przetwarzanie: IC0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[618/4481] Przetwarzanie: IC0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[619/4481] Przetwarzanie: IC0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[620/4481] Przetwarzanie: IC0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[621/4481] Przetwarzanie: IC0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[622/4481] Przetwarzanie: IC0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[623/4481] Przetwarzanie: IC0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[624/4481] Przetwarzanie: IC0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[625/4481] Przetwarzanie: IC0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[626/4481] Przetwarzanie: IC0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.96it/s]\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[627/4481] Przetwarzanie: IC0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[628/4481] Przetwarzanie: IC0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[629/4481] Przetwarzanie: IC0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.89it/s]\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[630/4481] Przetwarzanie: IC0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.62it/s]\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[631/4481] Przetwarzanie: IC0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[632/4481] Przetwarzanie: IC0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[633/4481] Przetwarzanie: IC0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[634/4481] Przetwarzanie: IC0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.65it/s]\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[635/4481] Przetwarzanie: IC0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[636/4481] Przetwarzanie: IC0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[637/4481] Przetwarzanie: IC0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[638/4481] Przetwarzanie: IC0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[639/4481] Przetwarzanie: IC0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640/4481] Przetwarzanie: IC0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[641/4481] Przetwarzanie: IC0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.08it/s]\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[642/4481] Przetwarzanie: IC0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[643/4481] Przetwarzanie: IC0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[644/4481] Przetwarzanie: IC0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[645/4481] Przetwarzanie: IC0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[646/4481] Przetwarzanie: IC0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[647/4481] Przetwarzanie: IC0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[648/4481] Przetwarzanie: IC0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[649/4481] Przetwarzanie: IC0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[650/4481] Przetwarzanie: IC0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[651/4481] Przetwarzanie: IC0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[652/4481] Przetwarzanie: IC0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.08it/s]\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[653/4481] Przetwarzanie: IC0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[654/4481] Przetwarzanie: IC0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.47it/s]\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[655/4481] Przetwarzanie: IC0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[656/4481] Przetwarzanie: IC0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[657/4481] Przetwarzanie: IC0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[658/4481] Przetwarzanie: IC0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[659/4481] Przetwarzanie: IC0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[660/4481] Przetwarzanie: IC0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[661/4481] Przetwarzanie: IC0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[662/4481] Przetwarzanie: IC0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[663/4481] Przetwarzanie: IC0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[664/4481] Przetwarzanie: IC0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[665/4481] Przetwarzanie: IC0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[666/4481] Przetwarzanie: IC0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[667/4481] Przetwarzanie: IC0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[668/4481] Przetwarzanie: IC0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[669/4481] Przetwarzanie: IC0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[670/4481] Przetwarzanie: IC0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[671/4481] Przetwarzanie: IC0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[672/4481] Przetwarzanie: IC0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.33it/s]\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[673/4481] Przetwarzanie: IC0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[674/4481] Przetwarzanie: IC0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[675/4481] Przetwarzanie: IC0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[676/4481] Przetwarzanie: IC0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[677/4481] Przetwarzanie: IC0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[678/4481] Przetwarzanie: IC0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[679/4481] Przetwarzanie: IC0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[680/4481] Przetwarzanie: IC0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[681/4481] Przetwarzanie: IC0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[682/4481] Przetwarzanie: IC0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[683/4481] Przetwarzanie: IC0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[684/4481] Przetwarzanie: IC0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[685/4481] Przetwarzanie: IC0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[686/4481] Przetwarzanie: IC0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[687/4481] Przetwarzanie: IC0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[688/4481] Przetwarzanie: IC0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[689/4481] Przetwarzanie: IC0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[690/4481] Przetwarzanie: IC0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[691/4481] Przetwarzanie: IC0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[692/4481] Przetwarzanie: IC0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[693/4481] Przetwarzanie: IC0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[694/4481] Przetwarzanie: IC0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[695/4481] Przetwarzanie: IC0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[696/4481] Przetwarzanie: IC0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[697/4481] Przetwarzanie: IC0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[698/4481] Przetwarzanie: IC0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[699/4481] Przetwarzanie: IC0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700/4481] Przetwarzanie: IC0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[701/4481] Przetwarzanie: IC0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[702/4481] Przetwarzanie: IC0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[703/4481] Przetwarzanie: IC0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[704/4481] Przetwarzanie: IC0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[705/4481] Przetwarzanie: IC0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[706/4481] Przetwarzanie: IC0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[707/4481] Przetwarzanie: IC0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708/4481] Przetwarzanie: IC0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:35:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[709/4481] Przetwarzanie: IC0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.56it/s]\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[710/4481] Przetwarzanie: IC0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[711/4481] Przetwarzanie: IC0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[712/4481] Przetwarzanie: IC0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[713/4481] Przetwarzanie: IC0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[714/4481] Przetwarzanie: IC0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[715/4481] Przetwarzanie: IC0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[716/4481] Przetwarzanie: IC0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[717/4481] Przetwarzanie: IC0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[718/4481] Przetwarzanie: IC0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[719/4481] Przetwarzanie: IC0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.92it/s]\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[720/4481] Przetwarzanie: IC0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.81it/s]\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[721/4481] Przetwarzanie: IC0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[722/4481] Przetwarzanie: IC0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[723/4481] Przetwarzanie: IC0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[724/4481] Przetwarzanie: IC0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[725/4481] Przetwarzanie: IC0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.18it/s]\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[726/4481] Przetwarzanie: IC0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[727/4481] Przetwarzanie: IC0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[728/4481] Przetwarzanie: IC0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.88it/s]\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[729/4481] Przetwarzanie: IC0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[730/4481] Przetwarzanie: IC0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[731/4481] Przetwarzanie: IC0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.65it/s]\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[732/4481] Przetwarzanie: IC0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[733/4481] Przetwarzanie: IC0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[734/4481] Przetwarzanie: IC0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.34it/s]\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[735/4481] Przetwarzanie: IC0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[736/4481] Przetwarzanie: IC0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[737/4481] Przetwarzanie: IC0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[738/4481] Przetwarzanie: IC0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[739/4481] Przetwarzanie: IC0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[740/4481] Przetwarzanie: IC0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[741/4481] Przetwarzanie: IC0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[742/4481] Przetwarzanie: IC0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[743/4481] Przetwarzanie: IC0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[744/4481] Przetwarzanie: IC0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.99it/s]\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[745/4481] Przetwarzanie: IC0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[746/4481] Przetwarzanie: IC0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[747/4481] Przetwarzanie: IC0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[748/4481] Przetwarzanie: IC0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[749/4481] Przetwarzanie: IC0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750/4481] Przetwarzanie: IC0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[751/4481] Przetwarzanie: IC0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[752/4481] Przetwarzanie: IC0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[753/4481] Przetwarzanie: IC0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.11it/s]\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[754/4481] Przetwarzanie: IC0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[755/4481] Przetwarzanie: IC0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[756/4481] Przetwarzanie: IC0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[757/4481] Przetwarzanie: IC0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[758/4481] Przetwarzanie: IC0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[759/4481] Przetwarzanie: IC0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[760/4481] Przetwarzanie: IC0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[761/4481] Przetwarzanie: IC0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[762/4481] Przetwarzanie: IC0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[763/4481] Przetwarzanie: IC0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[764/4481] Przetwarzanie: IC0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[765/4481] Przetwarzanie: IC0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[766/4481] Przetwarzanie: IC0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[767/4481] Przetwarzanie: IC0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[768/4481] Przetwarzanie: IC0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.64it/s]\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[769/4481] Przetwarzanie: IC0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[770/4481] Przetwarzanie: IC0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[771/4481] Przetwarzanie: IC0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[772/4481] Przetwarzanie: IC0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[773/4481] Przetwarzanie: IC0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[774/4481] Przetwarzanie: IC0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[775/4481] Przetwarzanie: IC0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[776/4481] Przetwarzanie: IC0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[777/4481] Przetwarzanie: IC0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[778/4481] Przetwarzanie: IC0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[779/4481] Przetwarzanie: IC0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[780/4481] Przetwarzanie: IC0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[781/4481] Przetwarzanie: IC0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[782/4481] Przetwarzanie: IC0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[783/4481] Przetwarzanie: IC0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784/4481] Przetwarzanie: IC0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[785/4481] Przetwarzanie: IC0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[786/4481] Przetwarzanie: IC0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[787/4481] Przetwarzanie: IC0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[788/4481] Przetwarzanie: IC0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[789/4481] Przetwarzanie: IC0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[790/4481] Przetwarzanie: IC0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[791/4481] Przetwarzanie: IC0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[792/4481] Przetwarzanie: IC0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[793/4481] Przetwarzanie: IC0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[794/4481] Przetwarzanie: IC0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[795/4481] Przetwarzanie: IC0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[796/4481] Przetwarzanie: IC0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[797/4481] Przetwarzanie: IC0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.64it/s]\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[798/4481] Przetwarzanie: IC0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[799/4481] Przetwarzanie: IC0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.57it/s]\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800/4481] Przetwarzanie: IC0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[801/4481] Przetwarzanie: IC0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[802/4481] Przetwarzanie: IC0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[803/4481] Przetwarzanie: IC0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804/4481] Przetwarzanie: IC0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[805/4481] Przetwarzanie: IC0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[806/4481] Przetwarzanie: IC0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[807/4481] Przetwarzanie: IC0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[808/4481] Przetwarzanie: IC0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[809/4481] Przetwarzanie: IC0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[810/4481] Przetwarzanie: IC0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[811/4481] Przetwarzanie: IC0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[812/4481] Przetwarzanie: IC0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[813/4481] Przetwarzanie: IC0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[814/4481] Przetwarzanie: IC0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.61it/s]\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[815/4481] Przetwarzanie: IC0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[816/4481] Przetwarzanie: IC0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[817/4481] Przetwarzanie: IC0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[818/4481] Przetwarzanie: IC0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[819/4481] Przetwarzanie: IC0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[820/4481] Przetwarzanie: IC0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[821/4481] Przetwarzanie: IC0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822/4481] Przetwarzanie: IC0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[823/4481] Przetwarzanie: IC0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[824/4481] Przetwarzanie: IC0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[825/4481] Przetwarzanie: IC0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[826/4481] Przetwarzanie: IC0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[827/4481] Przetwarzanie: IC0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[828/4481] Przetwarzanie: IC0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[829/4481] Przetwarzanie: IC0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n",
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[830/4481] Przetwarzanie: IC0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[831/4481] Przetwarzanie: IC0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[832/4481] Przetwarzanie: IC0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[833/4481] Przetwarzanie: IC0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[834/4481] Przetwarzanie: IC0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[835/4481] Przetwarzanie: IC0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[836/4481] Przetwarzanie: IC0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[837/4481] Przetwarzanie: IC0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[838/4481] Przetwarzanie: IC0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[839/4481] Przetwarzanie: IC0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[840/4481] Przetwarzanie: IC0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[841/4481] Przetwarzanie: IC0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[842/4481] Przetwarzanie: IC0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[843/4481] Przetwarzanie: IC0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[844/4481] Przetwarzanie: IC0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[845/4481] Przetwarzanie: IC0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[846/4481] Przetwarzanie: IC0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[847/4481] Przetwarzanie: IC0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[848/4481] Przetwarzanie: IC0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[849/4481] Przetwarzanie: IC0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[850/4481] Przetwarzanie: IC0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[851/4481] Przetwarzanie: IC0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[852/4481] Przetwarzanie: IC0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[853/4481] Przetwarzanie: IC0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[854/4481] Przetwarzanie: IC0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.10it/s]\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[855/4481] Przetwarzanie: IC0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[856/4481] Przetwarzanie: IC0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[857/4481] Przetwarzanie: IC0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[858/4481] Przetwarzanie: IC0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[859/4481] Przetwarzanie: IC0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[860/4481] Przetwarzanie: IC0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[861/4481] Przetwarzanie: IC0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[862/4481] Przetwarzanie: IC0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[863/4481] Przetwarzanie: IC0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[864/4481] Przetwarzanie: IC0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[865/4481] Przetwarzanie: IC0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[866/4481] Przetwarzanie: IC0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[867/4481] Przetwarzanie: IC0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[868/4481] Przetwarzanie: IC0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[869/4481] Przetwarzanie: IC0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[870/4481] Przetwarzanie: IC0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[871/4481] Przetwarzanie: IC0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[872/4481] Przetwarzanie: IC0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[873/4481] Przetwarzanie: IC0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[874/4481] Przetwarzanie: IC0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[875/4481] Przetwarzanie: IC0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[876/4481] Przetwarzanie: IC0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[877/4481] Przetwarzanie: IC0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[878/4481] Przetwarzanie: IC0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[879/4481] Przetwarzanie: IC0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[880/4481] Przetwarzanie: IC0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[881/4481] Przetwarzanie: IC0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[882/4481] Przetwarzanie: IC0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[883/4481] Przetwarzanie: IC0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[884/4481] Przetwarzanie: IC0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[885/4481] Przetwarzanie: IC0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[886/4481] Przetwarzanie: IC0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.21it/s]\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[887/4481] Przetwarzanie: IC0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.65it/s]\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[888/4481] Przetwarzanie: IC0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[889/4481] Przetwarzanie: IC0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[890/4481] Przetwarzanie: IC0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[891/4481] Przetwarzanie: IC0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[892/4481] Przetwarzanie: IC0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[893/4481] Przetwarzanie: IC0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.04it/s]\n",
      "[NeMo W 2026-01-08 11:36:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[894/4481] Przetwarzanie: IC0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:36:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[895/4481] Przetwarzanie: IC0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:36:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[896/4481] Przetwarzanie: IC0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[897/4481] Przetwarzanie: IC0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[898/4481] Przetwarzanie: IC0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.05it/s]\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[899/4481] Przetwarzanie: IC0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900/4481] Przetwarzanie: IC0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.64it/s]\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[901/4481] Przetwarzanie: IC0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[902/4481] Przetwarzanie: IC0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[903/4481] Przetwarzanie: IC0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[904/4481] Przetwarzanie: IC0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.59it/s]\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[905/4481] Przetwarzanie: IC0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[906/4481] Przetwarzanie: IC0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[907/4481] Przetwarzanie: IC0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[908/4481] Przetwarzanie: IC0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[909/4481] Przetwarzanie: IC0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[910/4481] Przetwarzanie: IC0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[911/4481] Przetwarzanie: IC0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[912/4481] Przetwarzanie: IC0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[913/4481] Przetwarzanie: IC0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[914/4481] Przetwarzanie: IC0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[915/4481] Przetwarzanie: IC0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[916/4481] Przetwarzanie: IC0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[917/4481] Przetwarzanie: IC0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[918/4481] Przetwarzanie: IC0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[919/4481] Przetwarzanie: IC0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[920/4481] Przetwarzanie: IC0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[921/4481] Przetwarzanie: IC0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[922/4481] Przetwarzanie: IC0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.57it/s]\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[923/4481] Przetwarzanie: IC0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[924/4481] Przetwarzanie: IC0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[925/4481] Przetwarzanie: IC0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[926/4481] Przetwarzanie: IC0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[927/4481] Przetwarzanie: IC0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[928/4481] Przetwarzanie: IC0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[929/4481] Przetwarzanie: IC0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[930/4481] Przetwarzanie: IC0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[931/4481] Przetwarzanie: IC0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[932/4481] Przetwarzanie: IC0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[933/4481] Przetwarzanie: IC0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[934/4481] Przetwarzanie: IC0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[935/4481] Przetwarzanie: IC0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[936/4481] Przetwarzanie: IC0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[937/4481] Przetwarzanie: IC0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[938/4481] Przetwarzanie: IC0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[939/4481] Przetwarzanie: IC0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[940/4481] Przetwarzanie: IC0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[941/4481] Przetwarzanie: IC0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[942/4481] Przetwarzanie: IC0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[943/4481] Przetwarzanie: IC0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[944/4481] Przetwarzanie: IC0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[945/4481] Przetwarzanie: IC0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[946/4481] Przetwarzanie: IC0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[947/4481] Przetwarzanie: IC0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[948/4481] Przetwarzanie: IC0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[949/4481] Przetwarzanie: IC0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[950/4481] Przetwarzanie: IC0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[951/4481] Przetwarzanie: IC0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[952/4481] Przetwarzanie: IC0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[953/4481] Przetwarzanie: IC0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[954/4481] Przetwarzanie: IC0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[955/4481] Przetwarzanie: IC0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[956/4481] Przetwarzanie: IC0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[957/4481] Przetwarzanie: IC0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[958/4481] Przetwarzanie: IC0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.82it/s]\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[959/4481] Przetwarzanie: IC0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[960/4481] Przetwarzanie: IC0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[961/4481] Przetwarzanie: IC0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[962/4481] Przetwarzanie: IC0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[963/4481] Przetwarzanie: IC0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[964/4481] Przetwarzanie: IC0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.53it/s]\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[965/4481] Przetwarzanie: IC0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[966/4481] Przetwarzanie: IC0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[967/4481] Przetwarzanie: IC0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[968/4481] Przetwarzanie: IC0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[969/4481] Przetwarzanie: IC0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[970/4481] Przetwarzanie: IC0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[971/4481] Przetwarzanie: IC0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[972/4481] Przetwarzanie: IC0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[973/4481] Przetwarzanie: IC0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[974/4481] Przetwarzanie: IC0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[975/4481] Przetwarzanie: IC0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[976/4481] Przetwarzanie: IC0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[977/4481] Przetwarzanie: IC0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[978/4481] Przetwarzanie: IC0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[979/4481] Przetwarzanie: IC0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[980/4481] Przetwarzanie: IC0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[981/4481] Przetwarzanie: IC0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[982/4481] Przetwarzanie: IC0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[983/4481] Przetwarzanie: IC0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[984/4481] Przetwarzanie: IC0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:36:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[985/4481] Przetwarzanie: IC0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[986/4481] Przetwarzanie: IC0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[987/4481] Przetwarzanie: IC0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[988/4481] Przetwarzanie: IC0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[989/4481] Przetwarzanie: IC0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.88it/s]\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[990/4481] Przetwarzanie: IC0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[991/4481] Przetwarzanie: IC0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[992/4481] Przetwarzanie: IC0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[993/4481] Przetwarzanie: IC0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[994/4481] Przetwarzanie: IC0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.68it/s]\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[995/4481] Przetwarzanie: IC0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[996/4481] Przetwarzanie: IC0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[997/4481] Przetwarzanie: IC0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[998/4481] Przetwarzanie: IC0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[999/4481] Przetwarzanie: IC0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000/4481] Przetwarzanie: IC0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:36:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1001/4481] Przetwarzanie: IC0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1002/4481] Przetwarzanie: IC0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1003/4481] Przetwarzanie: IC0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1004/4481] Przetwarzanie: IC0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1005/4481] Przetwarzanie: IC0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1006/4481] Przetwarzanie: IC0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1007/4481] Przetwarzanie: IC0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1008/4481] Przetwarzanie: IC0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1009/4481] Przetwarzanie: IC0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1010/4481] Przetwarzanie: IC0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1011/4481] Przetwarzanie: IC0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1012/4481] Przetwarzanie: IC0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.14it/s]\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1013/4481] Przetwarzanie: IC0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1014/4481] Przetwarzanie: IC0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1015/4481] Przetwarzanie: IC0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1016/4481] Przetwarzanie: IC0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1017/4481] Przetwarzanie: IC0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1018/4481] Przetwarzanie: IC0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1019/4481] Przetwarzanie: IC0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1020/4481] Przetwarzanie: IC0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1021/4481] Przetwarzanie: IC0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1022/4481] Przetwarzanie: IC0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1023/4481] Przetwarzanie: IC0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1024/4481] Przetwarzanie: IC0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1025/4481] Przetwarzanie: IC0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1026/4481] Przetwarzanie: IC0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027/4481] Przetwarzanie: IC0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1028/4481] Przetwarzanie: IC0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1029/4481] Przetwarzanie: IC0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1030/4481] Przetwarzanie: IC0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1031/4481] Przetwarzanie: IC0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1032/4481] Przetwarzanie: IC0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1033/4481] Przetwarzanie: IC0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1034/4481] Przetwarzanie: IC0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.66it/s]\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1035/4481] Przetwarzanie: IC0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1036/4481] Przetwarzanie: IC0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1037/4481] Przetwarzanie: IC0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1038/4481] Przetwarzanie: IC0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1039/4481] Przetwarzanie: IC0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1040/4481] Przetwarzanie: IC0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1041/4481] Przetwarzanie: IC0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1042/4481] Przetwarzanie: IC0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1043/4481] Przetwarzanie: IC0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1044/4481] Przetwarzanie: IC0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045/4481] Przetwarzanie: IC0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1046/4481] Przetwarzanie: IC0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1047/4481] Przetwarzanie: IC0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1048/4481] Przetwarzanie: IC0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.78it/s]\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1049/4481] Przetwarzanie: IC0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1050/4481] Przetwarzanie: IC0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.10it/s]\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1051/4481] Przetwarzanie: IC0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1052/4481] Przetwarzanie: IC0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1053/4481] Przetwarzanie: IC0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1054/4481] Przetwarzanie: IC0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1055/4481] Przetwarzanie: IC0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1056/4481] Przetwarzanie: IC0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1057/4481] Przetwarzanie: IC0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1058/4481] Przetwarzanie: IC0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1059/4481] Przetwarzanie: IC0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1060/4481] Przetwarzanie: IC0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1061/4481] Przetwarzanie: IC0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1062/4481] Przetwarzanie: IC0_surprised_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1063/4481] Przetwarzanie: IC0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1064/4481] Przetwarzanie: IC0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1065/4481] Przetwarzanie: IC0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1066/4481] Przetwarzanie: IC0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1067/4481] Przetwarzanie: IC0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1068/4481] Przetwarzanie: IC0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1069/4481] Przetwarzanie: IC0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1070/4481] Przetwarzanie: IC0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1071/4481] Przetwarzanie: IC0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1072/4481] Przetwarzanie: IC0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1073/4481] Przetwarzanie: IC0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1074/4481] Przetwarzanie: IC0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1075/4481] Przetwarzanie: IC0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1076/4481] Przetwarzanie: IC0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1077/4481] Przetwarzanie: IC0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.23it/s]\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1078/4481] Przetwarzanie: IC0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1079/4481] Przetwarzanie: IC0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1080/4481] Przetwarzanie: KD0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.25it/s]\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1081/4481] Przetwarzanie: KD0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1082/4481] Przetwarzanie: KD0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1083/4481] Przetwarzanie: KD0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1084/4481] Przetwarzanie: KD0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1085/4481] Przetwarzanie: KD0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1086/4481] Przetwarzanie: KD0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1087/4481] Przetwarzanie: KD0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1088/4481] Przetwarzanie: KD0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1089/4481] Przetwarzanie: KD0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1090/4481] Przetwarzanie: KD0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1091/4481] Przetwarzanie: KD0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1092/4481] Przetwarzanie: KD0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1093/4481] Przetwarzanie: KD0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1094/4481] Przetwarzanie: KD0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1095/4481] Przetwarzanie: KD0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1096/4481] Przetwarzanie: KD0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1097/4481] Przetwarzanie: KD0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1098/4481] Przetwarzanie: KD0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1099/4481] Przetwarzanie: KD0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100/4481] Przetwarzanie: KD0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1101/4481] Przetwarzanie: KD0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1102/4481] Przetwarzanie: KD0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.14it/s]\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1103/4481] Przetwarzanie: KD0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1104/4481] Przetwarzanie: KD0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1105/4481] Przetwarzanie: KD0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1106/4481] Przetwarzanie: KD0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1107/4481] Przetwarzanie: KD0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1108/4481] Przetwarzanie: KD0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1109/4481] Przetwarzanie: KD0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1110/4481] Przetwarzanie: KD0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1111/4481] Przetwarzanie: KD0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1112/4481] Przetwarzanie: KD0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1113/4481] Przetwarzanie: KD0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.85it/s]\n",
      "[NeMo W 2026-01-08 11:37:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1114/4481] Przetwarzanie: KD0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1115/4481] Przetwarzanie: KD0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1116/4481] Przetwarzanie: KD0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1117/4481] Przetwarzanie: KD0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1118/4481] Przetwarzanie: KD0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1119/4481] Przetwarzanie: KD0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1120/4481] Przetwarzanie: KD0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1121/4481] Przetwarzanie: KD0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1122/4481] Przetwarzanie: KD0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1123/4481] Przetwarzanie: KD0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1124/4481] Przetwarzanie: KD0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1125/4481] Przetwarzanie: KD0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1126/4481] Przetwarzanie: KD0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1127/4481] Przetwarzanie: KD0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1128/4481] Przetwarzanie: KD0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1129/4481] Przetwarzanie: KD0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130/4481] Przetwarzanie: KD0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131/4481] Przetwarzanie: KD0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1132/4481] Przetwarzanie: KD0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1133/4481] Przetwarzanie: KD0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1134/4481] Przetwarzanie: KD0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1135/4481] Przetwarzanie: KD0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1136/4481] Przetwarzanie: KD0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1137/4481] Przetwarzanie: KD0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1138/4481] Przetwarzanie: KD0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1139/4481] Przetwarzanie: KD0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1140/4481] Przetwarzanie: KD0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1141/4481] Przetwarzanie: KD0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1142/4481] Przetwarzanie: KD0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1143/4481] Przetwarzanie: KD0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1144/4481] Przetwarzanie: KD0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1145/4481] Przetwarzanie: KD0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1146/4481] Przetwarzanie: KD0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1147/4481] Przetwarzanie: KD0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1148/4481] Przetwarzanie: KD0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1149/4481] Przetwarzanie: KD0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1150/4481] Przetwarzanie: KD0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151/4481] Przetwarzanie: KD0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1152/4481] Przetwarzanie: KD0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1153/4481] Przetwarzanie: KD0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1154/4481] Przetwarzanie: KD0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1155/4481] Przetwarzanie: KD0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1156/4481] Przetwarzanie: KD0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1157/4481] Przetwarzanie: KD0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1158/4481] Przetwarzanie: KD0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1159/4481] Przetwarzanie: KD0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.22it/s]\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1160/4481] Przetwarzanie: KD0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1161/4481] Przetwarzanie: KD0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:37:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1162/4481] Przetwarzanie: KD0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:37:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1163/4481] Przetwarzanie: KD0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:37:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1164/4481] Przetwarzanie: KD0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1165/4481] Przetwarzanie: KD0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1166/4481] Przetwarzanie: KD0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1167/4481] Przetwarzanie: KD0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1168/4481] Przetwarzanie: KD0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1169/4481] Przetwarzanie: KD0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1170/4481] Przetwarzanie: KD0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1171/4481] Przetwarzanie: KD0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1172/4481] Przetwarzanie: KD0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1173/4481] Przetwarzanie: KD0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1174/4481] Przetwarzanie: KD0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.66it/s]\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1175/4481] Przetwarzanie: KD0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1176/4481] Przetwarzanie: KD0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1177/4481] Przetwarzanie: KD0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1178/4481] Przetwarzanie: KD0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1179/4481] Przetwarzanie: KD0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1180/4481] Przetwarzanie: KD0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1181/4481] Przetwarzanie: KD0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1182/4481] Przetwarzanie: KD0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1183/4481] Przetwarzanie: KD0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1184/4481] Przetwarzanie: KD0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1185/4481] Przetwarzanie: KD0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1186/4481] Przetwarzanie: KD0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1187/4481] Przetwarzanie: KD0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1188/4481] Przetwarzanie: KD0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1189/4481] Przetwarzanie: KD0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1190/4481] Przetwarzanie: KD0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1191/4481] Przetwarzanie: KD0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1192/4481] Przetwarzanie: KD0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1193/4481] Przetwarzanie: KD0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1194/4481] Przetwarzanie: KD0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1195/4481] Przetwarzanie: KD0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1196/4481] Przetwarzanie: KD0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1197/4481] Przetwarzanie: KD0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1198/4481] Przetwarzanie: KD0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1199/4481] Przetwarzanie: KD0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200/4481] Przetwarzanie: KD0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1201/4481] Przetwarzanie: KD0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1202/4481] Przetwarzanie: KD0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1203/4481] Przetwarzanie: KD0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1204/4481] Przetwarzanie: KD0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1205/4481] Przetwarzanie: KD0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1206/4481] Przetwarzanie: KD0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1207/4481] Przetwarzanie: KD0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1208/4481] Przetwarzanie: KD0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1209/4481] Przetwarzanie: KD0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1210/4481] Przetwarzanie: KD0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1211/4481] Przetwarzanie: KD0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1212/4481] Przetwarzanie: KD0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1213/4481] Przetwarzanie: KD0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1214/4481] Przetwarzanie: KD0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.11it/s]\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1215/4481] Przetwarzanie: KD0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1216/4481] Przetwarzanie: KD0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1217/4481] Przetwarzanie: KD0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1218/4481] Przetwarzanie: KD0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1219/4481] Przetwarzanie: KD0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1220/4481] Przetwarzanie: KD0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1221/4481] Przetwarzanie: KD0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1222/4481] Przetwarzanie: KD0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1223/4481] Przetwarzanie: KD0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1224/4481] Przetwarzanie: KD0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1225/4481] Przetwarzanie: KD0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1226/4481] Przetwarzanie: KD0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1227/4481] Przetwarzanie: KD0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1228/4481] Przetwarzanie: KD0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.82it/s]\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1229/4481] Przetwarzanie: KD0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1230/4481] Przetwarzanie: KD0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1231/4481] Przetwarzanie: KD0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1232/4481] Przetwarzanie: KD0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1233/4481] Przetwarzanie: KD0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1234/4481] Przetwarzanie: KD0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1235/4481] Przetwarzanie: KD0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1236/4481] Przetwarzanie: KD0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1237/4481] Przetwarzanie: KD0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1238/4481] Przetwarzanie: KD0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1239/4481] Przetwarzanie: KD0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1240/4481] Przetwarzanie: KD0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1241/4481] Przetwarzanie: KD0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1242/4481] Przetwarzanie: KD0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1243/4481] Przetwarzanie: KD0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1244/4481] Przetwarzanie: KD0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1245/4481] Przetwarzanie: KD0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.67it/s]\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1246/4481] Przetwarzanie: KD0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1247/4481] Przetwarzanie: KD0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1248/4481] Przetwarzanie: KD0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1249/4481] Przetwarzanie: KD0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1250/4481] Przetwarzanie: KD0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1251/4481] Przetwarzanie: KD0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1252/4481] Przetwarzanie: KD0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1253/4481] Przetwarzanie: KD0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1254/4481] Przetwarzanie: KD0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1255/4481] Przetwarzanie: KD0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1256/4481] Przetwarzanie: KD0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1257/4481] Przetwarzanie: KD0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1258/4481] Przetwarzanie: KD0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1259/4481] Przetwarzanie: KD0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1260/4481] Przetwarzanie: KD0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.78it/s]\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1261/4481] Przetwarzanie: KD0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1262/4481] Przetwarzanie: KD0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1263/4481] Przetwarzanie: KD0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1264/4481] Przetwarzanie: KD0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.56it/s]\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1265/4481] Przetwarzanie: KD0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1266/4481] Przetwarzanie: KD0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:37:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1267/4481] Przetwarzanie: KD0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1268/4481] Przetwarzanie: KD0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1269/4481] Przetwarzanie: KD0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1270/4481] Przetwarzanie: KD0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1271/4481] Przetwarzanie: KD0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.79it/s]\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1272/4481] Przetwarzanie: KD0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1273/4481] Przetwarzanie: KD0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1274/4481] Przetwarzanie: KD0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1275/4481] Przetwarzanie: KD0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1276/4481] Przetwarzanie: KD0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1277/4481] Przetwarzanie: KD0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1278/4481] Przetwarzanie: KD0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1279/4481] Przetwarzanie: KD0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1280/4481] Przetwarzanie: KD0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1281/4481] Przetwarzanie: KD0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1282/4481] Przetwarzanie: KD0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1283/4481] Przetwarzanie: KD0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1284/4481] Przetwarzanie: KD0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1285/4481] Przetwarzanie: KD0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1286/4481] Przetwarzanie: KD0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1287/4481] Przetwarzanie: KD0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1288/4481] Przetwarzanie: KD0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1289/4481] Przetwarzanie: KD0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1290/4481] Przetwarzanie: KD0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1291/4481] Przetwarzanie: KD0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1292/4481] Przetwarzanie: KD0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1293/4481] Przetwarzanie: KD0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:37:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1294/4481] Przetwarzanie: KD0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1295/4481] Przetwarzanie: KD0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1296/4481] Przetwarzanie: KD0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1297/4481] Przetwarzanie: KD0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1298/4481] Przetwarzanie: KD0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1299/4481] Przetwarzanie: KD0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300/4481] Przetwarzanie: KD0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1301/4481] Przetwarzanie: KD0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1302/4481] Przetwarzanie: KD0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1303/4481] Przetwarzanie: KD0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1304/4481] Przetwarzanie: KD0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1305/4481] Przetwarzanie: KD0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1306/4481] Przetwarzanie: KD0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1307/4481] Przetwarzanie: KD0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1308/4481] Przetwarzanie: KD0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1309/4481] Przetwarzanie: KD0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1310/4481] Przetwarzanie: KD0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1311/4481] Przetwarzanie: KD0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1312/4481] Przetwarzanie: KD0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1313/4481] Przetwarzanie: KD0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1314/4481] Przetwarzanie: KD0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1315/4481] Przetwarzanie: KD0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1316/4481] Przetwarzanie: KD0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1317/4481] Przetwarzanie: KD0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1318/4481] Przetwarzanie: KD0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1319/4481] Przetwarzanie: KD0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1320/4481] Przetwarzanie: KD0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1321/4481] Przetwarzanie: KD0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1322/4481] Przetwarzanie: KD0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1323/4481] Przetwarzanie: KD0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1324/4481] Przetwarzanie: KD0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1325/4481] Przetwarzanie: KD0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1326/4481] Przetwarzanie: KD0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1327/4481] Przetwarzanie: KD0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1328/4481] Przetwarzanie: KD0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1329/4481] Przetwarzanie: KD0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1330/4481] Przetwarzanie: KD0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1331/4481] Przetwarzanie: KD0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.75it/s]\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1332/4481] Przetwarzanie: KD0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1333/4481] Przetwarzanie: KD0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1334/4481] Przetwarzanie: KD0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1335/4481] Przetwarzanie: KD0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1336/4481] Przetwarzanie: KD0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1337/4481] Przetwarzanie: KD0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.66it/s]\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1338/4481] Przetwarzanie: KD0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1339/4481] Przetwarzanie: KD0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1340/4481] Przetwarzanie: KD0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1341/4481] Przetwarzanie: KD0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.19it/s]\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1342/4481] Przetwarzanie: KD0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.67it/s]\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1343/4481] Przetwarzanie: KD0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1344/4481] Przetwarzanie: KD0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1345/4481] Przetwarzanie: KD0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1346/4481] Przetwarzanie: KD0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1347/4481] Przetwarzanie: KD0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1348/4481] Przetwarzanie: KD0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1349/4481] Przetwarzanie: KD0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1350/4481] Przetwarzanie: KD0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1351/4481] Przetwarzanie: KD0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1352/4481] Przetwarzanie: KD0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1353/4481] Przetwarzanie: KD0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1354/4481] Przetwarzanie: KD0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  9.19it/s]\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1355/4481] Przetwarzanie: KD0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1356/4481] Przetwarzanie: KD0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1357/4481] Przetwarzanie: KD0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1358/4481] Przetwarzanie: KD0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1359/4481] Przetwarzanie: KD0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1360/4481] Przetwarzanie: KD0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1361/4481] Przetwarzanie: KD0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1362/4481] Przetwarzanie: KD0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1363/4481] Przetwarzanie: KD0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1364/4481] Przetwarzanie: KD0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1365/4481] Przetwarzanie: KD0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1366/4481] Przetwarzanie: KD0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1367/4481] Przetwarzanie: KD0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1368/4481] Przetwarzanie: KD0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1369/4481] Przetwarzanie: KD0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1370/4481] Przetwarzanie: KD0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1371/4481] Przetwarzanie: KD0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1372/4481] Przetwarzanie: KD0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1373/4481] Przetwarzanie: KD0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1374/4481] Przetwarzanie: KD0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1375/4481] Przetwarzanie: KD0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1376/4481] Przetwarzanie: KD0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1377/4481] Przetwarzanie: KD0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1378/4481] Przetwarzanie: KD0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1379/4481] Przetwarzanie: KD0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1380/4481] Przetwarzanie: KD0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.39it/s]\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1381/4481] Przetwarzanie: KD0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1382/4481] Przetwarzanie: KD0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1383/4481] Przetwarzanie: KD0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1384/4481] Przetwarzanie: KD0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1385/4481] Przetwarzanie: KD0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1386/4481] Przetwarzanie: KD0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1387/4481] Przetwarzanie: KD0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1388/4481] Przetwarzanie: KD0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1389/4481] Przetwarzanie: KD0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1390/4481] Przetwarzanie: KD0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1391/4481] Przetwarzanie: KD0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1392/4481] Przetwarzanie: KD0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1393/4481] Przetwarzanie: KD0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1394/4481] Przetwarzanie: KD0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1395/4481] Przetwarzanie: KD0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1396/4481] Przetwarzanie: KD0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1397/4481] Przetwarzanie: KD0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1398/4481] Przetwarzanie: KD0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1399/4481] Przetwarzanie: KD0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.97it/s]\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400/4481] Przetwarzanie: KD0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1401/4481] Przetwarzanie: KD0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1402/4481] Przetwarzanie: KD0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1403/4481] Przetwarzanie: KD0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1404/4481] Przetwarzanie: KD0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1405/4481] Przetwarzanie: KD0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1406/4481] Przetwarzanie: KD0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1407/4481] Przetwarzanie: KD0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1408/4481] Przetwarzanie: KD0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1409/4481] Przetwarzanie: KD0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1410/4481] Przetwarzanie: KD0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1411/4481] Przetwarzanie: KD0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1412/4481] Przetwarzanie: KD0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1413/4481] Przetwarzanie: KD0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1414/4481] Przetwarzanie: KD0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1415/4481] Przetwarzanie: KD0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1416/4481] Przetwarzanie: KD0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1417/4481] Przetwarzanie: KD0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1418/4481] Przetwarzanie: KD0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1419/4481] Przetwarzanie: KD0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1420/4481] Przetwarzanie: KD0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1421/4481] Przetwarzanie: KD0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1422/4481] Przetwarzanie: KD0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1423/4481] Przetwarzanie: KD0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1424/4481] Przetwarzanie: KD0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1425/4481] Przetwarzanie: KD0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1426/4481] Przetwarzanie: KD0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1427/4481] Przetwarzanie: KD0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1428/4481] Przetwarzanie: KD0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1429/4481] Przetwarzanie: KD0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1430/4481] Przetwarzanie: KD0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1431/4481] Przetwarzanie: KD0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1432/4481] Przetwarzanie: KD0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1433/4481] Przetwarzanie: KD0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1434/4481] Przetwarzanie: KD0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1435/4481] Przetwarzanie: KD0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.79it/s]\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1436/4481] Przetwarzanie: KD0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1437/4481] Przetwarzanie: KD0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1438/4481] Przetwarzanie: KD0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1439/4481] Przetwarzanie: KD0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1440/4481] Przetwarzanie: KD0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1441/4481] Przetwarzanie: KD0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1442/4481] Przetwarzanie: KD0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1443/4481] Przetwarzanie: KD0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1444/4481] Przetwarzanie: KD0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.64it/s]\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1445/4481] Przetwarzanie: KD0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1446/4481] Przetwarzanie: KD0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1447/4481] Przetwarzanie: KD0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1448/4481] Przetwarzanie: KD0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1449/4481] Przetwarzanie: KD0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450/4481] Przetwarzanie: KD0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1451/4481] Przetwarzanie: KD0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.75it/s]\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1452/4481] Przetwarzanie: KD0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1453/4481] Przetwarzanie: KD0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.33it/s]\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1454/4481] Przetwarzanie: KD0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1455/4481] Przetwarzanie: KD0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1456/4481] Przetwarzanie: KD0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1457/4481] Przetwarzanie: KD0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1458/4481] Przetwarzanie: KD0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1459/4481] Przetwarzanie: KD0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1460/4481] Przetwarzanie: KD0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1461/4481] Przetwarzanie: KD0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1462/4481] Przetwarzanie: KD0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1463/4481] Przetwarzanie: KD0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1464/4481] Przetwarzanie: KD0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1465/4481] Przetwarzanie: KD0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1466/4481] Przetwarzanie: KD0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1467/4481] Przetwarzanie: KD0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1468/4481] Przetwarzanie: KD0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1469/4481] Przetwarzanie: KD0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1470/4481] Przetwarzanie: KD0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1471/4481] Przetwarzanie: KD0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1472/4481] Przetwarzanie: KD0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1473/4481] Przetwarzanie: KD0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1474/4481] Przetwarzanie: KD0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1475/4481] Przetwarzanie: KD0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1476/4481] Przetwarzanie: KD0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1477/4481] Przetwarzanie: KD0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478/4481] Przetwarzanie: KD0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1479/4481] Przetwarzanie: KD0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1480/4481] Przetwarzanie: KD0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1481/4481] Przetwarzanie: KD0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1482/4481] Przetwarzanie: KD0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1483/4481] Przetwarzanie: KD0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1484/4481] Przetwarzanie: KD0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.77it/s]\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1485/4481] Przetwarzanie: KD0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1486/4481] Przetwarzanie: KD0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1487/4481] Przetwarzanie: KD0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.32it/s]\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1488/4481] Przetwarzanie: KD0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1489/4481] Przetwarzanie: KD0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1490/4481] Przetwarzanie: KD0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1491/4481] Przetwarzanie: KD0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1492/4481] Przetwarzanie: KD0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493/4481] Przetwarzanie: KD0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1494/4481] Przetwarzanie: KD0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.10it/s]\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1495/4481] Przetwarzanie: KD0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1496/4481] Przetwarzanie: KD0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1497/4481] Przetwarzanie: KD0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1498/4481] Przetwarzanie: KD0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1499/4481] Przetwarzanie: KD0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500/4481] Przetwarzanie: KD0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1501/4481] Przetwarzanie: KD0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1502/4481] Przetwarzanie: KD0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1503/4481] Przetwarzanie: KD0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1504/4481] Przetwarzanie: KD0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1505/4481] Przetwarzanie: KD0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1506/4481] Przetwarzanie: KD0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1507/4481] Przetwarzanie: KD0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1508/4481] Przetwarzanie: KD0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1509/4481] Przetwarzanie: KD0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1510/4481] Przetwarzanie: KD0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1511/4481] Przetwarzanie: KD0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512/4481] Przetwarzanie: KD0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1513/4481] Przetwarzanie: KD0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1514/4481] Przetwarzanie: KD0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1515/4481] Przetwarzanie: KD0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1516/4481] Przetwarzanie: KD0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1517/4481] Przetwarzanie: KD0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1518/4481] Przetwarzanie: KD0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1519/4481] Przetwarzanie: KD0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1520/4481] Przetwarzanie: KD0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1521/4481] Przetwarzanie: KD0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1522/4481] Przetwarzanie: KD0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523/4481] Przetwarzanie: KD0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.06it/s]\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1524/4481] Przetwarzanie: KD0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1525/4481] Przetwarzanie: KD0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1526/4481] Przetwarzanie: KD0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1527/4481] Przetwarzanie: KD0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1528/4481] Przetwarzanie: KD0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1529/4481] Przetwarzanie: KD0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1530/4481] Przetwarzanie: KD0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.81it/s]\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1531/4481] Przetwarzanie: KD0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1532/4481] Przetwarzanie: KD0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1533/4481] Przetwarzanie: KD0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1534/4481] Przetwarzanie: KD0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.57it/s]\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1535/4481] Przetwarzanie: KD0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1536/4481] Przetwarzanie: KD0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1537/4481] Przetwarzanie: KD0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1538/4481] Przetwarzanie: KD0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1539/4481] Przetwarzanie: KD0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1540/4481] Przetwarzanie: KD0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1541/4481] Przetwarzanie: KD0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.27it/s]\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1542/4481] Przetwarzanie: KD0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.65it/s]\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1543/4481] Przetwarzanie: KD0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1544/4481] Przetwarzanie: KD0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1545/4481] Przetwarzanie: KD0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1546/4481] Przetwarzanie: KD0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1547/4481] Przetwarzanie: KD0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1548/4481] Przetwarzanie: KD0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1549/4481] Przetwarzanie: KD0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550/4481] Przetwarzanie: KD0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1551/4481] Przetwarzanie: KD0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1552/4481] Przetwarzanie: KD0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1553/4481] Przetwarzanie: KD0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1554/4481] Przetwarzanie: KD0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1555/4481] Przetwarzanie: KD0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1556/4481] Przetwarzanie: KD0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1557/4481] Przetwarzanie: KD0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1558/4481] Przetwarzanie: KD0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1559/4481] Przetwarzanie: KD0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1560/4481] Przetwarzanie: KD0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1561/4481] Przetwarzanie: KD0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1562/4481] Przetwarzanie: KD0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1563/4481] Przetwarzanie: KD0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1564/4481] Przetwarzanie: KD0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1565/4481] Przetwarzanie: KD0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1566/4481] Przetwarzanie: KD0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1567/4481] Przetwarzanie: KD0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1568/4481] Przetwarzanie: KD0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1569/4481] Przetwarzanie: KD0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1570/4481] Przetwarzanie: KD0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1571/4481] Przetwarzanie: KD0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1572/4481] Przetwarzanie: KD0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1573/4481] Przetwarzanie: KD0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1574/4481] Przetwarzanie: KD0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.78it/s]\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1575/4481] Przetwarzanie: KD0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1576/4481] Przetwarzanie: KD0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1577/4481] Przetwarzanie: KD0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1578/4481] Przetwarzanie: KD0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1579/4481] Przetwarzanie: KD0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1580/4481] Przetwarzanie: KD0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1581/4481] Przetwarzanie: KD0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1582/4481] Przetwarzanie: KD0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1583/4481] Przetwarzanie: KD0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1584/4481] Przetwarzanie: KD0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:38:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1585/4481] Przetwarzanie: KD0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1586/4481] Przetwarzanie: KD0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1587/4481] Przetwarzanie: KD0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1588/4481] Przetwarzanie: KD0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1589/4481] Przetwarzanie: KD0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1590/4481] Przetwarzanie: KD0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1591/4481] Przetwarzanie: KD0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1592/4481] Przetwarzanie: KD0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1593/4481] Przetwarzanie: KD0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.16it/s]\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1594/4481] Przetwarzanie: KD0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.56it/s]\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1595/4481] Przetwarzanie: KD0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1596/4481] Przetwarzanie: KD0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1597/4481] Przetwarzanie: KD0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1598/4481] Przetwarzanie: KD0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1599/4481] Przetwarzanie: KD0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600/4481] Przetwarzanie: KD0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1601/4481] Przetwarzanie: KD0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1602/4481] Przetwarzanie: KD0_surprised_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1603/4481] Przetwarzanie: KD0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1604/4481] Przetwarzanie: KD0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1605/4481] Przetwarzanie: KD0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1606/4481] Przetwarzanie: KD0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1607/4481] Przetwarzanie: KD0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1608/4481] Przetwarzanie: KD0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1609/4481] Przetwarzanie: KD0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1610/4481] Przetwarzanie: KD0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1611/4481] Przetwarzanie: KD0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1612/4481] Przetwarzanie: KD0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1613/4481] Przetwarzanie: KD0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.96it/s]\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1614/4481] Przetwarzanie: KD0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1615/4481] Przetwarzanie: KD0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1616/4481] Przetwarzanie: KD0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1617/4481] Przetwarzanie: KD0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1618/4481] Przetwarzanie: KD0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1619/4481] Przetwarzanie: KD0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1620/4481] Przetwarzanie: KS0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1621/4481] Przetwarzanie: KS0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1622/4481] Przetwarzanie: KS0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1623/4481] Przetwarzanie: KS0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1624/4481] Przetwarzanie: KS0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.61it/s]\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1625/4481] Przetwarzanie: KS0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1626/4481] Przetwarzanie: KS0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1627/4481] Przetwarzanie: KS0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1628/4481] Przetwarzanie: KS0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1629/4481] Przetwarzanie: KS0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1630/4481] Przetwarzanie: KS0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1631/4481] Przetwarzanie: KS0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1632/4481] Przetwarzanie: KS0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1633/4481] Przetwarzanie: KS0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1634/4481] Przetwarzanie: KS0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1635/4481] Przetwarzanie: KS0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1636/4481] Przetwarzanie: KS0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1637/4481] Przetwarzanie: KS0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1638/4481] Przetwarzanie: KS0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1639/4481] Przetwarzanie: KS0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1640/4481] Przetwarzanie: KS0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1641/4481] Przetwarzanie: KS0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1642/4481] Przetwarzanie: KS0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.79it/s]\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1643/4481] Przetwarzanie: KS0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1644/4481] Przetwarzanie: KS0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1645/4481] Przetwarzanie: KS0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1646/4481] Przetwarzanie: KS0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1647/4481] Przetwarzanie: KS0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1648/4481] Przetwarzanie: KS0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1649/4481] Przetwarzanie: KS0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1650/4481] Przetwarzanie: KS0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1651/4481] Przetwarzanie: KS0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1652/4481] Przetwarzanie: KS0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1653/4481] Przetwarzanie: KS0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.22it/s]\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1654/4481] Przetwarzanie: KS0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1655/4481] Przetwarzanie: KS0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1656/4481] Przetwarzanie: KS0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1657/4481] Przetwarzanie: KS0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1658/4481] Przetwarzanie: KS0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1659/4481] Przetwarzanie: KS0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1660/4481] Przetwarzanie: KS0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1661/4481] Przetwarzanie: KS0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1662/4481] Przetwarzanie: KS0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1663/4481] Przetwarzanie: KS0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1664/4481] Przetwarzanie: KS0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.79it/s]\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1665/4481] Przetwarzanie: KS0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1666/4481] Przetwarzanie: KS0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1667/4481] Przetwarzanie: KS0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1668/4481] Przetwarzanie: KS0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1669/4481] Przetwarzanie: KS0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1670/4481] Przetwarzanie: KS0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1671/4481] Przetwarzanie: KS0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1672/4481] Przetwarzanie: KS0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1673/4481] Przetwarzanie: KS0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1674/4481] Przetwarzanie: KS0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1675/4481] Przetwarzanie: KS0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1676/4481] Przetwarzanie: KS0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1677/4481] Przetwarzanie: KS0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1678/4481] Przetwarzanie: KS0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1679/4481] Przetwarzanie: KS0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.19it/s]\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1680/4481] Przetwarzanie: KS0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1681/4481] Przetwarzanie: KS0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1682/4481] Przetwarzanie: KS0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1683/4481] Przetwarzanie: KS0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1684/4481] Przetwarzanie: KS0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1685/4481] Przetwarzanie: KS0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1686/4481] Przetwarzanie: KS0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1687/4481] Przetwarzanie: KS0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1688/4481] Przetwarzanie: KS0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1689/4481] Przetwarzanie: KS0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1690/4481] Przetwarzanie: KS0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1691/4481] Przetwarzanie: KS0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1692/4481] Przetwarzanie: KS0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1693/4481] Przetwarzanie: KS0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1694/4481] Przetwarzanie: KS0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1695/4481] Przetwarzanie: KS0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1696/4481] Przetwarzanie: KS0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1697/4481] Przetwarzanie: KS0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.64it/s]\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1698/4481] Przetwarzanie: KS0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1699/4481] Przetwarzanie: KS0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700/4481] Przetwarzanie: KS0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1701/4481] Przetwarzanie: KS0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.76it/s]\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1702/4481] Przetwarzanie: KS0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1703/4481] Przetwarzanie: KS0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1704/4481] Przetwarzanie: KS0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1705/4481] Przetwarzanie: KS0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.75it/s]\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1706/4481] Przetwarzanie: KS0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1707/4481] Przetwarzanie: KS0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1708/4481] Przetwarzanie: KS0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1709/4481] Przetwarzanie: KS0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.93it/s]\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1710/4481] Przetwarzanie: KS0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.80it/s]\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1711/4481] Przetwarzanie: KS0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1712/4481] Przetwarzanie: KS0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1713/4481] Przetwarzanie: KS0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1714/4481] Przetwarzanie: KS0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.65it/s]\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1715/4481] Przetwarzanie: KS0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1716/4481] Przetwarzanie: KS0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1717/4481] Przetwarzanie: KS0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1718/4481] Przetwarzanie: KS0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1719/4481] Przetwarzanie: KS0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1720/4481] Przetwarzanie: KS0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1721/4481] Przetwarzanie: KS0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1722/4481] Przetwarzanie: KS0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1723/4481] Przetwarzanie: KS0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1724/4481] Przetwarzanie: KS0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1725/4481] Przetwarzanie: KS0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1726/4481] Przetwarzanie: KS0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1727/4481] Przetwarzanie: KS0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1728/4481] Przetwarzanie: KS0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1729/4481] Przetwarzanie: KS0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1730/4481] Przetwarzanie: KS0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1731/4481] Przetwarzanie: KS0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1732/4481] Przetwarzanie: KS0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.04it/s]\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1733/4481] Przetwarzanie: KS0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1734/4481] Przetwarzanie: KS0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1735/4481] Przetwarzanie: KS0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1736/4481] Przetwarzanie: KS0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1737/4481] Przetwarzanie: KS0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1738/4481] Przetwarzanie: KS0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1739/4481] Przetwarzanie: KS0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1740/4481] Przetwarzanie: KS0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1741/4481] Przetwarzanie: KS0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1742/4481] Przetwarzanie: KS0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1743/4481] Przetwarzanie: KS0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.13it/s]\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1744/4481] Przetwarzanie: KS0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1745/4481] Przetwarzanie: KS0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1746/4481] Przetwarzanie: KS0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.99it/s]\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1747/4481] Przetwarzanie: KS0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1748/4481] Przetwarzanie: KS0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1749/4481] Przetwarzanie: KS0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1750/4481] Przetwarzanie: KS0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1751/4481] Przetwarzanie: KS0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1752/4481] Przetwarzanie: KS0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1753/4481] Przetwarzanie: KS0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1754/4481] Przetwarzanie: KS0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1755/4481] Przetwarzanie: KS0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1756/4481] Przetwarzanie: KS0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.65it/s]\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1757/4481] Przetwarzanie: KS0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1758/4481] Przetwarzanie: KS0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1759/4481] Przetwarzanie: KS0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1760/4481] Przetwarzanie: KS0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1761/4481] Przetwarzanie: KS0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1762/4481] Przetwarzanie: KS0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1763/4481] Przetwarzanie: KS0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1764/4481] Przetwarzanie: KS0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1765/4481] Przetwarzanie: KS0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1766/4481] Przetwarzanie: KS0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767/4481] Przetwarzanie: KS0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1768/4481] Przetwarzanie: KS0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.70it/s]\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1769/4481] Przetwarzanie: KS0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1770/4481] Przetwarzanie: KS0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1771/4481] Przetwarzanie: KS0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1772/4481] Przetwarzanie: KS0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1773/4481] Przetwarzanie: KS0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1774/4481] Przetwarzanie: KS0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1775/4481] Przetwarzanie: KS0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1776/4481] Przetwarzanie: KS0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1777/4481] Przetwarzanie: KS0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1778/4481] Przetwarzanie: KS0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1779/4481] Przetwarzanie: KS0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1780/4481] Przetwarzanie: KS0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1781/4481] Przetwarzanie: KS0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1782/4481] Przetwarzanie: KS0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1783/4481] Przetwarzanie: KS0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1784/4481] Przetwarzanie: KS0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1785/4481] Przetwarzanie: KS0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1786/4481] Przetwarzanie: KS0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1787/4481] Przetwarzanie: KS0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1788/4481] Przetwarzanie: KS0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1789/4481] Przetwarzanie: KS0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1790/4481] Przetwarzanie: KS0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1791/4481] Przetwarzanie: KS0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1792/4481] Przetwarzanie: KS0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1793/4481] Przetwarzanie: KS0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.06it/s]\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1794/4481] Przetwarzanie: KS0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1795/4481] Przetwarzanie: KS0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1796/4481] Przetwarzanie: KS0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.92it/s]\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1797/4481] Przetwarzanie: KS0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1798/4481] Przetwarzanie: KS0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1799/4481] Przetwarzanie: KS0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800/4481] Przetwarzanie: KS0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.80it/s]\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1801/4481] Przetwarzanie: KS0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1802/4481] Przetwarzanie: KS0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1803/4481] Przetwarzanie: KS0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1804/4481] Przetwarzanie: KS0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.71it/s]\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1805/4481] Przetwarzanie: KS0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1806/4481] Przetwarzanie: KS0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1807/4481] Przetwarzanie: KS0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1808/4481] Przetwarzanie: KS0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1809/4481] Przetwarzanie: KS0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1810/4481] Przetwarzanie: KS0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1811/4481] Przetwarzanie: KS0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1812/4481] Przetwarzanie: KS0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1813/4481] Przetwarzanie: KS0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1814/4481] Przetwarzanie: KS0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1815/4481] Przetwarzanie: KS0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1816/4481] Przetwarzanie: KS0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1817/4481] Przetwarzanie: KS0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1818/4481] Przetwarzanie: KS0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1819/4481] Przetwarzanie: KS0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1820/4481] Przetwarzanie: KS0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1821/4481] Przetwarzanie: KS0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1822/4481] Przetwarzanie: KS0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1823/4481] Przetwarzanie: KS0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1824/4481] Przetwarzanie: KS0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1825/4481] Przetwarzanie: KS0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1826/4481] Przetwarzanie: KS0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1827/4481] Przetwarzanie: KS0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1828/4481] Przetwarzanie: KS0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1829/4481] Przetwarzanie: KS0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1830/4481] Przetwarzanie: KS0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1831/4481] Przetwarzanie: KS0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1832/4481] Przetwarzanie: KS0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1833/4481] Przetwarzanie: KS0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1834/4481] Przetwarzanie: KS0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1835/4481] Przetwarzanie: KS0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.37it/s]\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1836/4481] Przetwarzanie: KS0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1837/4481] Przetwarzanie: KS0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1838/4481] Przetwarzanie: KS0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1839/4481] Przetwarzanie: KS0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1840/4481] Przetwarzanie: KS0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1841/4481] Przetwarzanie: KS0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1842/4481] Przetwarzanie: KS0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1843/4481] Przetwarzanie: KS0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1844/4481] Przetwarzanie: KS0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.79it/s]\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1845/4481] Przetwarzanie: KS0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1846/4481] Przetwarzanie: KS0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1847/4481] Przetwarzanie: KS0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1848/4481] Przetwarzanie: KS0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.65it/s]\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1849/4481] Przetwarzanie: KS0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.98it/s]\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1850/4481] Przetwarzanie: KS0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1851/4481] Przetwarzanie: KS0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1852/4481] Przetwarzanie: KS0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1853/4481] Przetwarzanie: KS0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1854/4481] Przetwarzanie: KS0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1855/4481] Przetwarzanie: KS0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1856/4481] Przetwarzanie: KS0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1857/4481] Przetwarzanie: KS0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1858/4481] Przetwarzanie: KS0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1859/4481] Przetwarzanie: KS0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1860/4481] Przetwarzanie: KS0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.11it/s]\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1861/4481] Przetwarzanie: KS0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1862/4481] Przetwarzanie: KS0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1863/4481] Przetwarzanie: KS0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1864/4481] Przetwarzanie: KS0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.58it/s]\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1865/4481] Przetwarzanie: KS0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1866/4481] Przetwarzanie: KS0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1867/4481] Przetwarzanie: KS0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:39:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1868/4481] Przetwarzanie: KS0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1869/4481] Przetwarzanie: KS0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1870/4481] Przetwarzanie: KS0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.12it/s]\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1871/4481] Przetwarzanie: KS0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1872/4481] Przetwarzanie: KS0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1873/4481] Przetwarzanie: KS0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1874/4481] Przetwarzanie: KS0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.92it/s]\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:39:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1875/4481] Przetwarzanie: KS0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1876/4481] Przetwarzanie: KS0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1877/4481] Przetwarzanie: KS0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1878/4481] Przetwarzanie: KS0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1879/4481] Przetwarzanie: KS0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1880/4481] Przetwarzanie: KS0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1881/4481] Przetwarzanie: KS0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1882/4481] Przetwarzanie: KS0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1883/4481] Przetwarzanie: KS0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1884/4481] Przetwarzanie: KS0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.16it/s]\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1885/4481] Przetwarzanie: KS0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1886/4481] Przetwarzanie: KS0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1887/4481] Przetwarzanie: KS0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1888/4481] Przetwarzanie: KS0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1889/4481] Przetwarzanie: KS0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1890/4481] Przetwarzanie: KS0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.79it/s]\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1891/4481] Przetwarzanie: KS0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1892/4481] Przetwarzanie: KS0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1893/4481] Przetwarzanie: KS0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.98it/s]\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1894/4481] Przetwarzanie: KS0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.62it/s]\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1895/4481] Przetwarzanie: KS0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1896/4481] Przetwarzanie: KS0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1897/4481] Przetwarzanie: KS0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1898/4481] Przetwarzanie: KS0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1899/4481] Przetwarzanie: KS0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900/4481] Przetwarzanie: KS0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1901/4481] Przetwarzanie: KS0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1902/4481] Przetwarzanie: KS0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1903/4481] Przetwarzanie: KS0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.34it/s]\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1904/4481] Przetwarzanie: KS0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1905/4481] Przetwarzanie: KS0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1906/4481] Przetwarzanie: KS0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1907/4481] Przetwarzanie: KS0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.61it/s]\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1908/4481] Przetwarzanie: KS0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1909/4481] Przetwarzanie: KS0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.64it/s]\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1910/4481] Przetwarzanie: KS0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1911/4481] Przetwarzanie: KS0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1912/4481] Przetwarzanie: KS0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1913/4481] Przetwarzanie: KS0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1914/4481] Przetwarzanie: KS0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1915/4481] Przetwarzanie: KS0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1916/4481] Przetwarzanie: KS0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1917/4481] Przetwarzanie: KS0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1918/4481] Przetwarzanie: KS0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1919/4481] Przetwarzanie: KS0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1920/4481] Przetwarzanie: KS0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1921/4481] Przetwarzanie: KS0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1922/4481] Przetwarzanie: KS0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1923/4481] Przetwarzanie: KS0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1924/4481] Przetwarzanie: KS0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1925/4481] Przetwarzanie: KS0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.40it/s]\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1926/4481] Przetwarzanie: KS0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1927/4481] Przetwarzanie: KS0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1928/4481] Przetwarzanie: KS0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1929/4481] Przetwarzanie: KS0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1930/4481] Przetwarzanie: KS0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1931/4481] Przetwarzanie: KS0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1932/4481] Przetwarzanie: KS0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1933/4481] Przetwarzanie: KS0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1934/4481] Przetwarzanie: KS0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.27it/s]\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1935/4481] Przetwarzanie: KS0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1936/4481] Przetwarzanie: KS0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1937/4481] Przetwarzanie: KS0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1938/4481] Przetwarzanie: KS0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.36it/s]\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1939/4481] Przetwarzanie: KS0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.98it/s]\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1940/4481] Przetwarzanie: KS0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1941/4481] Przetwarzanie: KS0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1942/4481] Przetwarzanie: KS0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1943/4481] Przetwarzanie: KS0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1944/4481] Przetwarzanie: KS0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.92it/s]\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1945/4481] Przetwarzanie: KS0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1946/4481] Przetwarzanie: KS0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1947/4481] Przetwarzanie: KS0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1948/4481] Przetwarzanie: KS0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1949/4481] Przetwarzanie: KS0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1950/4481] Przetwarzanie: KS0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1951/4481] Przetwarzanie: KS0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1952/4481] Przetwarzanie: KS0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1953/4481] Przetwarzanie: KS0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1954/4481] Przetwarzanie: KS0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.59it/s]\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1955/4481] Przetwarzanie: KS0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1956/4481] Przetwarzanie: KS0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1957/4481] Przetwarzanie: KS0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1958/4481] Przetwarzanie: KS0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1959/4481] Przetwarzanie: KS0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1960/4481] Przetwarzanie: KS0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1961/4481] Przetwarzanie: KS0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1962/4481] Przetwarzanie: KS0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1963/4481] Przetwarzanie: KS0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1964/4481] Przetwarzanie: KS0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1965/4481] Przetwarzanie: KS0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1966/4481] Przetwarzanie: KS0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1967/4481] Przetwarzanie: KS0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1968/4481] Przetwarzanie: KS0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1969/4481] Przetwarzanie: KS0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1970/4481] Przetwarzanie: KS0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1971/4481] Przetwarzanie: KS0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1972/4481] Przetwarzanie: KS0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1973/4481] Przetwarzanie: KS0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1974/4481] Przetwarzanie: KS0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1975/4481] Przetwarzanie: KS0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1976/4481] Przetwarzanie: KS0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1977/4481] Przetwarzanie: KS0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1978/4481] Przetwarzanie: KS0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1979/4481] Przetwarzanie: KS0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1980/4481] Przetwarzanie: KS0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1981/4481] Przetwarzanie: KS0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1982/4481] Przetwarzanie: KS0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1983/4481] Przetwarzanie: KS0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1984/4481] Przetwarzanie: KS0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.73it/s]\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1985/4481] Przetwarzanie: KS0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1986/4481] Przetwarzanie: KS0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.37it/s]\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1987/4481] Przetwarzanie: KS0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1988/4481] Przetwarzanie: KS0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1989/4481] Przetwarzanie: KS0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1990/4481] Przetwarzanie: KS0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1991/4481] Przetwarzanie: KS0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1992/4481] Przetwarzanie: KS0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1993/4481] Przetwarzanie: KS0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1994/4481] Przetwarzanie: KS0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1995/4481] Przetwarzanie: KS0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1996/4481] Przetwarzanie: KS0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1997/4481] Przetwarzanie: KS0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1998/4481] Przetwarzanie: KS0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1999/4481] Przetwarzanie: KS0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000/4481] Przetwarzanie: KS0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2001/4481] Przetwarzanie: KS0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2002/4481] Przetwarzanie: KS0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2003/4481] Przetwarzanie: KS0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2004/4481] Przetwarzanie: KS0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005/4481] Przetwarzanie: KS0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006/4481] Przetwarzanie: KS0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007/4481] Przetwarzanie: KS0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2008/4481] Przetwarzanie: KS0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009/4481] Przetwarzanie: KS0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010/4481] Przetwarzanie: KS0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.38it/s]\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2011/4481] Przetwarzanie: KS0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2012/4481] Przetwarzanie: KS0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2013/4481] Przetwarzanie: KS0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2014/4481] Przetwarzanie: KS0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015/4481] Przetwarzanie: KS0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016/4481] Przetwarzanie: KS0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017/4481] Przetwarzanie: KS0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018/4481] Przetwarzanie: KS0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/4481] Przetwarzanie: KS0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020/4481] Przetwarzanie: KS0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/4481] Przetwarzanie: KS0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/4481] Przetwarzanie: KS0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/4481] Przetwarzanie: KS0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/4481] Przetwarzanie: KS0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/4481] Przetwarzanie: KS0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026/4481] Przetwarzanie: KS0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2027/4481] Przetwarzanie: KS0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2028/4481] Przetwarzanie: KS0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2029/4481] Przetwarzanie: KS0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2030/4481] Przetwarzanie: KS0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2031/4481] Przetwarzanie: KS0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2032/4481] Przetwarzanie: KS0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2033/4481] Przetwarzanie: KS0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2034/4481] Przetwarzanie: KS0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2035/4481] Przetwarzanie: KS0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2036/4481] Przetwarzanie: KS0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2037/4481] Przetwarzanie: KS0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2038/4481] Przetwarzanie: KS0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2039/4481] Przetwarzanie: KS0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2040/4481] Przetwarzanie: KS0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2041/4481] Przetwarzanie: KS0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2042/4481] Przetwarzanie: KS0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2043/4481] Przetwarzanie: KS0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2044/4481] Przetwarzanie: KS0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.55it/s]\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2045/4481] Przetwarzanie: KS0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2046/4481] Przetwarzanie: KS0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2047/4481] Przetwarzanie: KS0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048/4481] Przetwarzanie: KS0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2049/4481] Przetwarzanie: KS0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2050/4481] Przetwarzanie: KS0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2051/4481] Przetwarzanie: KS0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2052/4481] Przetwarzanie: KS0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2053/4481] Przetwarzanie: KS0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2054/4481] Przetwarzanie: KS0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2055/4481] Przetwarzanie: KS0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2056/4481] Przetwarzanie: KS0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2057/4481] Przetwarzanie: KS0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2058/4481] Przetwarzanie: KS0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2059/4481] Przetwarzanie: KS0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2060/4481] Przetwarzanie: KS0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2061/4481] Przetwarzanie: KS0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2062/4481] Przetwarzanie: KS0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2063/4481] Przetwarzanie: KS0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2064/4481] Przetwarzanie: KS0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2065/4481] Przetwarzanie: KS0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2066/4481] Przetwarzanie: KS0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2067/4481] Przetwarzanie: KS0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2068/4481] Przetwarzanie: KS0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2069/4481] Przetwarzanie: KS0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2070/4481] Przetwarzanie: KS0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2071/4481] Przetwarzanie: KS0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2072/4481] Przetwarzanie: KS0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2073/4481] Przetwarzanie: KS0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2074/4481] Przetwarzanie: KS0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.37it/s]\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2075/4481] Przetwarzanie: KS0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2076/4481] Przetwarzanie: KS0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2077/4481] Przetwarzanie: KS0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2078/4481] Przetwarzanie: KS0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2079/4481] Przetwarzanie: KS0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2080/4481] Przetwarzanie: KS0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2081/4481] Przetwarzanie: KS0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2082/4481] Przetwarzanie: KS0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2083/4481] Przetwarzanie: KS0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2084/4481] Przetwarzanie: KS0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2085/4481] Przetwarzanie: KS0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2086/4481] Przetwarzanie: KS0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2087/4481] Przetwarzanie: KS0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2088/4481] Przetwarzanie: KS0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2089/4481] Przetwarzanie: KS0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2090/4481] Przetwarzanie: KS0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2091/4481] Przetwarzanie: KS0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2092/4481] Przetwarzanie: KS0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.63it/s]\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2093/4481] Przetwarzanie: KS0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2094/4481] Przetwarzanie: KS0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2095/4481] Przetwarzanie: KS0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2096/4481] Przetwarzanie: KS0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2097/4481] Przetwarzanie: KS0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2098/4481] Przetwarzanie: KS0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2099/4481] Przetwarzanie: KS0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100/4481] Przetwarzanie: KS0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2101/4481] Przetwarzanie: KS0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2102/4481] Przetwarzanie: KS0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2103/4481] Przetwarzanie: KS0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2104/4481] Przetwarzanie: KS0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2105/4481] Przetwarzanie: KS0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2106/4481] Przetwarzanie: KS0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2107/4481] Przetwarzanie: KS0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2108/4481] Przetwarzanie: KS0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2109/4481] Przetwarzanie: KS0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2110/4481] Przetwarzanie: KS0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2111/4481] Przetwarzanie: KS0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2112/4481] Przetwarzanie: KS0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2113/4481] Przetwarzanie: KS0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2114/4481] Przetwarzanie: KS0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2115/4481] Przetwarzanie: KS0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2116/4481] Przetwarzanie: KS0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2117/4481] Przetwarzanie: KS0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2118/4481] Przetwarzanie: KS0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2119/4481] Przetwarzanie: KS0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.00it/s]\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2120/4481] Przetwarzanie: KS0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2121/4481] Przetwarzanie: KS0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2122/4481] Przetwarzanie: KS0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2123/4481] Przetwarzanie: KS0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2124/4481] Przetwarzanie: KS0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2125/4481] Przetwarzanie: KS0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2126/4481] Przetwarzanie: KS0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2127/4481] Przetwarzanie: KS0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2128/4481] Przetwarzanie: KS0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2129/4481] Przetwarzanie: KS0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2130/4481] Przetwarzanie: KS0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2131/4481] Przetwarzanie: KS0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2132/4481] Przetwarzanie: KS0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2133/4481] Przetwarzanie: KS0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2134/4481] Przetwarzanie: KS0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2135/4481] Przetwarzanie: KS0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2136/4481] Przetwarzanie: KS0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2137/4481] Przetwarzanie: KS0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2138/4481] Przetwarzanie: KS0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2139/4481] Przetwarzanie: KS0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2140/4481] Przetwarzanie: KS0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2141/4481] Przetwarzanie: KS0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2142/4481] Przetwarzanie: KS0_surprised_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2143/4481] Przetwarzanie: KS0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2144/4481] Przetwarzanie: KS0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2145/4481] Przetwarzanie: KS0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2146/4481] Przetwarzanie: KS0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2147/4481] Przetwarzanie: KS0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2148/4481] Przetwarzanie: KS0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2149/4481] Przetwarzanie: KS0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2150/4481] Przetwarzanie: KS0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2151/4481] Przetwarzanie: KS0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2152/4481] Przetwarzanie: KS0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2153/4481] Przetwarzanie: KS0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.09it/s]\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2154/4481] Przetwarzanie: KS0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2155/4481] Przetwarzanie: KS0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2156/4481] Przetwarzanie: KS0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2157/4481] Przetwarzanie: KS0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.23it/s]\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2158/4481] Przetwarzanie: KS0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2159/4481] Przetwarzanie: KS0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2160/4481] Przetwarzanie: MK0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2161/4481] Przetwarzanie: MK0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2162/4481] Przetwarzanie: MK0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.37it/s]\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2163/4481] Przetwarzanie: MK0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2164/4481] Przetwarzanie: MK0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.70it/s]\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2165/4481] Przetwarzanie: MK0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.40it/s]\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:40:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2166/4481] Przetwarzanie: MK0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2167/4481] Przetwarzanie: MK0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2168/4481] Przetwarzanie: MK0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2169/4481] Przetwarzanie: MK0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2170/4481] Przetwarzanie: MK0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.54it/s]\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2171/4481] Przetwarzanie: MK0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.26it/s]\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2172/4481] Przetwarzanie: MK0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2173/4481] Przetwarzanie: MK0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.55it/s]\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2174/4481] Przetwarzanie: MK0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2175/4481] Przetwarzanie: MK0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.37it/s]\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2176/4481] Przetwarzanie: MK0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2177/4481] Przetwarzanie: MK0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2178/4481] Przetwarzanie: MK0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2179/4481] Przetwarzanie: MK0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.35it/s]\n",
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2180/4481] Przetwarzanie: MK0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.37it/s]\n",
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2181/4481] Przetwarzanie: MK0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2182/4481] Przetwarzanie: MK0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2183/4481] Przetwarzanie: MK0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2184/4481] Przetwarzanie: MK0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.66it/s]\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2185/4481] Przetwarzanie: MK0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2186/4481] Przetwarzanie: MK0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.39it/s]\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2187/4481] Przetwarzanie: MK0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.65it/s]\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2188/4481] Przetwarzanie: MK0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2189/4481] Przetwarzanie: MK0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.98it/s]\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2190/4481] Przetwarzanie: MK0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2191/4481] Przetwarzanie: MK0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2192/4481] Przetwarzanie: MK0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2193/4481] Przetwarzanie: MK0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.28it/s]\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2194/4481] Przetwarzanie: MK0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2195/4481] Przetwarzanie: MK0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.81it/s]\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2196/4481] Przetwarzanie: MK0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2197/4481] Przetwarzanie: MK0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2198/4481] Przetwarzanie: MK0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2199/4481] Przetwarzanie: MK0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2200/4481] Przetwarzanie: MK0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2201/4481] Przetwarzanie: MK0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2202/4481] Przetwarzanie: MK0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.34it/s]\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2203/4481] Przetwarzanie: MK0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.55it/s]\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2204/4481] Przetwarzanie: MK0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2205/4481] Przetwarzanie: MK0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2206/4481] Przetwarzanie: MK0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2207/4481] Przetwarzanie: MK0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2208/4481] Przetwarzanie: MK0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.99it/s]\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2209/4481] Przetwarzanie: MK0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2210/4481] Przetwarzanie: MK0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2211/4481] Przetwarzanie: MK0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2212/4481] Przetwarzanie: MK0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2213/4481] Przetwarzanie: MK0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2214/4481] Przetwarzanie: MK0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2215/4481] Przetwarzanie: MK0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2216/4481] Przetwarzanie: MK0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2217/4481] Przetwarzanie: MK0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2218/4481] Przetwarzanie: MK0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2219/4481] Przetwarzanie: MK0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2220/4481] Przetwarzanie: MK0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2221/4481] Przetwarzanie: MK0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.56it/s]\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2222/4481] Przetwarzanie: MK0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2223/4481] Przetwarzanie: MK0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.77it/s]\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2224/4481] Przetwarzanie: MK0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.55it/s]\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2225/4481] Przetwarzanie: MK0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2226/4481] Przetwarzanie: MK0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2227/4481] Przetwarzanie: MK0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:41:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2228/4481] Przetwarzanie: MK0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2229/4481] Przetwarzanie: MK0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2230/4481] Przetwarzanie: MK0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2231/4481] Przetwarzanie: MK0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.58it/s]\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2232/4481] Przetwarzanie: MK0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2233/4481] Przetwarzanie: MK0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2234/4481] Przetwarzanie: MK0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2235/4481] Przetwarzanie: MK0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2236/4481] Przetwarzanie: MK0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2237/4481] Przetwarzanie: MK0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2238/4481] Przetwarzanie: MK0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2239/4481] Przetwarzanie: MK0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.58it/s]\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2240/4481] Przetwarzanie: MK0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2241/4481] Przetwarzanie: MK0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2242/4481] Przetwarzanie: MK0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2243/4481] Przetwarzanie: MK0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.15it/s]\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2244/4481] Przetwarzanie: MK0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.17it/s]\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2245/4481] Przetwarzanie: MK0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2246/4481] Przetwarzanie: MK0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2247/4481] Przetwarzanie: MK0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.16it/s]\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2248/4481] Przetwarzanie: MK0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2249/4481] Przetwarzanie: MK0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.04it/s]\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2250/4481] Przetwarzanie: MK0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2251/4481] Przetwarzanie: MK0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2252/4481] Przetwarzanie: MK0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.99it/s]\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2253/4481] Przetwarzanie: MK0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.99it/s]\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2254/4481] Przetwarzanie: MK0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.64it/s]\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2255/4481] Przetwarzanie: MK0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2256/4481] Przetwarzanie: MK0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2257/4481] Przetwarzanie: MK0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.64it/s]\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2258/4481] Przetwarzanie: MK0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2259/4481] Przetwarzanie: MK0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2260/4481] Przetwarzanie: MK0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2261/4481] Przetwarzanie: MK0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.78it/s]\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262/4481] Przetwarzanie: MK0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2263/4481] Przetwarzanie: MK0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2264/4481] Przetwarzanie: MK0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2265/4481] Przetwarzanie: MK0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.42it/s]\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2266/4481] Przetwarzanie: MK0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2267/4481] Przetwarzanie: MK0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2268/4481] Przetwarzanie: MK0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2269/4481] Przetwarzanie: MK0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2270/4481] Przetwarzanie: MK0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2271/4481] Przetwarzanie: MK0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2272/4481] Przetwarzanie: MK0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2273/4481] Przetwarzanie: MK0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2274/4481] Przetwarzanie: MK0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2275/4481] Przetwarzanie: MK0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2276/4481] Przetwarzanie: MK0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2277/4481] Przetwarzanie: MK0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2278/4481] Przetwarzanie: MK0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2279/4481] Przetwarzanie: MK0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2280/4481] Przetwarzanie: MK0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2281/4481] Przetwarzanie: MK0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2282/4481] Przetwarzanie: MK0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2283/4481] Przetwarzanie: MK0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.80it/s]\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2284/4481] Przetwarzanie: MK0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2285/4481] Przetwarzanie: MK0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.37it/s]\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2286/4481] Przetwarzanie: MK0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2287/4481] Przetwarzanie: MK0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2288/4481] Przetwarzanie: MK0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2289/4481] Przetwarzanie: MK0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2290/4481] Przetwarzanie: MK0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.44it/s]\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2291/4481] Przetwarzanie: MK0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2292/4481] Przetwarzanie: MK0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2293/4481] Przetwarzanie: MK0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2294/4481] Przetwarzanie: MK0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.38it/s]\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2295/4481] Przetwarzanie: MK0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2296/4481] Przetwarzanie: MK0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2297/4481] Przetwarzanie: MK0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2298/4481] Przetwarzanie: MK0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2299/4481] Przetwarzanie: MK0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2300/4481] Przetwarzanie: MK0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2301/4481] Przetwarzanie: MK0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2302/4481] Przetwarzanie: MK0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2303/4481] Przetwarzanie: MK0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2304/4481] Przetwarzanie: MK0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2305/4481] Przetwarzanie: MK0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2306/4481] Przetwarzanie: MK0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.62it/s]\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2307/4481] Przetwarzanie: MK0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.61it/s]\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2308/4481] Przetwarzanie: MK0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2309/4481] Przetwarzanie: MK0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2310/4481] Przetwarzanie: MK0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2311/4481] Przetwarzanie: MK0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2312/4481] Przetwarzanie: MK0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2313/4481] Przetwarzanie: MK0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2314/4481] Przetwarzanie: MK0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.57it/s]\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2315/4481] Przetwarzanie: MK0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2316/4481] Przetwarzanie: MK0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2317/4481] Przetwarzanie: MK0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2318/4481] Przetwarzanie: MK0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2319/4481] Przetwarzanie: MK0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2320/4481] Przetwarzanie: MK0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2321/4481] Przetwarzanie: MK0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2322/4481] Przetwarzanie: MK0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2323/4481] Przetwarzanie: MK0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2324/4481] Przetwarzanie: MK0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2325/4481] Przetwarzanie: MK0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2326/4481] Przetwarzanie: MK0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2327/4481] Przetwarzanie: MK0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.15it/s]\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2328/4481] Przetwarzanie: MK0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2329/4481] Przetwarzanie: MK0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.59it/s]\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2330/4481] Przetwarzanie: MK0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2331/4481] Przetwarzanie: MK0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2332/4481] Przetwarzanie: MK0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.92it/s]\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2333/4481] Przetwarzanie: MK0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2334/4481] Przetwarzanie: MK0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2335/4481] Przetwarzanie: MK0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2336/4481] Przetwarzanie: MK0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2337/4481] Przetwarzanie: MK0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.43it/s]\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2338/4481] Przetwarzanie: MK0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2339/4481] Przetwarzanie: MK0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2340/4481] Przetwarzanie: MK0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.78it/s]\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2341/4481] Przetwarzanie: MK0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2342/4481] Przetwarzanie: MK0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.99it/s]\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2343/4481] Przetwarzanie: MK0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2344/4481] Przetwarzanie: MK0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.67it/s]\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2345/4481] Przetwarzanie: MK0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2346/4481] Przetwarzanie: MK0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2347/4481] Przetwarzanie: MK0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2348/4481] Przetwarzanie: MK0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2349/4481] Przetwarzanie: MK0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2350/4481] Przetwarzanie: MK0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2351/4481] Przetwarzanie: MK0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2352/4481] Przetwarzanie: MK0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2353/4481] Przetwarzanie: MK0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2354/4481] Przetwarzanie: MK0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2355/4481] Przetwarzanie: MK0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2356/4481] Przetwarzanie: MK0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2357/4481] Przetwarzanie: MK0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2358/4481] Przetwarzanie: MK0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2359/4481] Przetwarzanie: MK0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2360/4481] Przetwarzanie: MK0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2361/4481] Przetwarzanie: MK0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2362/4481] Przetwarzanie: MK0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.14it/s]\n",
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2363/4481] Przetwarzanie: MK0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2364/4481] Przetwarzanie: MK0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2365/4481] Przetwarzanie: MK0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2366/4481] Przetwarzanie: MK0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2367/4481] Przetwarzanie: MK0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2368/4481] Przetwarzanie: MK0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2369/4481] Przetwarzanie: MK0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2370/4481] Przetwarzanie: MK0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2371/4481] Przetwarzanie: MK0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2372/4481] Przetwarzanie: MK0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2373/4481] Przetwarzanie: MK0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2374/4481] Przetwarzanie: MK0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2375/4481] Przetwarzanie: MK0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2376/4481] Przetwarzanie: MK0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2377/4481] Przetwarzanie: MK0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2378/4481] Przetwarzanie: MK0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2379/4481] Przetwarzanie: MK0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2380/4481] Przetwarzanie: MK0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2381/4481] Przetwarzanie: MK0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2382/4481] Przetwarzanie: MK0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2383/4481] Przetwarzanie: MK0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2384/4481] Przetwarzanie: MK0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2385/4481] Przetwarzanie: MK0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2386/4481] Przetwarzanie: MK0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2387/4481] Przetwarzanie: MK0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2388/4481] Przetwarzanie: MK0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2389/4481] Przetwarzanie: MK0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2390/4481] Przetwarzanie: MK0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2391/4481] Przetwarzanie: MK0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2392/4481] Przetwarzanie: MK0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2393/4481] Przetwarzanie: MK0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2394/4481] Przetwarzanie: MK0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2395/4481] Przetwarzanie: MK0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2396/4481] Przetwarzanie: MK0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2397/4481] Przetwarzanie: MK0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2398/4481] Przetwarzanie: MK0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2399/4481] Przetwarzanie: MK0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400/4481] Przetwarzanie: MK0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2401/4481] Przetwarzanie: MK0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2402/4481] Przetwarzanie: MK0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2403/4481] Przetwarzanie: MK0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2404/4481] Przetwarzanie: MK0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.33it/s]\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2405/4481] Przetwarzanie: MK0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2406/4481] Przetwarzanie: MK0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2407/4481] Przetwarzanie: MK0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.10it/s]\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2408/4481] Przetwarzanie: MK0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2409/4481] Przetwarzanie: MK0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2410/4481] Przetwarzanie: MK0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2411/4481] Przetwarzanie: MK0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2412/4481] Przetwarzanie: MK0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2413/4481] Przetwarzanie: MK0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2414/4481] Przetwarzanie: MK0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2415/4481] Przetwarzanie: MK0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2416/4481] Przetwarzanie: MK0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.30it/s]\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2417/4481] Przetwarzanie: MK0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2418/4481] Przetwarzanie: MK0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2419/4481] Przetwarzanie: MK0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2420/4481] Przetwarzanie: MK0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2421/4481] Przetwarzanie: MK0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2422/4481] Przetwarzanie: MK0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2423/4481] Przetwarzanie: MK0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.23it/s]\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2424/4481] Przetwarzanie: MK0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.16it/s]\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2425/4481] Przetwarzanie: MK0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2426/4481] Przetwarzanie: MK0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2427/4481] Przetwarzanie: MK0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2428/4481] Przetwarzanie: MK0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2429/4481] Przetwarzanie: MK0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2430/4481] Przetwarzanie: MK0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2431/4481] Przetwarzanie: MK0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2432/4481] Przetwarzanie: MK0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2433/4481] Przetwarzanie: MK0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2434/4481] Przetwarzanie: MK0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.61it/s]\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2435/4481] Przetwarzanie: MK0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2436/4481] Przetwarzanie: MK0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2437/4481] Przetwarzanie: MK0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2438/4481] Przetwarzanie: MK0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2439/4481] Przetwarzanie: MK0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2440/4481] Przetwarzanie: MK0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2441/4481] Przetwarzanie: MK0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2442/4481] Przetwarzanie: MK0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2443/4481] Przetwarzanie: MK0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2444/4481] Przetwarzanie: MK0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2445/4481] Przetwarzanie: MK0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2446/4481] Przetwarzanie: MK0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2447/4481] Przetwarzanie: MK0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.63it/s]\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2448/4481] Przetwarzanie: MK0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2449/4481] Przetwarzanie: MK0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2450/4481] Przetwarzanie: MK0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2451/4481] Przetwarzanie: MK0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2452/4481] Przetwarzanie: MK0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.61it/s]\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2453/4481] Przetwarzanie: MK0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2454/4481] Przetwarzanie: MK0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2455/4481] Przetwarzanie: MK0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2456/4481] Przetwarzanie: MK0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2457/4481] Przetwarzanie: MK0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2458/4481] Przetwarzanie: MK0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2459/4481] Przetwarzanie: MK0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2460/4481] Przetwarzanie: MK0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:41:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2461/4481] Przetwarzanie: MK0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2462/4481] Przetwarzanie: MK0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2463/4481] Przetwarzanie: MK0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2464/4481] Przetwarzanie: MK0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2465/4481] Przetwarzanie: MK0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2466/4481] Przetwarzanie: MK0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2467/4481] Przetwarzanie: MK0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2468/4481] Przetwarzanie: MK0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2469/4481] Przetwarzanie: MK0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2470/4481] Przetwarzanie: MK0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2471/4481] Przetwarzanie: MK0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2472/4481] Przetwarzanie: MK0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2473/4481] Przetwarzanie: MK0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2474/4481] Przetwarzanie: MK0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.12it/s]\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2475/4481] Przetwarzanie: MK0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2476/4481] Przetwarzanie: MK0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2477/4481] Przetwarzanie: MK0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2478/4481] Przetwarzanie: MK0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2479/4481] Przetwarzanie: MK0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2480/4481] Przetwarzanie: MK0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2481/4481] Przetwarzanie: MK0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2482/4481] Przetwarzanie: MK0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2483/4481] Przetwarzanie: MK0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.74it/s]\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2484/4481] Przetwarzanie: MK0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2485/4481] Przetwarzanie: MK0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2486/4481] Przetwarzanie: MK0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2487/4481] Przetwarzanie: MK0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2488/4481] Przetwarzanie: MK0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2489/4481] Przetwarzanie: MK0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2490/4481] Przetwarzanie: MK0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2491/4481] Przetwarzanie: MK0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2492/4481] Przetwarzanie: MK0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2493/4481] Przetwarzanie: MK0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2494/4481] Przetwarzanie: MK0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2495/4481] Przetwarzanie: MK0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2496/4481] Przetwarzanie: MK0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2497/4481] Przetwarzanie: MK0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2498/4481] Przetwarzanie: MK0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2499/4481] Przetwarzanie: MK0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500/4481] Przetwarzanie: MK0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.17it/s]\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2501/4481] Przetwarzanie: MK0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2502/4481] Przetwarzanie: MK0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2503/4481] Przetwarzanie: MK0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2504/4481] Przetwarzanie: MK0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2505/4481] Przetwarzanie: MK0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2506/4481] Przetwarzanie: MK0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2507/4481] Przetwarzanie: MK0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2508/4481] Przetwarzanie: MK0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2509/4481] Przetwarzanie: MK0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2510/4481] Przetwarzanie: MK0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2511/4481] Przetwarzanie: MK0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2512/4481] Przetwarzanie: MK0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2513/4481] Przetwarzanie: MK0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2514/4481] Przetwarzanie: MK0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2515/4481] Przetwarzanie: MK0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2516/4481] Przetwarzanie: MK0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.97it/s]\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2517/4481] Przetwarzanie: MK0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2518/4481] Przetwarzanie: MK0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2519/4481] Przetwarzanie: MK0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.97it/s]\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2520/4481] Przetwarzanie: MK0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2521/4481] Przetwarzanie: MK0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2522/4481] Przetwarzanie: MK0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2523/4481] Przetwarzanie: MK0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2524/4481] Przetwarzanie: MK0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.55it/s]\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2525/4481] Przetwarzanie: MK0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.97it/s]\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2526/4481] Przetwarzanie: MK0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.14it/s]\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2527/4481] Przetwarzanie: MK0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2528/4481] Przetwarzanie: MK0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2529/4481] Przetwarzanie: MK0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2530/4481] Przetwarzanie: MK0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2531/4481] Przetwarzanie: MK0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2532/4481] Przetwarzanie: MK0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2533/4481] Przetwarzanie: MK0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2534/4481] Przetwarzanie: MK0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2535/4481] Przetwarzanie: MK0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.18it/s]\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2536/4481] Przetwarzanie: MK0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.82it/s]\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2537/4481] Przetwarzanie: MK0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2538/4481] Przetwarzanie: MK0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2539/4481] Przetwarzanie: MK0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2540/4481] Przetwarzanie: MK0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2541/4481] Przetwarzanie: MK0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2542/4481] Przetwarzanie: MK0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2543/4481] Przetwarzanie: MK0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2544/4481] Przetwarzanie: MK0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.43it/s]\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2545/4481] Przetwarzanie: MK0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2546/4481] Przetwarzanie: MK0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2547/4481] Przetwarzanie: MK0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2548/4481] Przetwarzanie: MK0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2549/4481] Przetwarzanie: MK0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2550/4481] Przetwarzanie: MK0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2551/4481] Przetwarzanie: MK0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2552/4481] Przetwarzanie: MK0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2553/4481] Przetwarzanie: MK0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.22it/s]\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2554/4481] Przetwarzanie: MK0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2555/4481] Przetwarzanie: MK0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2556/4481] Przetwarzanie: MK0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2557/4481] Przetwarzanie: MK0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2558/4481] Przetwarzanie: MK0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2559/4481] Przetwarzanie: MK0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2560/4481] Przetwarzanie: MK0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2561/4481] Przetwarzanie: MK0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2562/4481] Przetwarzanie: MK0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2563/4481] Przetwarzanie: MK0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2564/4481] Przetwarzanie: MK0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.10it/s]\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2565/4481] Przetwarzanie: MK0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2566/4481] Przetwarzanie: MK0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2567/4481] Przetwarzanie: MK0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2568/4481] Przetwarzanie: MK0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2569/4481] Przetwarzanie: MK0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2570/4481] Przetwarzanie: MK0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2571/4481] Przetwarzanie: MK0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2572/4481] Przetwarzanie: MK0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2573/4481] Przetwarzanie: MK0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2574/4481] Przetwarzanie: MK0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2575/4481] Przetwarzanie: MK0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2576/4481] Przetwarzanie: MK0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2577/4481] Przetwarzanie: MK0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2578/4481] Przetwarzanie: MK0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2579/4481] Przetwarzanie: MK0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2580/4481] Przetwarzanie: MK0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2581/4481] Przetwarzanie: MK0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2582/4481] Przetwarzanie: MK0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2583/4481] Przetwarzanie: MK0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2584/4481] Przetwarzanie: MK0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2585/4481] Przetwarzanie: MK0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2586/4481] Przetwarzanie: MK0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2587/4481] Przetwarzanie: MK0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2588/4481] Przetwarzanie: MK0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2589/4481] Przetwarzanie: MK0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2590/4481] Przetwarzanie: MK0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2591/4481] Przetwarzanie: MK0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2592/4481] Przetwarzanie: MK0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2593/4481] Przetwarzanie: MK0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2594/4481] Przetwarzanie: MK0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2595/4481] Przetwarzanie: MK0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2596/4481] Przetwarzanie: MK0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2597/4481] Przetwarzanie: MK0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2598/4481] Przetwarzanie: MK0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2599/4481] Przetwarzanie: MK0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2600/4481] Przetwarzanie: MK0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2601/4481] Przetwarzanie: MK0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2602/4481] Przetwarzanie: MK0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2603/4481] Przetwarzanie: MK0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.09it/s]\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2604/4481] Przetwarzanie: MK0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2605/4481] Przetwarzanie: MK0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.16it/s]\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2606/4481] Przetwarzanie: MK0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2607/4481] Przetwarzanie: MK0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2608/4481] Przetwarzanie: MK0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2609/4481] Przetwarzanie: MK0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2610/4481] Przetwarzanie: MP0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2611/4481] Przetwarzanie: MP0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2612/4481] Przetwarzanie: MP0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2613/4481] Przetwarzanie: MP0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2614/4481] Przetwarzanie: MP0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2615/4481] Przetwarzanie: MP0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.45it/s]\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2616/4481] Przetwarzanie: MP0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2617/4481] Przetwarzanie: MP0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2618/4481] Przetwarzanie: MP0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619/4481] Przetwarzanie: MP0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2620/4481] Przetwarzanie: MP0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2621/4481] Przetwarzanie: MP0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2622/4481] Przetwarzanie: MP0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2623/4481] Przetwarzanie: MP0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.57it/s]\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2624/4481] Przetwarzanie: MP0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2625/4481] Przetwarzanie: MP0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2626/4481] Przetwarzanie: MP0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2627/4481] Przetwarzanie: MP0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2628/4481] Przetwarzanie: MP0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.62it/s]\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2629/4481] Przetwarzanie: MP0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2630/4481] Przetwarzanie: MP0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2631/4481] Przetwarzanie: MP0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.35it/s]\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2632/4481] Przetwarzanie: MP0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2633/4481] Przetwarzanie: MP0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2634/4481] Przetwarzanie: MP0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2635/4481] Przetwarzanie: MP0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2636/4481] Przetwarzanie: MP0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2637/4481] Przetwarzanie: MP0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2638/4481] Przetwarzanie: MP0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2639/4481] Przetwarzanie: MP0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2640/4481] Przetwarzanie: MP0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2641/4481] Przetwarzanie: MP0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2642/4481] Przetwarzanie: MP0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2643/4481] Przetwarzanie: MP0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2644/4481] Przetwarzanie: MP0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2645/4481] Przetwarzanie: MP0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2646/4481] Przetwarzanie: MP0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.04it/s]\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2647/4481] Przetwarzanie: MP0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2648/4481] Przetwarzanie: MP0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2649/4481] Przetwarzanie: MP0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2650/4481] Przetwarzanie: MP0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2651/4481] Przetwarzanie: MP0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2652/4481] Przetwarzanie: MP0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2653/4481] Przetwarzanie: MP0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.78it/s]\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2654/4481] Przetwarzanie: MP0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2655/4481] Przetwarzanie: MP0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2656/4481] Przetwarzanie: MP0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2657/4481] Przetwarzanie: MP0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2658/4481] Przetwarzanie: MP0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2659/4481] Przetwarzanie: MP0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2660/4481] Przetwarzanie: MP0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.75it/s]\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2661/4481] Przetwarzanie: MP0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2662/4481] Przetwarzanie: MP0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2663/4481] Przetwarzanie: MP0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2664/4481] Przetwarzanie: MP0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2665/4481] Przetwarzanie: MP0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2666/4481] Przetwarzanie: MP0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2667/4481] Przetwarzanie: MP0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2668/4481] Przetwarzanie: MP0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2669/4481] Przetwarzanie: MP0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2670/4481] Przetwarzanie: MP0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.28it/s]\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2671/4481] Przetwarzanie: MP0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2672/4481] Przetwarzanie: MP0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.25it/s]\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2673/4481] Przetwarzanie: MP0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2674/4481] Przetwarzanie: MP0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2675/4481] Przetwarzanie: MP0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.36it/s]\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2676/4481] Przetwarzanie: MP0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2677/4481] Przetwarzanie: MP0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2678/4481] Przetwarzanie: MP0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2679/4481] Przetwarzanie: MP0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2680/4481] Przetwarzanie: MP0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2681/4481] Przetwarzanie: MP0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2682/4481] Przetwarzanie: MP0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.34it/s]\n",
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2683/4481] Przetwarzanie: MP0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2684/4481] Przetwarzanie: MP0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2685/4481] Przetwarzanie: MP0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.22it/s]\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2686/4481] Przetwarzanie: MP0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2687/4481] Przetwarzanie: MP0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2688/4481] Przetwarzanie: MP0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2689/4481] Przetwarzanie: MP0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2690/4481] Przetwarzanie: MP0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2691/4481] Przetwarzanie: MP0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2692/4481] Przetwarzanie: MP0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2693/4481] Przetwarzanie: MP0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2694/4481] Przetwarzanie: MP0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2695/4481] Przetwarzanie: MP0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2696/4481] Przetwarzanie: MP0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2697/4481] Przetwarzanie: MP0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2698/4481] Przetwarzanie: MP0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2699/4481] Przetwarzanie: MP0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2700/4481] Przetwarzanie: MP0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2701/4481] Przetwarzanie: MP0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2702/4481] Przetwarzanie: MP0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2703/4481] Przetwarzanie: MP0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2704/4481] Przetwarzanie: MP0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2705/4481] Przetwarzanie: MP0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2706/4481] Przetwarzanie: MP0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2707/4481] Przetwarzanie: MP0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2708/4481] Przetwarzanie: MP0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2709/4481] Przetwarzanie: MP0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2710/4481] Przetwarzanie: MP0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2711/4481] Przetwarzanie: MP0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2712/4481] Przetwarzanie: MP0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2713/4481] Przetwarzanie: MP0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2714/4481] Przetwarzanie: MP0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2715/4481] Przetwarzanie: MP0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:42:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2716/4481] Przetwarzanie: MP0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2717/4481] Przetwarzanie: MP0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2718/4481] Przetwarzanie: MP0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2719/4481] Przetwarzanie: MP0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2720/4481] Przetwarzanie: MP0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2721/4481] Przetwarzanie: MP0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2722/4481] Przetwarzanie: MP0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2723/4481] Przetwarzanie: MP0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2724/4481] Przetwarzanie: MP0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2725/4481] Przetwarzanie: MP0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2726/4481] Przetwarzanie: MP0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2727/4481] Przetwarzanie: MP0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2728/4481] Przetwarzanie: MP0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2729/4481] Przetwarzanie: MP0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2730/4481] Przetwarzanie: MP0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2731/4481] Przetwarzanie: MP0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2732/4481] Przetwarzanie: MP0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2733/4481] Przetwarzanie: MP0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2734/4481] Przetwarzanie: MP0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2735/4481] Przetwarzanie: MP0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2736/4481] Przetwarzanie: MP0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2737/4481] Przetwarzanie: MP0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2738/4481] Przetwarzanie: MP0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2739/4481] Przetwarzanie: MP0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2740/4481] Przetwarzanie: MP0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2741/4481] Przetwarzanie: MP0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2742/4481] Przetwarzanie: MP0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2743/4481] Przetwarzanie: MP0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2744/4481] Przetwarzanie: MP0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2745/4481] Przetwarzanie: MP0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746/4481] Przetwarzanie: MP0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2747/4481] Przetwarzanie: MP0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2748/4481] Przetwarzanie: MP0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2749/4481] Przetwarzanie: MP0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.37it/s]\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2750/4481] Przetwarzanie: MP0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2751/4481] Przetwarzanie: MP0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2752/4481] Przetwarzanie: MP0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2753/4481] Przetwarzanie: MP0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2754/4481] Przetwarzanie: MP0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2755/4481] Przetwarzanie: MP0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2756/4481] Przetwarzanie: MP0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2757/4481] Przetwarzanie: MP0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2758/4481] Przetwarzanie: MP0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:42:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2759/4481] Przetwarzanie: MP0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2760/4481] Przetwarzanie: MP0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2761/4481] Przetwarzanie: MP0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2762/4481] Przetwarzanie: MP0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2763/4481] Przetwarzanie: MP0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2764/4481] Przetwarzanie: MP0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2765/4481] Przetwarzanie: MP0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2766/4481] Przetwarzanie: MP0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.00it/s]\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2767/4481] Przetwarzanie: MP0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:43:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2768/4481] Przetwarzanie: MP0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2769/4481] Przetwarzanie: MP0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.09it/s]\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2770/4481] Przetwarzanie: MP0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2771/4481] Przetwarzanie: MP0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2772/4481] Przetwarzanie: MP0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2773/4481] Przetwarzanie: MP0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.36it/s]\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2774/4481] Przetwarzanie: MP0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2775/4481] Przetwarzanie: MP0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.91it/s]\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2776/4481] Przetwarzanie: MP0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2777/4481] Przetwarzanie: MP0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2778/4481] Przetwarzanie: MP0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2779/4481] Przetwarzanie: MP0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2780/4481] Przetwarzanie: MP0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2781/4481] Przetwarzanie: MP0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.13it/s]\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2782/4481] Przetwarzanie: MP0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2783/4481] Przetwarzanie: MP0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2784/4481] Przetwarzanie: MP0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2785/4481] Przetwarzanie: MP0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2786/4481] Przetwarzanie: MP0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2787/4481] Przetwarzanie: MP0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2788/4481] Przetwarzanie: MP0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2789/4481] Przetwarzanie: MP0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2790/4481] Przetwarzanie: MP0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2791/4481] Przetwarzanie: MP0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.63it/s]\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2792/4481] Przetwarzanie: MP0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2793/4481] Przetwarzanie: MP0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2794/4481] Przetwarzanie: MP0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2795/4481] Przetwarzanie: MP0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2796/4481] Przetwarzanie: MP0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2797/4481] Przetwarzanie: MP0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2798/4481] Przetwarzanie: MP0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2799/4481] Przetwarzanie: MP0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800/4481] Przetwarzanie: MP0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2801/4481] Przetwarzanie: MP0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2802/4481] Przetwarzanie: MP0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2803/4481] Przetwarzanie: MP0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2804/4481] Przetwarzanie: MP0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2805/4481] Przetwarzanie: MP0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2806/4481] Przetwarzanie: MP0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2807/4481] Przetwarzanie: MP0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2808/4481] Przetwarzanie: MP0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2809/4481] Przetwarzanie: MP0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2810/4481] Przetwarzanie: MP0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2811/4481] Przetwarzanie: MP0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.38it/s]\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2812/4481] Przetwarzanie: MP0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2813/4481] Przetwarzanie: MP0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2814/4481] Przetwarzanie: MP0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2815/4481] Przetwarzanie: MP0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2816/4481] Przetwarzanie: MP0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2817/4481] Przetwarzanie: MP0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.66it/s]\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2818/4481] Przetwarzanie: MP0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2819/4481] Przetwarzanie: MP0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2820/4481] Przetwarzanie: MP0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.91it/s]\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2821/4481] Przetwarzanie: MP0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2822/4481] Przetwarzanie: MP0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2823/4481] Przetwarzanie: MP0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.35it/s]\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2824/4481] Przetwarzanie: MP0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2825/4481] Przetwarzanie: MP0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2826/4481] Przetwarzanie: MP0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2827/4481] Przetwarzanie: MP0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2828/4481] Przetwarzanie: MP0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2829/4481] Przetwarzanie: MP0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.33it/s]\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2830/4481] Przetwarzanie: MP0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2831/4481] Przetwarzanie: MP0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2832/4481] Przetwarzanie: MP0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2833/4481] Przetwarzanie: MP0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2834/4481] Przetwarzanie: MP0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2835/4481] Przetwarzanie: MP0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2836/4481] Przetwarzanie: MP0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2837/4481] Przetwarzanie: MP0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2838/4481] Przetwarzanie: MP0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2839/4481] Przetwarzanie: MP0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2840/4481] Przetwarzanie: MP0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2841/4481] Przetwarzanie: MP0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2842/4481] Przetwarzanie: MP0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2843/4481] Przetwarzanie: MP0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2844/4481] Przetwarzanie: MP0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2845/4481] Przetwarzanie: MP0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2846/4481] Przetwarzanie: MP0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2847/4481] Przetwarzanie: MP0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2848/4481] Przetwarzanie: MP0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2849/4481] Przetwarzanie: MP0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2850/4481] Przetwarzanie: MP0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.96it/s]\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2851/4481] Przetwarzanie: MP0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2852/4481] Przetwarzanie: MP0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2853/4481] Przetwarzanie: MP0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2854/4481] Przetwarzanie: MP0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2855/4481] Przetwarzanie: MP0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2856/4481] Przetwarzanie: MP0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2857/4481] Przetwarzanie: MP0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2858/4481] Przetwarzanie: MP0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2859/4481] Przetwarzanie: MP0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2860/4481] Przetwarzanie: MP0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2861/4481] Przetwarzanie: MP0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2862/4481] Przetwarzanie: MP0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2863/4481] Przetwarzanie: MP0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.07it/s]\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2864/4481] Przetwarzanie: MP0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2865/4481] Przetwarzanie: MP0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.79it/s]\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2866/4481] Przetwarzanie: SM0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2867/4481] Przetwarzanie: SM0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2868/4481] Przetwarzanie: SM0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2869/4481] Przetwarzanie: SM0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2870/4481] Przetwarzanie: SM0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.73it/s]\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2871/4481] Przetwarzanie: SM0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2872/4481] Przetwarzanie: SM0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2873/4481] Przetwarzanie: SM0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2874/4481] Przetwarzanie: SM0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2875/4481] Przetwarzanie: SM0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2876/4481] Przetwarzanie: SM0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2877/4481] Przetwarzanie: SM0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2878/4481] Przetwarzanie: SM0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2879/4481] Przetwarzanie: SM0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2880/4481] Przetwarzanie: SM0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2881/4481] Przetwarzanie: SM0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2882/4481] Przetwarzanie: SM0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2883/4481] Przetwarzanie: SM0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2884/4481] Przetwarzanie: SM0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2885/4481] Przetwarzanie: SM0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2886/4481] Przetwarzanie: SM0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2887/4481] Przetwarzanie: SM0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2888/4481] Przetwarzanie: SM0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2889/4481] Przetwarzanie: SM0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2890/4481] Przetwarzanie: SM0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2891/4481] Przetwarzanie: SM0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2892/4481] Przetwarzanie: SM0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2893/4481] Przetwarzanie: SM0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2894/4481] Przetwarzanie: SM0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2895/4481] Przetwarzanie: SM0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2896/4481] Przetwarzanie: SM0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2897/4481] Przetwarzanie: SM0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2898/4481] Przetwarzanie: SM0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2899/4481] Przetwarzanie: SM0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2900/4481] Przetwarzanie: SM0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2901/4481] Przetwarzanie: SM0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2902/4481] Przetwarzanie: SM0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2903/4481] Przetwarzanie: SM0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2904/4481] Przetwarzanie: SM0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2905/4481] Przetwarzanie: SM0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2906/4481] Przetwarzanie: SM0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2907/4481] Przetwarzanie: SM0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2908/4481] Przetwarzanie: SM0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2909/4481] Przetwarzanie: SM0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2910/4481] Przetwarzanie: SM0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.79it/s]\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2911/4481] Przetwarzanie: SM0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2912/4481] Przetwarzanie: SM0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2913/4481] Przetwarzanie: SM0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2914/4481] Przetwarzanie: SM0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2915/4481] Przetwarzanie: SM0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2916/4481] Przetwarzanie: SM0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2917/4481] Przetwarzanie: SM0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2918/4481] Przetwarzanie: SM0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2919/4481] Przetwarzanie: SM0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2920/4481] Przetwarzanie: SM0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2921/4481] Przetwarzanie: SM0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2922/4481] Przetwarzanie: SM0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2923/4481] Przetwarzanie: SM0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2924/4481] Przetwarzanie: SM0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2925/4481] Przetwarzanie: SM0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2926/4481] Przetwarzanie: SM0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2927/4481] Przetwarzanie: SM0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2928/4481] Przetwarzanie: SM0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2929/4481] Przetwarzanie: SM0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2930/4481] Przetwarzanie: SM0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2931/4481] Przetwarzanie: SM0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2932/4481] Przetwarzanie: SM0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2933/4481] Przetwarzanie: SM0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2934/4481] Przetwarzanie: SM0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2935/4481] Przetwarzanie: SM0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2936/4481] Przetwarzanie: SM0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2937/4481] Przetwarzanie: SM0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2938/4481] Przetwarzanie: SM0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2939/4481] Przetwarzanie: SM0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2940/4481] Przetwarzanie: SM0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2941/4481] Przetwarzanie: SM0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2942/4481] Przetwarzanie: SM0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2943/4481] Przetwarzanie: SM0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.39it/s]\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2944/4481] Przetwarzanie: SM0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2945/4481] Przetwarzanie: SM0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2946/4481] Przetwarzanie: SM0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2947/4481] Przetwarzanie: SM0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2948/4481] Przetwarzanie: SM0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2949/4481] Przetwarzanie: SM0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2950/4481] Przetwarzanie: SM0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2951/4481] Przetwarzanie: SM0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2952/4481] Przetwarzanie: SM0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2953/4481] Przetwarzanie: SM0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2954/4481] Przetwarzanie: SM0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2955/4481] Przetwarzanie: SM0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2956/4481] Przetwarzanie: SM0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.69it/s]\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2957/4481] Przetwarzanie: SM0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2958/4481] Przetwarzanie: SM0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2959/4481] Przetwarzanie: SM0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2960/4481] Przetwarzanie: SM0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.72it/s]\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2961/4481] Przetwarzanie: SM0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2962/4481] Przetwarzanie: SM0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2963/4481] Przetwarzanie: SM0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2964/4481] Przetwarzanie: SM0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2965/4481] Przetwarzanie: SM0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2966/4481] Przetwarzanie: SM0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2967/4481] Przetwarzanie: SM0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.38it/s]\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2968/4481] Przetwarzanie: SM0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2969/4481] Przetwarzanie: SM0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2970/4481] Przetwarzanie: SM0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2971/4481] Przetwarzanie: SM0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2972/4481] Przetwarzanie: SM0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2973/4481] Przetwarzanie: SM0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2974/4481] Przetwarzanie: SM0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2975/4481] Przetwarzanie: SM0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2976/4481] Przetwarzanie: SM0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2977/4481] Przetwarzanie: SM0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.22it/s]\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2978/4481] Przetwarzanie: SM0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2979/4481] Przetwarzanie: SM0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2980/4481] Przetwarzanie: SM0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2981/4481] Przetwarzanie: SM0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2982/4481] Przetwarzanie: SM0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2983/4481] Przetwarzanie: SM0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2984/4481] Przetwarzanie: SM0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2985/4481] Przetwarzanie: SM0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2986/4481] Przetwarzanie: SM0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2987/4481] Przetwarzanie: SM0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2988/4481] Przetwarzanie: SM0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2989/4481] Przetwarzanie: SM0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2990/4481] Przetwarzanie: SM0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2991/4481] Przetwarzanie: SM0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2992/4481] Przetwarzanie: SM0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2993/4481] Przetwarzanie: SM0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2994/4481] Przetwarzanie: SM0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2995/4481] Przetwarzanie: SM0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2996/4481] Przetwarzanie: SM0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2997/4481] Przetwarzanie: SM0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.09it/s]\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2998/4481] Przetwarzanie: SM0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2999/4481] Przetwarzanie: SM0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.63it/s]\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000/4481] Przetwarzanie: SM0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3001/4481] Przetwarzanie: SM0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3002/4481] Przetwarzanie: SM0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3003/4481] Przetwarzanie: SM0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3004/4481] Przetwarzanie: SM0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.78it/s]\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3005/4481] Przetwarzanie: SM0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3006/4481] Przetwarzanie: SM0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3007/4481] Przetwarzanie: SM0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3008/4481] Przetwarzanie: SM0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3009/4481] Przetwarzanie: SM0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3010/4481] Przetwarzanie: SM0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3011/4481] Przetwarzanie: SM0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3012/4481] Przetwarzanie: SM0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3013/4481] Przetwarzanie: SM0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3014/4481] Przetwarzanie: SM0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3015/4481] Przetwarzanie: SM0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3016/4481] Przetwarzanie: SM0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3017/4481] Przetwarzanie: SM0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3018/4481] Przetwarzanie: SM0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3019/4481] Przetwarzanie: SM0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3020/4481] Przetwarzanie: SM0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3021/4481] Przetwarzanie: SM0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3022/4481] Przetwarzanie: SM0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3023/4481] Przetwarzanie: SM0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3024/4481] Przetwarzanie: SM0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3025/4481] Przetwarzanie: SM0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.95it/s]\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3026/4481] Przetwarzanie: SM0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3027/4481] Przetwarzanie: SM0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3028/4481] Przetwarzanie: SM0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3029/4481] Przetwarzanie: SM0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3030/4481] Przetwarzanie: SM0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3031/4481] Przetwarzanie: SM0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3032/4481] Przetwarzanie: SM0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3033/4481] Przetwarzanie: SM0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3034/4481] Przetwarzanie: SM0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3035/4481] Przetwarzanie: SM0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3036/4481] Przetwarzanie: SM0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3037/4481] Przetwarzanie: SM0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3038/4481] Przetwarzanie: SM0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3039/4481] Przetwarzanie: SM0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3040/4481] Przetwarzanie: SM0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3041/4481] Przetwarzanie: SM0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3042/4481] Przetwarzanie: SM0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3043/4481] Przetwarzanie: SM0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3044/4481] Przetwarzanie: SM0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3045/4481] Przetwarzanie: SM0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3046/4481] Przetwarzanie: SM0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3047/4481] Przetwarzanie: SM0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:43:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3048/4481] Przetwarzanie: SM0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3049/4481] Przetwarzanie: SM0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.68it/s]\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3050/4481] Przetwarzanie: SM0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3051/4481] Przetwarzanie: SM0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3052/4481] Przetwarzanie: SM0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3053/4481] Przetwarzanie: SM0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3054/4481] Przetwarzanie: SM0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3055/4481] Przetwarzanie: SM0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3056/4481] Przetwarzanie: SM0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3057/4481] Przetwarzanie: SM0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3058/4481] Przetwarzanie: SM0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3059/4481] Przetwarzanie: SM0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3060/4481] Przetwarzanie: SM0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3061/4481] Przetwarzanie: SM0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3062/4481] Przetwarzanie: SM0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3063/4481] Przetwarzanie: SM0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3064/4481] Przetwarzanie: SM0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3065/4481] Przetwarzanie: SM0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3066/4481] Przetwarzanie: SM0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3067/4481] Przetwarzanie: SM0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3068/4481] Przetwarzanie: SM0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3069/4481] Przetwarzanie: SM0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3070/4481] Przetwarzanie: SM0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.18it/s]\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3071/4481] Przetwarzanie: SM0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3072/4481] Przetwarzanie: SM0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3073/4481] Przetwarzanie: SM0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3074/4481] Przetwarzanie: SM0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3075/4481] Przetwarzanie: SM0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3076/4481] Przetwarzanie: SM0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3077/4481] Przetwarzanie: SM0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3078/4481] Przetwarzanie: SM0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3079/4481] Przetwarzanie: SM0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3080/4481] Przetwarzanie: SM0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3081/4481] Przetwarzanie: SM0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3082/4481] Przetwarzanie: SM0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3083/4481] Przetwarzanie: SM0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3084/4481] Przetwarzanie: SM0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3085/4481] Przetwarzanie: SM0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3086/4481] Przetwarzanie: SM0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3087/4481] Przetwarzanie: SM0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3088/4481] Przetwarzanie: SM0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.73it/s]\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3089/4481] Przetwarzanie: SM0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3090/4481] Przetwarzanie: SM0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3091/4481] Przetwarzanie: SM0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3092/4481] Przetwarzanie: SM0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3093/4481] Przetwarzanie: SM0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3094/4481] Przetwarzanie: SM0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3095/4481] Przetwarzanie: SM0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3096/4481] Przetwarzanie: SM0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3097/4481] Przetwarzanie: SM0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3098/4481] Przetwarzanie: SM0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3099/4481] Przetwarzanie: SM0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3100/4481] Przetwarzanie: SM0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3101/4481] Przetwarzanie: SM0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3102/4481] Przetwarzanie: SM0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3103/4481] Przetwarzanie: SM0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3104/4481] Przetwarzanie: SM0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3105/4481] Przetwarzanie: SM0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3106/4481] Przetwarzanie: SM0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3107/4481] Przetwarzanie: SM0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3108/4481] Przetwarzanie: SM0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3109/4481] Przetwarzanie: SM0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3110/4481] Przetwarzanie: SM0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3111/4481] Przetwarzanie: SM0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3112/4481] Przetwarzanie: SM0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3113/4481] Przetwarzanie: SM0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3114/4481] Przetwarzanie: SM0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3115/4481] Przetwarzanie: SM0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.72it/s]\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3116/4481] Przetwarzanie: SM0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3117/4481] Przetwarzanie: SM0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3118/4481] Przetwarzanie: SM0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3119/4481] Przetwarzanie: SM0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3120/4481] Przetwarzanie: SM0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3121/4481] Przetwarzanie: SM0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3122/4481] Przetwarzanie: SM0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3123/4481] Przetwarzanie: SM0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3124/4481] Przetwarzanie: SM0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3125/4481] Przetwarzanie: SM0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3126/4481] Przetwarzanie: SM0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3127/4481] Przetwarzanie: SM0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.04it/s]\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3128/4481] Przetwarzanie: SM0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3129/4481] Przetwarzanie: SM0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3130/4481] Przetwarzanie: SM0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3131/4481] Przetwarzanie: SM0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3132/4481] Przetwarzanie: SM0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3133/4481] Przetwarzanie: SM0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3134/4481] Przetwarzanie: SM0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3135/4481] Przetwarzanie: SM0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3136/4481] Przetwarzanie: SM0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3137/4481] Przetwarzanie: SM0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3138/4481] Przetwarzanie: SM0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.66it/s]\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3139/4481] Przetwarzanie: SM0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3140/4481] Przetwarzanie: SM0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3141/4481] Przetwarzanie: SM0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3142/4481] Przetwarzanie: SM0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3143/4481] Przetwarzanie: SM0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3144/4481] Przetwarzanie: SM0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3145/4481] Przetwarzanie: SM0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3146/4481] Przetwarzanie: SM0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3147/4481] Przetwarzanie: SM0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3148/4481] Przetwarzanie: SM0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3149/4481] Przetwarzanie: SM0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3150/4481] Przetwarzanie: SM0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3151/4481] Przetwarzanie: SM0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3152/4481] Przetwarzanie: SM0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3153/4481] Przetwarzanie: SM0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3154/4481] Przetwarzanie: SM0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3155/4481] Przetwarzanie: SM0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3156/4481] Przetwarzanie: SM0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3157/4481] Przetwarzanie: SM0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3158/4481] Przetwarzanie: SM0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3159/4481] Przetwarzanie: SM0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3160/4481] Przetwarzanie: SM0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3161/4481] Przetwarzanie: SM0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3162/4481] Przetwarzanie: SM0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3163/4481] Przetwarzanie: SM0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3164/4481] Przetwarzanie: SM0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3165/4481] Przetwarzanie: SM0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3166/4481] Przetwarzanie: SM0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3167/4481] Przetwarzanie: SM0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3168/4481] Przetwarzanie: SM0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3169/4481] Przetwarzanie: SM0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3170/4481] Przetwarzanie: SM0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3171/4481] Przetwarzanie: SM0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.40it/s]\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3172/4481] Przetwarzanie: SM0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3173/4481] Przetwarzanie: SM0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3174/4481] Przetwarzanie: SM0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3175/4481] Przetwarzanie: SM0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3176/4481] Przetwarzanie: SM0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3177/4481] Przetwarzanie: SM0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3178/4481] Przetwarzanie: SM0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.61it/s]\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3179/4481] Przetwarzanie: SM0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3180/4481] Przetwarzanie: SM0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3181/4481] Przetwarzanie: SM0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3182/4481] Przetwarzanie: SM0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3183/4481] Przetwarzanie: SM0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3184/4481] Przetwarzanie: SM0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3185/4481] Przetwarzanie: SM0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3186/4481] Przetwarzanie: SM0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3187/4481] Przetwarzanie: SM0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3188/4481] Przetwarzanie: SM0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3189/4481] Przetwarzanie: SM0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3190/4481] Przetwarzanie: SM0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3191/4481] Przetwarzanie: SM0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3192/4481] Przetwarzanie: SM0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3193/4481] Przetwarzanie: SM0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3194/4481] Przetwarzanie: SM0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3195/4481] Przetwarzanie: SM0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3196/4481] Przetwarzanie: SM0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3197/4481] Przetwarzanie: SM0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3198/4481] Przetwarzanie: SM0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3199/4481] Przetwarzanie: SM0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3200/4481] Przetwarzanie: SM0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3201/4481] Przetwarzanie: SM0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3202/4481] Przetwarzanie: SM0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3203/4481] Przetwarzanie: SM0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3204/4481] Przetwarzanie: SM0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3205/4481] Przetwarzanie: SM0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3206/4481] Przetwarzanie: SM0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3207/4481] Przetwarzanie: SM0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3208/4481] Przetwarzanie: SM0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3209/4481] Przetwarzanie: SM0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3210/4481] Przetwarzanie: SM0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3211/4481] Przetwarzanie: SM0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.69it/s]\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3212/4481] Przetwarzanie: SM0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3213/4481] Przetwarzanie: SM0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3214/4481] Przetwarzanie: SM0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3215/4481] Przetwarzanie: SM0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3216/4481] Przetwarzanie: SM0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3217/4481] Przetwarzanie: SM0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3218/4481] Przetwarzanie: SM0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:44:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3219/4481] Przetwarzanie: SM0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:44:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3220/4481] Przetwarzanie: SM0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.03it/s]\n",
      "[NeMo W 2026-01-08 11:44:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3221/4481] Przetwarzanie: SM0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3222/4481] Przetwarzanie: SM0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3223/4481] Przetwarzanie: SM0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3224/4481] Przetwarzanie: SM0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3225/4481] Przetwarzanie: SM0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3226/4481] Przetwarzanie: SM0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3227/4481] Przetwarzanie: SM0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3228/4481] Przetwarzanie: SM0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.68it/s]\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3229/4481] Przetwarzanie: SM0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3230/4481] Przetwarzanie: SM0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3231/4481] Przetwarzanie: SM0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3232/4481] Przetwarzanie: SM0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3233/4481] Przetwarzanie: SM0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3234/4481] Przetwarzanie: SM0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3235/4481] Przetwarzanie: SM0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3236/4481] Przetwarzanie: SM0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3237/4481] Przetwarzanie: SM0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3238/4481] Przetwarzanie: SM0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3239/4481] Przetwarzanie: SM0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3240/4481] Przetwarzanie: SM0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3241/4481] Przetwarzanie: SM0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3242/4481] Przetwarzanie: SM0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3243/4481] Przetwarzanie: SM0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3244/4481] Przetwarzanie: SM0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3245/4481] Przetwarzanie: SM0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3246/4481] Przetwarzanie: SM0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3247/4481] Przetwarzanie: SM0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3248/4481] Przetwarzanie: SM0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3249/4481] Przetwarzanie: SM0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3250/4481] Przetwarzanie: SM0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3251/4481] Przetwarzanie: SM0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3252/4481] Przetwarzanie: SM0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3253/4481] Przetwarzanie: SM0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3254/4481] Przetwarzanie: SM0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3255/4481] Przetwarzanie: SM0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3256/4481] Przetwarzanie: SM0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3257/4481] Przetwarzanie: SM0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3258/4481] Przetwarzanie: SM0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3259/4481] Przetwarzanie: SM0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3260/4481] Przetwarzanie: SM0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3261/4481] Przetwarzanie: SM0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3262/4481] Przetwarzanie: SM0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3263/4481] Przetwarzanie: SM0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3264/4481] Przetwarzanie: SM0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3265/4481] Przetwarzanie: SM0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3266/4481] Przetwarzanie: SM0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3267/4481] Przetwarzanie: SM0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3268/4481] Przetwarzanie: SM0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3269/4481] Przetwarzanie: SM0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3270/4481] Przetwarzanie: SM0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3271/4481] Przetwarzanie: SM0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3272/4481] Przetwarzanie: SM0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3273/4481] Przetwarzanie: SM0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3274/4481] Przetwarzanie: SM0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3275/4481] Przetwarzanie: SM0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3276/4481] Przetwarzanie: SM0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3277/4481] Przetwarzanie: SM0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3278/4481] Przetwarzanie: SM0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3279/4481] Przetwarzanie: SM0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3280/4481] Przetwarzanie: SM0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3281/4481] Przetwarzanie: SM0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3282/4481] Przetwarzanie: SM0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3283/4481] Przetwarzanie: SM0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3284/4481] Przetwarzanie: SM0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.91it/s]\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3285/4481] Przetwarzanie: SM0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3286/4481] Przetwarzanie: SM0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3287/4481] Przetwarzanie: SM0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3288/4481] Przetwarzanie: SM0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3289/4481] Przetwarzanie: SM0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3290/4481] Przetwarzanie: SM0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3291/4481] Przetwarzanie: SM0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3292/4481] Przetwarzanie: SM0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3293/4481] Przetwarzanie: SM0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3294/4481] Przetwarzanie: SM0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3295/4481] Przetwarzanie: SM0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3296/4481] Przetwarzanie: SM0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3297/4481] Przetwarzanie: SM0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3298/4481] Przetwarzanie: SM0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3299/4481] Przetwarzanie: SM0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3300/4481] Przetwarzanie: SM0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.22it/s]\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3301/4481] Przetwarzanie: SM0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3302/4481] Przetwarzanie: SM0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3303/4481] Przetwarzanie: SM0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3304/4481] Przetwarzanie: SM0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3305/4481] Przetwarzanie: SM0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:44:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3306/4481] Przetwarzanie: SM0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3307/4481] Przetwarzanie: SM0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3308/4481] Przetwarzanie: SM0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.11it/s]\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3309/4481] Przetwarzanie: SM0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3310/4481] Przetwarzanie: SM0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3311/4481] Przetwarzanie: SM0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3312/4481] Przetwarzanie: SM0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3313/4481] Przetwarzanie: SM0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.88it/s]\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3314/4481] Przetwarzanie: SM0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3315/4481] Przetwarzanie: SM0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3316/4481] Przetwarzanie: SM0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3317/4481] Przetwarzanie: SM0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3318/4481] Przetwarzanie: SM0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.56it/s]\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3319/4481] Przetwarzanie: SM0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3320/4481] Przetwarzanie: SM0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3321/4481] Przetwarzanie: SM0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3322/4481] Przetwarzanie: SM0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3323/4481] Przetwarzanie: SM0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3324/4481] Przetwarzanie: SM0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3325/4481] Przetwarzanie: SM0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3326/4481] Przetwarzanie: SM0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.48it/s]\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3327/4481] Przetwarzanie: SM0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3328/4481] Przetwarzanie: SM0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3329/4481] Przetwarzanie: SM0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3330/4481] Przetwarzanie: SM0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3331/4481] Przetwarzanie: SM0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3332/4481] Przetwarzanie: SM0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3333/4481] Przetwarzanie: SM0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3334/4481] Przetwarzanie: SM0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3335/4481] Przetwarzanie: SM0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3336/4481] Przetwarzanie: SM0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3337/4481] Przetwarzanie: SM0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3338/4481] Przetwarzanie: SM0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3339/4481] Przetwarzanie: SM0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3340/4481] Przetwarzanie: SM0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:44:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.08it/s]\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3341/4481] Przetwarzanie: SM0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3342/4481] Przetwarzanie: SM0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3343/4481] Przetwarzanie: SM0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.82it/s]\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3344/4481] Przetwarzanie: SM0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3345/4481] Przetwarzanie: SM0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3346/4481] Przetwarzanie: SM0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.19it/s]\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3347/4481] Przetwarzanie: SM0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3348/4481] Przetwarzanie: SM0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3349/4481] Przetwarzanie: SM0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3350/4481] Przetwarzanie: SM0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3351/4481] Przetwarzanie: SM0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3352/4481] Przetwarzanie: SM0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3353/4481] Przetwarzanie: SM0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3354/4481] Przetwarzanie: SM0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3355/4481] Przetwarzanie: SM0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3356/4481] Przetwarzanie: SM0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3357/4481] Przetwarzanie: SM0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3358/4481] Przetwarzanie: SM0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3359/4481] Przetwarzanie: SM0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3360/4481] Przetwarzanie: SM0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3361/4481] Przetwarzanie: SM0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3362/4481] Przetwarzanie: SM0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3363/4481] Przetwarzanie: SM0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3364/4481] Przetwarzanie: SM0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n",
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3365/4481] Przetwarzanie: SM0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3366/4481] Przetwarzanie: SM0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3367/4481] Przetwarzanie: SM0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3368/4481] Przetwarzanie: SM0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3369/4481] Przetwarzanie: SM0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3370/4481] Przetwarzanie: SM0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3371/4481] Przetwarzanie: SM0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.59it/s]\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372/4481] Przetwarzanie: SM0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3373/4481] Przetwarzanie: SM0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3374/4481] Przetwarzanie: SM0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3375/4481] Przetwarzanie: SM0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3376/4481] Przetwarzanie: SM0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3377/4481] Przetwarzanie: SM0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3378/4481] Przetwarzanie: SM0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3379/4481] Przetwarzanie: SM0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3380/4481] Przetwarzanie: SM0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3381/4481] Przetwarzanie: SM0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3382/4481] Przetwarzanie: SM0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3383/4481] Przetwarzanie: SM0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3384/4481] Przetwarzanie: SM0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3385/4481] Przetwarzanie: SM0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3386/4481] Przetwarzanie: SM0_surprised_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3387/4481] Przetwarzanie: SM0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3388/4481] Przetwarzanie: SM0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3389/4481] Przetwarzanie: SM0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3390/4481] Przetwarzanie: SM0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3391/4481] Przetwarzanie: SM0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.65it/s]\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3392/4481] Przetwarzanie: SM0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3393/4481] Przetwarzanie: SM0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3394/4481] Przetwarzanie: SM0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3395/4481] Przetwarzanie: SM0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3396/4481] Przetwarzanie: SM0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3397/4481] Przetwarzanie: SM0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.07it/s]\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3398/4481] Przetwarzanie: SM0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3399/4481] Przetwarzanie: SM0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3400/4481] Przetwarzanie: SM0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3401/4481] Przetwarzanie: SM0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3402/4481] Przetwarzanie: SM0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3403/4481] Przetwarzanie: SM0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3404/4481] Przetwarzanie: TP0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3405/4481] Przetwarzanie: TP0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3406/4481] Przetwarzanie: TP0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3407/4481] Przetwarzanie: TP0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3408/4481] Przetwarzanie: TP0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  9.34it/s]\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3409/4481] Przetwarzanie: TP0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3410/4481] Przetwarzanie: TP0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3411/4481] Przetwarzanie: TP0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3412/4481] Przetwarzanie: TP0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3413/4481] Przetwarzanie: TP0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3414/4481] Przetwarzanie: TP0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3415/4481] Przetwarzanie: TP0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3416/4481] Przetwarzanie: TP0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3417/4481] Przetwarzanie: TP0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.37it/s]\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3418/4481] Przetwarzanie: TP0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3419/4481] Przetwarzanie: TP0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3420/4481] Przetwarzanie: TP0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3421/4481] Przetwarzanie: TP0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3422/4481] Przetwarzanie: TP0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3423/4481] Przetwarzanie: TP0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3424/4481] Przetwarzanie: TP0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3425/4481] Przetwarzanie: TP0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3426/4481] Przetwarzanie: TP0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.22it/s]\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3427/4481] Przetwarzanie: TP0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3428/4481] Przetwarzanie: TP0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3429/4481] Przetwarzanie: TP0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3430/4481] Przetwarzanie: TP0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3431/4481] Przetwarzanie: TP0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3432/4481] Przetwarzanie: TP0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3433/4481] Przetwarzanie: TP0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3434/4481] Przetwarzanie: TP0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3435/4481] Przetwarzanie: TP0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3436/4481] Przetwarzanie: TP0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3437/4481] Przetwarzanie: TP0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3438/4481] Przetwarzanie: TP0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3439/4481] Przetwarzanie: TP0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3440/4481] Przetwarzanie: TP0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.00it/s]\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3441/4481] Przetwarzanie: TP0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3442/4481] Przetwarzanie: TP0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3443/4481] Przetwarzanie: TP0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.53it/s]\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3444/4481] Przetwarzanie: TP0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.54it/s]\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3445/4481] Przetwarzanie: TP0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3446/4481] Przetwarzanie: TP0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3447/4481] Przetwarzanie: TP0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3448/4481] Przetwarzanie: TP0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3449/4481] Przetwarzanie: TP0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3450/4481] Przetwarzanie: TP0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3451/4481] Przetwarzanie: TP0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.10it/s]\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3452/4481] Przetwarzanie: TP0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3453/4481] Przetwarzanie: TP0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.98it/s]\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3454/4481] Przetwarzanie: TP0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3455/4481] Przetwarzanie: TP0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3456/4481] Przetwarzanie: TP0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3457/4481] Przetwarzanie: TP0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3458/4481] Przetwarzanie: TP0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.77it/s]\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3459/4481] Przetwarzanie: TP0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3460/4481] Przetwarzanie: TP0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3461/4481] Przetwarzanie: TP0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3462/4481] Przetwarzanie: TP0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.79it/s]\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3463/4481] Przetwarzanie: TP0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3464/4481] Przetwarzanie: TP0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3465/4481] Przetwarzanie: TP0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3466/4481] Przetwarzanie: TP0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3467/4481] Przetwarzanie: TP0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3468/4481] Przetwarzanie: TP0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.33it/s]\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3469/4481] Przetwarzanie: TP0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3470/4481] Przetwarzanie: TP0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3471/4481] Przetwarzanie: TP0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.10it/s]\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3472/4481] Przetwarzanie: TP0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3473/4481] Przetwarzanie: TP0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3474/4481] Przetwarzanie: TP0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3475/4481] Przetwarzanie: TP0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3476/4481] Przetwarzanie: TP0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3477/4481] Przetwarzanie: TP0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3478/4481] Przetwarzanie: TP0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3479/4481] Przetwarzanie: TP0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.56it/s]\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3480/4481] Przetwarzanie: TP0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:45:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3481/4481] Przetwarzanie: TP0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3482/4481] Przetwarzanie: TP0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3483/4481] Przetwarzanie: TP0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.55it/s]\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3484/4481] Przetwarzanie: TP0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3485/4481] Przetwarzanie: TP0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3486/4481] Przetwarzanie: TP0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3487/4481] Przetwarzanie: TP0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3488/4481] Przetwarzanie: TP0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3489/4481] Przetwarzanie: TP0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3490/4481] Przetwarzanie: TP0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3491/4481] Przetwarzanie: TP0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3492/4481] Przetwarzanie: TP0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3493/4481] Przetwarzanie: TP0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3494/4481] Przetwarzanie: TP0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3495/4481] Przetwarzanie: TP0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3496/4481] Przetwarzanie: TP0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3497/4481] Przetwarzanie: TP0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3498/4481] Przetwarzanie: TP0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.76it/s]\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3499/4481] Przetwarzanie: TP0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500/4481] Przetwarzanie: TP0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3501/4481] Przetwarzanie: TP0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3502/4481] Przetwarzanie: TP0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3503/4481] Przetwarzanie: TP0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3504/4481] Przetwarzanie: TP0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3505/4481] Przetwarzanie: TP0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3506/4481] Przetwarzanie: TP0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3507/4481] Przetwarzanie: TP0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3508/4481] Przetwarzanie: TP0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3509/4481] Przetwarzanie: TP0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3510/4481] Przetwarzanie: TP0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3511/4481] Przetwarzanie: TP0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3512/4481] Przetwarzanie: TP0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3513/4481] Przetwarzanie: TP0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3514/4481] Przetwarzanie: TP0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3515/4481] Przetwarzanie: TP0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3516/4481] Przetwarzanie: TP0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.11it/s]\n",
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3517/4481] Przetwarzanie: TP0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3518/4481] Przetwarzanie: TP0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3519/4481] Przetwarzanie: TP0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3520/4481] Przetwarzanie: TP0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3521/4481] Przetwarzanie: TP0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3522/4481] Przetwarzanie: TP0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3523/4481] Przetwarzanie: TP0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3524/4481] Przetwarzanie: TP0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3525/4481] Przetwarzanie: TP0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3526/4481] Przetwarzanie: TP0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3527/4481] Przetwarzanie: TP0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.21it/s]\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3528/4481] Przetwarzanie: TP0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3529/4481] Przetwarzanie: TP0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3530/4481] Przetwarzanie: TP0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3531/4481] Przetwarzanie: TP0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3532/4481] Przetwarzanie: TP0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3533/4481] Przetwarzanie: TP0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3534/4481] Przetwarzanie: TP0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.55it/s]\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3535/4481] Przetwarzanie: TP0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3536/4481] Przetwarzanie: TP0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3537/4481] Przetwarzanie: TP0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3538/4481] Przetwarzanie: TP0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3539/4481] Przetwarzanie: TP0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3540/4481] Przetwarzanie: TP0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3541/4481] Przetwarzanie: TP0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3542/4481] Przetwarzanie: TP0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3543/4481] Przetwarzanie: TP0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3544/4481] Przetwarzanie: TP0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3545/4481] Przetwarzanie: TP0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:45:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3546/4481] Przetwarzanie: TP0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3547/4481] Przetwarzanie: TP0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3548/4481] Przetwarzanie: TP0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3549/4481] Przetwarzanie: TP0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3550/4481] Przetwarzanie: TP0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3551/4481] Przetwarzanie: TP0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3552/4481] Przetwarzanie: TP0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3553/4481] Przetwarzanie: TP0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3554/4481] Przetwarzanie: TP0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3555/4481] Przetwarzanie: TP0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3556/4481] Przetwarzanie: TP0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3557/4481] Przetwarzanie: TP0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3558/4481] Przetwarzanie: TP0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3559/4481] Przetwarzanie: TP0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3560/4481] Przetwarzanie: TP0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3561/4481] Przetwarzanie: TP0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3562/4481] Przetwarzanie: TP0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3563/4481] Przetwarzanie: TP0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3564/4481] Przetwarzanie: TP0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3565/4481] Przetwarzanie: TP0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3566/4481] Przetwarzanie: TP0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3567/4481] Przetwarzanie: TP0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3568/4481] Przetwarzanie: TP0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.67it/s]\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3569/4481] Przetwarzanie: TP0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3570/4481] Przetwarzanie: TP0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3571/4481] Przetwarzanie: TP0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3572/4481] Przetwarzanie: TP0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3573/4481] Przetwarzanie: TP0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3574/4481] Przetwarzanie: TP0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3575/4481] Przetwarzanie: TP0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3576/4481] Przetwarzanie: TP0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3577/4481] Przetwarzanie: TP0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3578/4481] Przetwarzanie: TP0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3579/4481] Przetwarzanie: TP0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3580/4481] Przetwarzanie: TP0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3581/4481] Przetwarzanie: TP0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3582/4481] Przetwarzanie: TP0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3583/4481] Przetwarzanie: TP0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.89it/s]\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3584/4481] Przetwarzanie: TP0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3585/4481] Przetwarzanie: TP0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3586/4481] Przetwarzanie: TP0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3587/4481] Przetwarzanie: TP0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3588/4481] Przetwarzanie: TP0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3589/4481] Przetwarzanie: TP0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3590/4481] Przetwarzanie: TP0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3591/4481] Przetwarzanie: TP0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3592/4481] Przetwarzanie: TP0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3593/4481] Przetwarzanie: TP0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3594/4481] Przetwarzanie: TP0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3595/4481] Przetwarzanie: TP0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3596/4481] Przetwarzanie: TP0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.61it/s]\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3597/4481] Przetwarzanie: TP0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3598/4481] Przetwarzanie: TP0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3599/4481] Przetwarzanie: TP0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.34it/s]\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600/4481] Przetwarzanie: TP0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3601/4481] Przetwarzanie: TP0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3602/4481] Przetwarzanie: TP0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3603/4481] Przetwarzanie: TP0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3604/4481] Przetwarzanie: TP0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3605/4481] Przetwarzanie: TP0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3606/4481] Przetwarzanie: TP0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3607/4481] Przetwarzanie: TP0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3608/4481] Przetwarzanie: TP0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3609/4481] Przetwarzanie: TP0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3610/4481] Przetwarzanie: TP0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.17it/s]\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3611/4481] Przetwarzanie: TP0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3612/4481] Przetwarzanie: TP0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3613/4481] Przetwarzanie: TP0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3614/4481] Przetwarzanie: TP0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3615/4481] Przetwarzanie: TP0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3616/4481] Przetwarzanie: TP0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3617/4481] Przetwarzanie: TP0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.76it/s]\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3618/4481] Przetwarzanie: TP0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3619/4481] Przetwarzanie: TP0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3620/4481] Przetwarzanie: TP0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.93it/s]\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3621/4481] Przetwarzanie: TP0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3622/4481] Przetwarzanie: TP0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3623/4481] Przetwarzanie: TP0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3624/4481] Przetwarzanie: TP0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3625/4481] Przetwarzanie: TP0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3626/4481] Przetwarzanie: TP0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3627/4481] Przetwarzanie: TP0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3628/4481] Przetwarzanie: TP0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.77it/s]\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3629/4481] Przetwarzanie: TP0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3630/4481] Przetwarzanie: TP0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3631/4481] Przetwarzanie: TP0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3632/4481] Przetwarzanie: TP0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:45:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3633/4481] Przetwarzanie: TP0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3634/4481] Przetwarzanie: TP0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3635/4481] Przetwarzanie: TP0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3636/4481] Przetwarzanie: TP0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3637/4481] Przetwarzanie: TP0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3638/4481] Przetwarzanie: TP0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3639/4481] Przetwarzanie: TP0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3640/4481] Przetwarzanie: TP0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3641/4481] Przetwarzanie: TP0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3642/4481] Przetwarzanie: TP0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3643/4481] Przetwarzanie: TP0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3644/4481] Przetwarzanie: TP0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.97it/s]\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3645/4481] Przetwarzanie: TP0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3646/4481] Przetwarzanie: TP0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3647/4481] Przetwarzanie: TP0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3648/4481] Przetwarzanie: TP0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3649/4481] Przetwarzanie: TP0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3650/4481] Przetwarzanie: TP0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3651/4481] Przetwarzanie: TP0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3652/4481] Przetwarzanie: TP0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.35it/s]\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3653/4481] Przetwarzanie: TP0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3654/4481] Przetwarzanie: TP0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3655/4481] Przetwarzanie: TP0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3656/4481] Przetwarzanie: TP0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3657/4481] Przetwarzanie: TP0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3658/4481] Przetwarzanie: TP0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3659/4481] Przetwarzanie: TP0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3660/4481] Przetwarzanie: TP0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.21it/s]\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3661/4481] Przetwarzanie: TP0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.69it/s]\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3662/4481] Przetwarzanie: TP0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3663/4481] Przetwarzanie: TP0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3664/4481] Przetwarzanie: TP0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3665/4481] Przetwarzanie: TP0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3666/4481] Przetwarzanie: TP0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3667/4481] Przetwarzanie: TP0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.09it/s]\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3668/4481] Przetwarzanie: TP0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3669/4481] Przetwarzanie: TP0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3670/4481] Przetwarzanie: TP0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.00it/s]\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3671/4481] Przetwarzanie: TP0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.41it/s]\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3672/4481] Przetwarzanie: TP0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3673/4481] Przetwarzanie: TP0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.89it/s]\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3674/4481] Przetwarzanie: TP0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3675/4481] Przetwarzanie: TP0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3676/4481] Przetwarzanie: TP0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3677/4481] Przetwarzanie: TP0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.32it/s]\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3678/4481] Przetwarzanie: TP0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.72it/s]\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3679/4481] Przetwarzanie: TP0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3680/4481] Przetwarzanie: TP0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3681/4481] Przetwarzanie: TP0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3682/4481] Przetwarzanie: TP0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3683/4481] Przetwarzanie: TP0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3684/4481] Przetwarzanie: TP0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.52it/s]\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3685/4481] Przetwarzanie: TP0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3686/4481] Przetwarzanie: TP0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3687/4481] Przetwarzanie: TP0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3688/4481] Przetwarzanie: TP0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3689/4481] Przetwarzanie: TP0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.33it/s]\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3690/4481] Przetwarzanie: TP0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3691/4481] Przetwarzanie: TP0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3692/4481] Przetwarzanie: TP0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3693/4481] Przetwarzanie: TP0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3694/4481] Przetwarzanie: TP0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3695/4481] Przetwarzanie: TP0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3696/4481] Przetwarzanie: TP0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.23it/s]\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3697/4481] Przetwarzanie: TP0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3698/4481] Przetwarzanie: TP0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3699/4481] Przetwarzanie: TP0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3700/4481] Przetwarzanie: TP0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3701/4481] Przetwarzanie: TP0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3702/4481] Przetwarzanie: TP0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3703/4481] Przetwarzanie: TP0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3704/4481] Przetwarzanie: TP0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3705/4481] Przetwarzanie: TP0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3706/4481] Przetwarzanie: TP0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3707/4481] Przetwarzanie: TP0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.24it/s]\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3708/4481] Przetwarzanie: TP0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3709/4481] Przetwarzanie: TP0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3710/4481] Przetwarzanie: TP0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3711/4481] Przetwarzanie: TP0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.35it/s]\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3712/4481] Przetwarzanie: TP0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3713/4481] Przetwarzanie: TP0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3714/4481] Przetwarzanie: TP0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.28it/s]\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3715/4481] Przetwarzanie: TP0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3716/4481] Przetwarzanie: TP0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3717/4481] Przetwarzanie: TP0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3718/4481] Przetwarzanie: TP0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3719/4481] Przetwarzanie: TP0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3720/4481] Przetwarzanie: TP0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3721/4481] Przetwarzanie: TP0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3722/4481] Przetwarzanie: TP0_neutral_53.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.60it/s]\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3723/4481] Przetwarzanie: TP0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3724/4481] Przetwarzanie: TP0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3725/4481] Przetwarzanie: TP0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3726/4481] Przetwarzanie: TP0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3727/4481] Przetwarzanie: TP0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.71it/s]\n",
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3728/4481] Przetwarzanie: TP0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3729/4481] Przetwarzanie: TP0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3730/4481] Przetwarzanie: TP0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3731/4481] Przetwarzanie: TP0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3732/4481] Przetwarzanie: TP0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3733/4481] Przetwarzanie: TP0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3734/4481] Przetwarzanie: TP0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3735/4481] Przetwarzanie: TP0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3736/4481] Przetwarzanie: TP0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3737/4481] Przetwarzanie: TP0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3738/4481] Przetwarzanie: TP0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3739/4481] Przetwarzanie: TP0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3740/4481] Przetwarzanie: TP0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3741/4481] Przetwarzanie: TP0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3742/4481] Przetwarzanie: TP0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3743/4481] Przetwarzanie: TP0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3744/4481] Przetwarzanie: TP0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3745/4481] Przetwarzanie: TP0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.53it/s]\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3746/4481] Przetwarzanie: TP0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3747/4481] Przetwarzanie: TP0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.19it/s]\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3748/4481] Przetwarzanie: TP0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3749/4481] Przetwarzanie: TP0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3750/4481] Przetwarzanie: TP0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3751/4481] Przetwarzanie: TP0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3752/4481] Przetwarzanie: TP0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3753/4481] Przetwarzanie: TP0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.55it/s]\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3754/4481] Przetwarzanie: TP0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3755/4481] Przetwarzanie: TP0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3756/4481] Przetwarzanie: TP0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.51it/s]\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3757/4481] Przetwarzanie: TP0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:46:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3758/4481] Przetwarzanie: TP0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:46:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3759/4481] Przetwarzanie: TP0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3760/4481] Przetwarzanie: TP0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3761/4481] Przetwarzanie: TP0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3762/4481] Przetwarzanie: TP0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3763/4481] Przetwarzanie: TP0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.88it/s]\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3764/4481] Przetwarzanie: TP0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3765/4481] Przetwarzanie: TP0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3766/4481] Przetwarzanie: TP0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3767/4481] Przetwarzanie: TP0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3768/4481] Przetwarzanie: TP0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.59it/s]\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3769/4481] Przetwarzanie: TP0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.22it/s]\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3770/4481] Przetwarzanie: TP0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3771/4481] Przetwarzanie: TP0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3772/4481] Przetwarzanie: TP0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3773/4481] Przetwarzanie: TP0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3774/4481] Przetwarzanie: TP0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3775/4481] Przetwarzanie: TP0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3776/4481] Przetwarzanie: TP0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3777/4481] Przetwarzanie: TP0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3778/4481] Przetwarzanie: TP0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3779/4481] Przetwarzanie: TP0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3780/4481] Przetwarzanie: TP0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3781/4481] Przetwarzanie: TP0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3782/4481] Przetwarzanie: TP0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3783/4481] Przetwarzanie: TP0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3784/4481] Przetwarzanie: TP0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3785/4481] Przetwarzanie: TP0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3786/4481] Przetwarzanie: TP0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3787/4481] Przetwarzanie: TP0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3788/4481] Przetwarzanie: TP0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3789/4481] Przetwarzanie: TP0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3790/4481] Przetwarzanie: TP0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3791/4481] Przetwarzanie: TP0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3792/4481] Przetwarzanie: TP0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3793/4481] Przetwarzanie: TP0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3794/4481] Przetwarzanie: TP0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3795/4481] Przetwarzanie: TP0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3796/4481] Przetwarzanie: TP0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3797/4481] Przetwarzanie: TP0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3798/4481] Przetwarzanie: TP0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3799/4481] Przetwarzanie: TP0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3800/4481] Przetwarzanie: TP0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3801/4481] Przetwarzanie: TP0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3802/4481] Przetwarzanie: TP0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3803/4481] Przetwarzanie: TP0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3804/4481] Przetwarzanie: TP0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.54it/s]\n",
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3805/4481] Przetwarzanie: TP0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3806/4481] Przetwarzanie: TP0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3807/4481] Przetwarzanie: TP0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3808/4481] Przetwarzanie: TP0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3809/4481] Przetwarzanie: TP0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3810/4481] Przetwarzanie: TP0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3811/4481] Przetwarzanie: TP0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3812/4481] Przetwarzanie: TP0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3813/4481] Przetwarzanie: TP0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3814/4481] Przetwarzanie: TP0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3815/4481] Przetwarzanie: TP0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3816/4481] Przetwarzanie: TP0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3817/4481] Przetwarzanie: TP0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3818/4481] Przetwarzanie: TP0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3819/4481] Przetwarzanie: TP0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3820/4481] Przetwarzanie: TP0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.63it/s]\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3821/4481] Przetwarzanie: TP0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3822/4481] Przetwarzanie: TP0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3823/4481] Przetwarzanie: TP0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3824/4481] Przetwarzanie: TP0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3825/4481] Przetwarzanie: TP0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3826/4481] Przetwarzanie: TP0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3827/4481] Przetwarzanie: TP0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3828/4481] Przetwarzanie: TP0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.53it/s]\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3829/4481] Przetwarzanie: TP0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3830/4481] Przetwarzanie: TP0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3831/4481] Przetwarzanie: TP0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.95it/s]\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3832/4481] Przetwarzanie: TP0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3833/4481] Przetwarzanie: TP0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3834/4481] Przetwarzanie: TP0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3835/4481] Przetwarzanie: TP0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3836/4481] Przetwarzanie: TP0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3837/4481] Przetwarzanie: TP0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3838/4481] Przetwarzanie: TP0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3839/4481] Przetwarzanie: TP0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3840/4481] Przetwarzanie: TP0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3841/4481] Przetwarzanie: TP0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.63it/s]\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3842/4481] Przetwarzanie: TP0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3843/4481] Przetwarzanie: TP0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:46:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3844/4481] Przetwarzanie: TP0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3845/4481] Przetwarzanie: TP0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3846/4481] Przetwarzanie: TP0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3847/4481] Przetwarzanie: TP0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3848/4481] Przetwarzanie: TP0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.05it/s]\n",
      "[NeMo W 2026-01-08 11:46:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3849/4481] Przetwarzanie: TP0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.79it/s]\n",
      "[NeMo W 2026-01-08 11:46:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3850/4481] Przetwarzanie: TP0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:46:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3851/4481] Przetwarzanie: TP0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.19it/s]\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3852/4481] Przetwarzanie: TP0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3853/4481] Przetwarzanie: TP0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.92it/s]\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3854/4481] Przetwarzanie: TP0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3855/4481] Przetwarzanie: TP0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3856/4481] Przetwarzanie: TP0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3857/4481] Przetwarzanie: TP0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3858/4481] Przetwarzanie: TP0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3859/4481] Przetwarzanie: TP0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3860/4481] Przetwarzanie: TP0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3861/4481] Przetwarzanie: TP0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3862/4481] Przetwarzanie: TP0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3863/4481] Przetwarzanie: TP0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3864/4481] Przetwarzanie: TP0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.51it/s]\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3865/4481] Przetwarzanie: TP0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3866/4481] Przetwarzanie: TP0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3867/4481] Przetwarzanie: TP0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3868/4481] Przetwarzanie: TP0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3869/4481] Przetwarzanie: TP0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3870/4481] Przetwarzanie: TP0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3871/4481] Przetwarzanie: TP0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3872/4481] Przetwarzanie: TP0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3873/4481] Przetwarzanie: TP0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3874/4481] Przetwarzanie: TP0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3875/4481] Przetwarzanie: TP0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3876/4481] Przetwarzanie: TP0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.22it/s]\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3877/4481] Przetwarzanie: TP0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3878/4481] Przetwarzanie: TP0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.94it/s]\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3879/4481] Przetwarzanie: TP0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3880/4481] Przetwarzanie: TP0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3881/4481] Przetwarzanie: TP0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3882/4481] Przetwarzanie: TP0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3883/4481] Przetwarzanie: TP0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.93it/s]\n",
      "[NeMo W 2026-01-08 11:46:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3884/4481] Przetwarzanie: TP0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:46:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3885/4481] Przetwarzanie: TP0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3886/4481] Przetwarzanie: TP0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3887/4481] Przetwarzanie: TP0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.15it/s]\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3888/4481] Przetwarzanie: TP0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3889/4481] Przetwarzanie: TP0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3890/4481] Przetwarzanie: TP0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3891/4481] Przetwarzanie: TP0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3892/4481] Przetwarzanie: TP0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.64it/s]\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3893/4481] Przetwarzanie: TP0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3894/4481] Przetwarzanie: TP0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3895/4481] Przetwarzanie: TP0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3896/4481] Przetwarzanie: TP0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3897/4481] Przetwarzanie: TP0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3898/4481] Przetwarzanie: TP0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3899/4481] Przetwarzanie: TP0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3900/4481] Przetwarzanie: TP0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.52it/s]\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3901/4481] Przetwarzanie: TP0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3902/4481] Przetwarzanie: TP0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3903/4481] Przetwarzanie: TP0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3904/4481] Przetwarzanie: TP0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3905/4481] Przetwarzanie: TP0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3906/4481] Przetwarzanie: TP0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3907/4481] Przetwarzanie: TP0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3908/4481] Przetwarzanie: TP0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3909/4481] Przetwarzanie: TP0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3910/4481] Przetwarzanie: TP0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3911/4481] Przetwarzanie: TP0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3912/4481] Przetwarzanie: TP0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.86it/s]\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3913/4481] Przetwarzanie: TP0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3914/4481] Przetwarzanie: TP0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3915/4481] Przetwarzanie: TP0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3916/4481] Przetwarzanie: TP0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3917/4481] Przetwarzanie: TP0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3918/4481] Przetwarzanie: TP0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:46:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3919/4481] Przetwarzanie: TP0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3920/4481] Przetwarzanie: TP0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3921/4481] Przetwarzanie: TP0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3922/4481] Przetwarzanie: TP0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3923/4481] Przetwarzanie: TP0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3924/4481] Przetwarzanie: TP0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3925/4481] Przetwarzanie: TP0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.51it/s]\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3926/4481] Przetwarzanie: TP0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3927/4481] Przetwarzanie: TP0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3928/4481] Przetwarzanie: TP0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3929/4481] Przetwarzanie: TP0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3930/4481] Przetwarzanie: TP0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.67it/s]\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3931/4481] Przetwarzanie: TP0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3932/4481] Przetwarzanie: TP0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.51it/s]\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3933/4481] Przetwarzanie: TP0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3934/4481] Przetwarzanie: TP0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3935/4481] Przetwarzanie: TP0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.65it/s]\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3936/4481] Przetwarzanie: TP0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.09it/s]\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3937/4481] Przetwarzanie: TP0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:47:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3938/4481] Przetwarzanie: TP0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:47:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3939/4481] Przetwarzanie: TP0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:47:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3940/4481] Przetwarzanie: TP0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.21it/s]\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3941/4481] Przetwarzanie: TP0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3942/4481] Przetwarzanie: TP0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.87it/s]\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3943/4481] Przetwarzanie: WR0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3944/4481] Przetwarzanie: WR0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3945/4481] Przetwarzanie: WR0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3946/4481] Przetwarzanie: WR0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.88it/s]\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3947/4481] Przetwarzanie: WR0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.64it/s]\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3948/4481] Przetwarzanie: WR0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3949/4481] Przetwarzanie: WR0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3950/4481] Przetwarzanie: WR0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3951/4481] Przetwarzanie: WR0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3952/4481] Przetwarzanie: WR0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3953/4481] Przetwarzanie: WR0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3954/4481] Przetwarzanie: WR0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3955/4481] Przetwarzanie: WR0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3956/4481] Przetwarzanie: WR0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3957/4481] Przetwarzanie: WR0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3958/4481] Przetwarzanie: WR0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3959/4481] Przetwarzanie: WR0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3960/4481] Przetwarzanie: WR0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3961/4481] Przetwarzanie: WR0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3962/4481] Przetwarzanie: WR0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3963/4481] Przetwarzanie: WR0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3964/4481] Przetwarzanie: WR0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3965/4481] Przetwarzanie: WR0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.02it/s]\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3966/4481] Przetwarzanie: WR0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3967/4481] Przetwarzanie: WR0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3968/4481] Przetwarzanie: WR0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3969/4481] Przetwarzanie: WR0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3970/4481] Przetwarzanie: WR0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3971/4481] Przetwarzanie: WR0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3972/4481] Przetwarzanie: WR0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3973/4481] Przetwarzanie: WR0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3974/4481] Przetwarzanie: WR0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3975/4481] Przetwarzanie: WR0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3976/4481] Przetwarzanie: WR0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3977/4481] Przetwarzanie: WR0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3978/4481] Przetwarzanie: WR0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3979/4481] Przetwarzanie: WR0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.01it/s]\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3980/4481] Przetwarzanie: WR0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3981/4481] Przetwarzanie: WR0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3982/4481] Przetwarzanie: WR0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3983/4481] Przetwarzanie: WR0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3984/4481] Przetwarzanie: WR0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3985/4481] Przetwarzanie: WR0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3986/4481] Przetwarzanie: WR0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3987/4481] Przetwarzanie: WR0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.04it/s]\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3988/4481] Przetwarzanie: WR0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3989/4481] Przetwarzanie: WR0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.84it/s]\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3990/4481] Przetwarzanie: WR0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.42it/s]\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3991/4481] Przetwarzanie: WR0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:47:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3992/4481] Przetwarzanie: WR0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3993/4481] Przetwarzanie: WR0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3994/4481] Przetwarzanie: WR0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3995/4481] Przetwarzanie: WR0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3996/4481] Przetwarzanie: WR0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.66it/s]\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3997/4481] Przetwarzanie: WR0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3998/4481] Przetwarzanie: WR0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3999/4481] Przetwarzanie: WR0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000/4481] Przetwarzanie: WR0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4001/4481] Przetwarzanie: WR0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.81it/s]\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4002/4481] Przetwarzanie: WR0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4003/4481] Przetwarzanie: WR0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4004/4481] Przetwarzanie: WR0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.64it/s]\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4005/4481] Przetwarzanie: WR0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4006/4481] Przetwarzanie: WR0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4007/4481] Przetwarzanie: WR0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4008/4481] Przetwarzanie: WR0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4009/4481] Przetwarzanie: WR0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4010/4481] Przetwarzanie: WR0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4011/4481] Przetwarzanie: WR0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4012/4481] Przetwarzanie: WR0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4013/4481] Przetwarzanie: WR0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4014/4481] Przetwarzanie: WR0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4015/4481] Przetwarzanie: WR0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4016/4481] Przetwarzanie: WR0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4017/4481] Przetwarzanie: WR0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4018/4481] Przetwarzanie: WR0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4019/4481] Przetwarzanie: WR0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4020/4481] Przetwarzanie: WR0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4021/4481] Przetwarzanie: WR0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.82it/s]\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4022/4481] Przetwarzanie: WR0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4023/4481] Przetwarzanie: WR0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4024/4481] Przetwarzanie: WR0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4025/4481] Przetwarzanie: WR0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4026/4481] Przetwarzanie: WR0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4027/4481] Przetwarzanie: WR0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4028/4481] Przetwarzanie: WR0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4029/4481] Przetwarzanie: WR0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4030/4481] Przetwarzanie: WR0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4031/4481] Przetwarzanie: WR0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4032/4481] Przetwarzanie: WR0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4033/4481] Przetwarzanie: WR0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4034/4481] Przetwarzanie: WR0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4035/4481] Przetwarzanie: WR0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4036/4481] Przetwarzanie: WR0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4037/4481] Przetwarzanie: WR0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.54it/s]\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4038/4481] Przetwarzanie: WR0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4039/4481] Przetwarzanie: WR0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4040/4481] Przetwarzanie: WR0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4041/4481] Przetwarzanie: WR0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4042/4481] Przetwarzanie: WR0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4043/4481] Przetwarzanie: WR0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4044/4481] Przetwarzanie: WR0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.14it/s]\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4045/4481] Przetwarzanie: WR0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4046/4481] Przetwarzanie: WR0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4047/4481] Przetwarzanie: WR0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4048/4481] Przetwarzanie: WR0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.22it/s]\n",
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4049/4481] Przetwarzanie: WR0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.47it/s]\n",
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4050/4481] Przetwarzanie: WR0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4051/4481] Przetwarzanie: WR0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4052/4481] Przetwarzanie: WR0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4053/4481] Przetwarzanie: WR0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4054/4481] Przetwarzanie: WR0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4055/4481] Przetwarzanie: WR0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.62it/s]\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4056/4481] Przetwarzanie: WR0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.65it/s]\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4057/4481] Przetwarzanie: WR0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4058/4481] Przetwarzanie: WR0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4059/4481] Przetwarzanie: WR0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4060/4481] Przetwarzanie: WR0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4061/4481] Przetwarzanie: WR0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4062/4481] Przetwarzanie: WR0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4063/4481] Przetwarzanie: WR0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4064/4481] Przetwarzanie: WR0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4065/4481] Przetwarzanie: WR0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4066/4481] Przetwarzanie: WR0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4067/4481] Przetwarzanie: WR0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4068/4481] Przetwarzanie: WR0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.30it/s]\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4069/4481] Przetwarzanie: WR0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4070/4481] Przetwarzanie: WR0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4071/4481] Przetwarzanie: WR0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4072/4481] Przetwarzanie: WR0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4073/4481] Przetwarzanie: WR0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4074/4481] Przetwarzanie: WR0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4075/4481] Przetwarzanie: WR0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.20it/s]\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4076/4481] Przetwarzanie: WR0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4077/4481] Przetwarzanie: WR0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4078/4481] Przetwarzanie: WR0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4079/4481] Przetwarzanie: WR0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4080/4481] Przetwarzanie: WR0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4081/4481] Przetwarzanie: WR0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4082/4481] Przetwarzanie: WR0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4083/4481] Przetwarzanie: WR0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4084/4481] Przetwarzanie: WR0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4085/4481] Przetwarzanie: WR0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4086/4481] Przetwarzanie: WR0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.52it/s]\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4087/4481] Przetwarzanie: WR0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4088/4481] Przetwarzanie: WR0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4089/4481] Przetwarzanie: WR0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4090/4481] Przetwarzanie: WR0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4091/4481] Przetwarzanie: WR0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4092/4481] Przetwarzanie: WR0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4093/4481] Przetwarzanie: WR0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.97it/s]\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4094/4481] Przetwarzanie: WR0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4095/4481] Przetwarzanie: WR0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4096/4481] Przetwarzanie: WR0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.21it/s]\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4097/4481] Przetwarzanie: WR0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4098/4481] Przetwarzanie: WR0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4099/4481] Przetwarzanie: WR0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4100/4481] Przetwarzanie: WR0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4101/4481] Przetwarzanie: WR0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4102/4481] Przetwarzanie: WR0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.64it/s]\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4103/4481] Przetwarzanie: WR0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4104/4481] Przetwarzanie: WR0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4105/4481] Przetwarzanie: WR0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4106/4481] Przetwarzanie: WR0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4107/4481] Przetwarzanie: WR0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4108/4481] Przetwarzanie: WR0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.51it/s]\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4109/4481] Przetwarzanie: WR0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4110/4481] Przetwarzanie: WR0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.10it/s]\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4111/4481] Przetwarzanie: WR0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4112/4481] Przetwarzanie: WR0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4113/4481] Przetwarzanie: WR0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4114/4481] Przetwarzanie: WR0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4115/4481] Przetwarzanie: WR0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.67it/s]\n",
      "[NeMo W 2026-01-08 11:47:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4116/4481] Przetwarzanie: WR0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.95it/s]\n",
      "[NeMo W 2026-01-08 11:47:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4117/4481] Przetwarzanie: WR0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.09it/s]\n",
      "[NeMo W 2026-01-08 11:47:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4118/4481] Przetwarzanie: WR0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.79it/s]\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4119/4481] Przetwarzanie: WR0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.96it/s]\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4120/4481] Przetwarzanie: WR0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4121/4481] Przetwarzanie: WR0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4122/4481] Przetwarzanie: WR0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4123/4481] Przetwarzanie: WR0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4124/4481] Przetwarzanie: WR0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4125/4481] Przetwarzanie: WR0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4126/4481] Przetwarzanie: WR0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4127/4481] Przetwarzanie: WR0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4128/4481] Przetwarzanie: WR0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.16it/s]\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4129/4481] Przetwarzanie: WR0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.22it/s]\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4130/4481] Przetwarzanie: WR0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4131/4481] Przetwarzanie: WR0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.81it/s]\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4132/4481] Przetwarzanie: WR0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4133/4481] Przetwarzanie: WR0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.49it/s]\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4134/4481] Przetwarzanie: WR0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.73it/s]\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4135/4481] Przetwarzanie: WR0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4136/4481] Przetwarzanie: WR0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.33it/s]\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4137/4481] Przetwarzanie: WR0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4138/4481] Przetwarzanie: WR0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.62it/s]\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4139/4481] Przetwarzanie: WR0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4140/4481] Przetwarzanie: WR0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4141/4481] Przetwarzanie: WR0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4142/4481] Przetwarzanie: WR0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4143/4481] Przetwarzanie: WR0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4144/4481] Przetwarzanie: WR0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4145/4481] Przetwarzanie: WR0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.59it/s]\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4146/4481] Przetwarzanie: WR0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4147/4481] Przetwarzanie: WR0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4148/4481] Przetwarzanie: WR0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4149/4481] Przetwarzanie: WR0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.89it/s]\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4150/4481] Przetwarzanie: WR0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4151/4481] Przetwarzanie: WR0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4152/4481] Przetwarzanie: WR0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.82it/s]\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4153/4481] Przetwarzanie: WR0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4154/4481] Przetwarzanie: WR0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.55it/s]\n",
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4155/4481] Przetwarzanie: WR0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4156/4481] Przetwarzanie: WR0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4157/4481] Przetwarzanie: WR0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4158/4481] Przetwarzanie: WR0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4159/4481] Przetwarzanie: WR0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4160/4481] Przetwarzanie: WR0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4161/4481] Przetwarzanie: WR0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4162/4481] Przetwarzanie: WR0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4163/4481] Przetwarzanie: WR0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.52it/s]\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4164/4481] Przetwarzanie: WR0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4165/4481] Przetwarzanie: WR0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4166/4481] Przetwarzanie: WR0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4167/4481] Przetwarzanie: WR0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4168/4481] Przetwarzanie: WR0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4169/4481] Przetwarzanie: WR0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4170/4481] Przetwarzanie: WR0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4171/4481] Przetwarzanie: WR0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4172/4481] Przetwarzanie: WR0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.92it/s]\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4173/4481] Przetwarzanie: WR0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4174/4481] Przetwarzanie: WR0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4175/4481] Przetwarzanie: WR0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4176/4481] Przetwarzanie: WR0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4177/4481] Przetwarzanie: WR0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4178/4481] Przetwarzanie: WR0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4179/4481] Przetwarzanie: WR0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4180/4481] Przetwarzanie: WR0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4181/4481] Przetwarzanie: WR0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.84it/s]\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4182/4481] Przetwarzanie: WR0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4183/4481] Przetwarzanie: WR0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4184/4481] Przetwarzanie: WR0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4185/4481] Przetwarzanie: WR0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4186/4481] Przetwarzanie: WR0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4187/4481] Przetwarzanie: WR0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4188/4481] Przetwarzanie: WR0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4189/4481] Przetwarzanie: WR0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4190/4481] Przetwarzanie: WR0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.03it/s]\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4191/4481] Przetwarzanie: WR0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4192/4481] Przetwarzanie: WR0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4193/4481] Przetwarzanie: WR0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4194/4481] Przetwarzanie: WR0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4195/4481] Przetwarzanie: WR0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4196/4481] Przetwarzanie: WR0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4197/4481] Przetwarzanie: WR0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4198/4481] Przetwarzanie: WR0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4199/4481] Przetwarzanie: WR0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4200/4481] Przetwarzanie: WR0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4201/4481] Przetwarzanie: WR0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4202/4481] Przetwarzanie: WR0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.40it/s]\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4203/4481] Przetwarzanie: WR0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4204/4481] Przetwarzanie: WR0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.53it/s]\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4205/4481] Przetwarzanie: WR0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.67it/s]\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:47:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4206/4481] Przetwarzanie: WR0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4207/4481] Przetwarzanie: WR0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4208/4481] Przetwarzanie: WR0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4209/4481] Przetwarzanie: WR0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.13it/s]\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4210/4481] Przetwarzanie: WR0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4211/4481] Przetwarzanie: WR0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.31it/s]\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4212/4481] Przetwarzanie: WR0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4213/4481] Przetwarzanie: WR0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4214/4481] Przetwarzanie: WR0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4215/4481] Przetwarzanie: WR0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4216/4481] Przetwarzanie: WR0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.69it/s]\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4217/4481] Przetwarzanie: WR0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4218/4481] Przetwarzanie: WR0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.90it/s]\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4219/4481] Przetwarzanie: WR0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.59it/s]\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4220/4481] Przetwarzanie: WR0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4221/4481] Przetwarzanie: WR0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.58it/s]\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4222/4481] Przetwarzanie: WR0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4223/4481] Przetwarzanie: WR0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.74it/s]\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4224/4481] Przetwarzanie: WR0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4225/4481] Przetwarzanie: WR0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4226/4481] Przetwarzanie: WR0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4227/4481] Przetwarzanie: WR0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.22it/s]\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4228/4481] Przetwarzanie: WR0_neutral_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4229/4481] Przetwarzanie: WR0_neutral_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.63it/s]\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4230/4481] Przetwarzanie: WR0_neutral_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4231/4481] Przetwarzanie: WR0_neutral_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4232/4481] Przetwarzanie: WR0_neutral_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4233/4481] Przetwarzanie: WR0_neutral_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4234/4481] Przetwarzanie: WR0_neutral_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4235/4481] Przetwarzanie: WR0_neutral_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4236/4481] Przetwarzanie: WR0_neutral_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.83it/s]\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4237/4481] Przetwarzanie: WR0_neutral_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4238/4481] Przetwarzanie: WR0_neutral_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.21it/s]\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4239/4481] Przetwarzanie: WR0_neutral_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4240/4481] Przetwarzanie: WR0_neutral_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4241/4481] Przetwarzanie: WR0_neutral_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4242/4481] Przetwarzanie: WR0_neutral_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.41it/s]\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4243/4481] Przetwarzanie: WR0_neutral_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4244/4481] Przetwarzanie: WR0_neutral_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4245/4481] Przetwarzanie: WR0_neutral_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4246/4481] Przetwarzanie: WR0_neutral_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4247/4481] Przetwarzanie: WR0_neutral_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.28it/s]\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4248/4481] Przetwarzanie: WR0_neutral_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4249/4481] Przetwarzanie: WR0_neutral_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4250/4481] Przetwarzanie: WR0_neutral_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4251/4481] Przetwarzanie: WR0_neutral_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4252/4481] Przetwarzanie: WR0_neutral_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4253/4481] Przetwarzanie: WR0_neutral_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4254/4481] Przetwarzanie: WR0_neutral_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4255/4481] Przetwarzanie: WR0_neutral_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4256/4481] Przetwarzanie: WR0_neutral_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.07it/s]\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4257/4481] Przetwarzanie: WR0_neutral_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4258/4481] Przetwarzanie: WR0_neutral_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4259/4481] Przetwarzanie: WR0_neutral_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4260/4481] Przetwarzanie: WR0_neutral_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4261/4481] Przetwarzanie: WR0_neutral_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.91it/s]\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4262/4481] Przetwarzanie: WR0_neutral_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4263/4481] Przetwarzanie: WR0_neutral_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4264/4481] Przetwarzanie: WR0_neutral_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4265/4481] Przetwarzanie: WR0_neutral_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.69it/s]\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4266/4481] Przetwarzanie: WR0_neutral_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4267/4481] Przetwarzanie: WR0_neutral_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.57it/s]\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4268/4481] Przetwarzanie: WR0_neutral_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.67it/s]\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4269/4481] Przetwarzanie: WR0_neutral_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4270/4481] Przetwarzanie: WR0_neutral_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.87it/s]\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4271/4481] Przetwarzanie: WR0_neutral_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4272/4481] Przetwarzanie: WR0_neutral_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4273/4481] Przetwarzanie: WR0_neutral_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4274/4481] Przetwarzanie: WR0_neutral_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4275/4481] Przetwarzanie: WR0_neutral_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.23it/s]\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4276/4481] Przetwarzanie: WR0_neutral_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4277/4481] Przetwarzanie: WR0_neutral_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4278/4481] Przetwarzanie: WR0_neutral_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4279/4481] Przetwarzanie: WR0_neutral_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.05it/s]\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4280/4481] Przetwarzanie: WR0_neutral_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.69it/s]\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4281/4481] Przetwarzanie: WR0_neutral_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4282/4481] Przetwarzanie: WR0_neutral_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4283/4481] Przetwarzanie: WR0_neutral_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4284/4481] Przetwarzanie: WR0_neutral_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.24it/s]\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4285/4481] Przetwarzanie: WR0_neutral_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4286/4481] Przetwarzanie: WR0_neutral_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4287/4481] Przetwarzanie: WR0_neutral_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4288/4481] Przetwarzanie: WR0_neutral_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4289/4481] Przetwarzanie: WR0_neutral_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4290/4481] Przetwarzanie: WR0_neutral_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.95it/s]\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4291/4481] Przetwarzanie: WR0_neutral_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.36it/s]\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4292/4481] Przetwarzanie: WR0_neutral_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4293/4481] Przetwarzanie: WR0_neutral_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4294/4481] Przetwarzanie: WR0_neutral_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.68it/s]\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4295/4481] Przetwarzanie: WR0_neutral_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.08it/s]\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4296/4481] Przetwarzanie: WR0_neutral_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.10it/s]\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4297/4481] Przetwarzanie: WR0_neutral_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4298/4481] Przetwarzanie: WR0_neutral_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.99it/s]\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4299/4481] Przetwarzanie: WR0_neutral_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.22it/s]\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4300/4481] Przetwarzanie: WR0_neutral_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.25it/s]\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4301/4481] Przetwarzanie: WR0_neutral_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.97it/s]\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4302/4481] Przetwarzanie: WR0_sadness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.62it/s]\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4303/4481] Przetwarzanie: WR0_sadness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4304/4481] Przetwarzanie: WR0_sadness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4305/4481] Przetwarzanie: WR0_sadness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4306/4481] Przetwarzanie: WR0_sadness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.57it/s]\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4307/4481] Przetwarzanie: WR0_sadness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.18it/s]\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4308/4481] Przetwarzanie: WR0_sadness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4309/4481] Przetwarzanie: WR0_sadness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4310/4481] Przetwarzanie: WR0_sadness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4311/4481] Przetwarzanie: WR0_sadness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4312/4481] Przetwarzanie: WR0_sadness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4313/4481] Przetwarzanie: WR0_sadness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4314/4481] Przetwarzanie: WR0_sadness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.51it/s]\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4315/4481] Przetwarzanie: WR0_sadness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4316/4481] Przetwarzanie: WR0_sadness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4317/4481] Przetwarzanie: WR0_sadness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.26it/s]\n",
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4318/4481] Przetwarzanie: WR0_sadness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4319/4481] Przetwarzanie: WR0_sadness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4320/4481] Przetwarzanie: WR0_sadness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4321/4481] Przetwarzanie: WR0_sadness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4322/4481] Przetwarzanie: WR0_sadness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.52it/s]\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4323/4481] Przetwarzanie: WR0_sadness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4324/4481] Przetwarzanie: WR0_sadness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.19it/s]\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4325/4481] Przetwarzanie: WR0_sadness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4326/4481] Przetwarzanie: WR0_sadness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4327/4481] Przetwarzanie: WR0_sadness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4328/4481] Przetwarzanie: WR0_sadness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.20it/s]\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4329/4481] Przetwarzanie: WR0_sadness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4330/4481] Przetwarzanie: WR0_sadness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4331/4481] Przetwarzanie: WR0_sadness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.43it/s]\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4332/4481] Przetwarzanie: WR0_sadness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4333/4481] Przetwarzanie: WR0_sadness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4334/4481] Przetwarzanie: WR0_sadness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4335/4481] Przetwarzanie: WR0_sadness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.20it/s]\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4336/4481] Przetwarzanie: WR0_sadness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4337/4481] Przetwarzanie: WR0_sadness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.95it/s]\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4338/4481] Przetwarzanie: WR0_sadness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.07it/s]\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4339/4481] Przetwarzanie: WR0_sadness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4340/4481] Przetwarzanie: WR0_sadness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4341/4481] Przetwarzanie: WR0_sadness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.37it/s]\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4342/4481] Przetwarzanie: WR0_sadness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.54it/s]\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4343/4481] Przetwarzanie: WR0_sadness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4344/4481] Przetwarzanie: WR0_sadness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4345/4481] Przetwarzanie: WR0_sadness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4346/4481] Przetwarzanie: WR0_sadness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.16it/s]\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4347/4481] Przetwarzanie: WR0_sadness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4348/4481] Przetwarzanie: WR0_sadness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4349/4481] Przetwarzanie: WR0_sadness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4350/4481] Przetwarzanie: WR0_sadness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.35it/s]\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4351/4481] Przetwarzanie: WR0_sadness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.85it/s]\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4352/4481] Przetwarzanie: WR0_sadness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4353/4481] Przetwarzanie: WR0_sadness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4354/4481] Przetwarzanie: WR0_sadness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.71it/s]\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4355/4481] Przetwarzanie: WR0_sadness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.65it/s]\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4356/4481] Przetwarzanie: WR0_sadness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.89it/s]\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4357/4481] Przetwarzanie: WR0_sadness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4358/4481] Przetwarzanie: WR0_sadness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4359/4481] Przetwarzanie: WR0_sadness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4360/4481] Przetwarzanie: WR0_sadness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.76it/s]\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4361/4481] Przetwarzanie: WR0_sadness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.22it/s]\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4362/4481] Przetwarzanie: WR0_sadness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4363/4481] Przetwarzanie: WR0_sadness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4364/4481] Przetwarzanie: WR0_sadness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.66it/s]\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4365/4481] Przetwarzanie: WR0_sadness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4366/4481] Przetwarzanie: WR0_sadness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.39it/s]\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4367/4481] Przetwarzanie: WR0_sadness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.44it/s]\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4368/4481] Przetwarzanie: WR0_sadness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4369/4481] Przetwarzanie: WR0_sadness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.06it/s]\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4370/4481] Przetwarzanie: WR0_sadness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.43it/s]\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4371/4481] Przetwarzanie: WR0_sadness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4372/4481] Przetwarzanie: WR0_sadness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.18it/s]\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4373/4481] Przetwarzanie: WR0_sadness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4374/4481] Przetwarzanie: WR0_sadness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4375/4481] Przetwarzanie: WR0_sadness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.25it/s]\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4376/4481] Przetwarzanie: WR0_sadness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.81it/s]\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4377/4481] Przetwarzanie: WR0_sadness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.67it/s]\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4378/4481] Przetwarzanie: WR0_sadness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.19it/s]\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4379/4481] Przetwarzanie: WR0_sadness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.60it/s]\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4380/4481] Przetwarzanie: WR0_sadness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.85it/s]\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4381/4481] Przetwarzanie: WR0_sadness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.38it/s]\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4382/4481] Przetwarzanie: WR0_sadness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4383/4481] Przetwarzanie: WR0_sadness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.04it/s]\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4384/4481] Przetwarzanie: WR0_sadness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4385/4481] Przetwarzanie: WR0_sadness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4386/4481] Przetwarzanie: WR0_sadness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4387/4481] Przetwarzanie: WR0_sadness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.86it/s]\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4388/4481] Przetwarzanie: WR0_sadness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.98it/s]\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4389/4481] Przetwarzanie: WR0_sadness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.24it/s]\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4390/4481] Przetwarzanie: WR0_sadness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.71it/s]\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4391/4481] Przetwarzanie: WR0_sadness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  3.86it/s]\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4392/4481] Przetwarzanie: WR0_surprised_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4393/4481] Przetwarzanie: WR0_surprised_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4394/4481] Przetwarzanie: WR0_surprised_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4395/4481] Przetwarzanie: WR0_surprised_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.23it/s]\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4396/4481] Przetwarzanie: WR0_surprised_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.71it/s]\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4397/4481] Przetwarzanie: WR0_surprised_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.24it/s]\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4398/4481] Przetwarzanie: WR0_surprised_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.27it/s]\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4399/4481] Przetwarzanie: WR0_surprised_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4400/4481] Przetwarzanie: WR0_surprised_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4401/4481] Przetwarzanie: WR0_surprised_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4402/4481] Przetwarzanie: WR0_surprised_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.46it/s]\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4403/4481] Przetwarzanie: WR0_surprised_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.72it/s]\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4404/4481] Przetwarzanie: WR0_surprised_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.49it/s]\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4405/4481] Przetwarzanie: WR0_surprised_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.45it/s]\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4406/4481] Przetwarzanie: WR0_surprised_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.27it/s]\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4407/4481] Przetwarzanie: WR0_surprised_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.19it/s]\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4408/4481] Przetwarzanie: WR0_surprised_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.54it/s]\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4409/4481] Przetwarzanie: WR0_surprised_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4410/4481] Przetwarzanie: WR0_surprised_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4411/4481] Przetwarzanie: WR0_surprised_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.23it/s]\n",
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4412/4481] Przetwarzanie: WR0_surprised_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4413/4481] Przetwarzanie: WR0_surprised_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4414/4481] Przetwarzanie: WR0_surprised_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  8.17it/s]\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4415/4481] Przetwarzanie: WR0_surprised_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.68it/s]\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4416/4481] Przetwarzanie: WR0_surprised_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.53it/s]\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4417/4481] Przetwarzanie: WR0_surprised_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4418/4481] Przetwarzanie: WR0_surprised_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.06it/s]\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4419/4481] Przetwarzanie: WR0_surprised_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4420/4481] Przetwarzanie: WR0_surprised_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.56it/s]\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4421/4481] Przetwarzanie: WR0_surprised_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.69it/s]\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4422/4481] Przetwarzanie: WR0_surprised_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.32it/s]\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4423/4481] Przetwarzanie: WR0_surprised_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4424/4481] Przetwarzanie: WR0_surprised_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.47it/s]\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4425/4481] Przetwarzanie: WR0_surprised_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.18it/s]\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4426/4481] Przetwarzanie: WR0_surprised_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4427/4481] Przetwarzanie: WR0_surprised_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  7.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4428/4481] Przetwarzanie: WR0_surprised_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.98it/s]\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4429/4481] Przetwarzanie: WR0_surprised_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4430/4481] Przetwarzanie: WR0_surprised_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.72it/s]\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4431/4481] Przetwarzanie: WR0_surprised_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4432/4481] Przetwarzanie: WR0_surprised_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.37it/s]\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4433/4481] Przetwarzanie: WR0_surprised_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4434/4481] Przetwarzanie: WR0_surprised_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.28it/s]\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4435/4481] Przetwarzanie: WR0_surprised_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4436/4481] Przetwarzanie: WR0_surprised_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  8.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4437/4481] Przetwarzanie: WR0_surprised_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4438/4481] Przetwarzanie: WR0_surprised_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.87it/s]\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4439/4481] Przetwarzanie: WR0_surprised_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.50it/s]\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4440/4481] Przetwarzanie: WR0_surprised_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.56it/s]\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4441/4481] Przetwarzanie: WR0_surprised_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.99it/s]\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4442/4481] Przetwarzanie: WR0_surprised_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.31it/s]\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4443/4481] Przetwarzanie: WR0_surprised_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4444/4481] Przetwarzanie: WR0_surprised_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4445/4481] Przetwarzanie: WR0_surprised_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.70it/s]\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4446/4481] Przetwarzanie: WR0_surprised_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4447/4481] Przetwarzanie: WR0_surprised_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.63it/s]\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4448/4481] Przetwarzanie: WR0_surprised_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4449/4481] Przetwarzanie: WR0_surprised_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4450/4481] Przetwarzanie: WR0_surprised_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  6.75it/s]\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4451/4481] Przetwarzanie: WR0_surprised_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.26it/s]\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4452/4481] Przetwarzanie: WR0_surprised_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.02it/s]\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4453/4481] Przetwarzanie: WR0_surprised_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.30it/s]\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4454/4481] Przetwarzanie: WR0_surprised_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4455/4481] Przetwarzanie: WR0_surprised_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4456/4481] Przetwarzanie: WR0_surprised_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.57it/s]\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4457/4481] Przetwarzanie: WR0_surprised_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.48it/s]\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4458/4481] Przetwarzanie: WR0_surprised_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  6.32it/s]\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4459/4481] Przetwarzanie: WR0_surprised_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.08it/s]\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4460/4481] Przetwarzanie: WR0_surprised_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4461/4481] Przetwarzanie: WR0_surprised_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4462/4481] Przetwarzanie: WR0_surprised_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4463/4481] Przetwarzanie: WR0_surprised_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4464/4481] Przetwarzanie: WR0_surprised_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4465/4481] Przetwarzanie: WR0_surprised_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.29it/s]\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4466/4481] Przetwarzanie: WR0_surprised_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4467/4481] Przetwarzanie: WR0_surprised_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4468/4481] Przetwarzanie: WR0_surprised_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.27it/s]\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4469/4481] Przetwarzanie: WR0_surprised_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.75it/s]\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4470/4481] Przetwarzanie: WR0_surprised_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.83it/s]\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4471/4481] Przetwarzanie: WR0_surprised_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.42it/s]\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4472/4481] Przetwarzanie: WR0_surprised_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4473/4481] Przetwarzanie: WR0_surprised_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:00,  4.90it/s]\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4474/4481] Przetwarzanie: WR0_surprised_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.73it/s]\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4475/4481] Przetwarzanie: WR0_surprised_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.12it/s]\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4476/4481] Przetwarzanie: WR0_surprised_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.14it/s]\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4477/4481] Przetwarzanie: WR0_surprised_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.88it/s]\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4478/4481] Przetwarzanie: WR0_surprised_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.02it/s]\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4479/4481] Przetwarzanie: WR0_surprised_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.26it/s]\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4480/4481] Przetwarzanie: WR0_surprised_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  7.35it/s]\n",
      "[NeMo W 2026-01-08 11:48:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 11:48:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4481/4481] Przetwarzanie: WR0_surprised_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Utworzono DataFrame z 4481 wierszami\n",
      "  phraseNumber speaker emotion                                transcript\n",
      "0            1     EB0   anger                  Lubię czytać przed snem.\n",
      "1           10     EB0   anger           Kupiłem nową szafę do sypialni.\n",
      "2           11     EB0   anger             Nie zachowuj się jak żigolek.\n",
      "3           12     EB0   anger                Mój też zawsze służy radą.\n",
      "4           13     EB0   anger          Interesuje mnie historia Polski.\n",
      "5           14     EB0   anger          Ten miesiąc minął bardzo szybko.\n",
      "6           15     EB0   anger          sporadycznie chodzę na siłowinę.\n",
      "7           16     EB0   anger         Racja, ten pomysł jest najlepszy.\n",
      "8           17     EB0   anger  Chcę przeczytać ten artykuł jeszcze raz.\n",
      "9           18     EB0   anger       Kwiecień to czwarty miesiąc w roku.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Folder z plikami audio\n",
    "audio_folder = Path(path)\n",
    "\n",
    "# Lista do przechowywania wyników\n",
    "results = []\n",
    "\n",
    "# Iteracja przez wszystkie pliki WAV\n",
    "wav_files = sorted(audio_folder.glob(\"*.wav\"))\n",
    "print(f\"Znaleziono {len(wav_files)} plików WAV\")\n",
    "\n",
    "for i, wav_file in enumerate(wav_files, 1):\n",
    "    # Parsowanie nazwy pliku: speaker_emotion_phraseNumber.wav\n",
    "    filename = wav_file.stem  # nazwa bez rozszerzenia\n",
    "    \n",
    "    # Rozdzielenie na części (speaker, emotion, phraseNumber)\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        speaker = parts[0]\n",
    "        emotion = parts[1]\n",
    "        phrase_number = parts[2]\n",
    "        \n",
    "        # Transkrypcja audio\n",
    "        print(f\"[{i}/{len(wav_files)}] Przetwarzanie: {wav_file.name}\")\n",
    "        try:\n",
    "            output = asr_ast_model.transcribe(\n",
    "                [str(wav_file)], \n",
    "                source_lang='pl', \n",
    "                target_lang='pl'\n",
    "            )\n",
    "            transcript = output[0].text\n",
    "            \n",
    "            # Dodanie do wyników\n",
    "            results.append({\n",
    "                'phraseNumber': phrase_number,\n",
    "                'speaker': speaker,\n",
    "                'emotion': emotion,\n",
    "                'transcript': transcript\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  Błąd przy przetwarzaniu {wav_file.name}: {e}\")\n",
    "            results.append({\n",
    "                'phraseNumber': phrase_number,\n",
    "                'speaker': speaker,\n",
    "                'emotion': emotion,\n",
    "                'transcript': f\"ERROR: {e}\"\n",
    "            })\n",
    "    else:\n",
    "        print(f\"  Pominięto plik o nieoczekiwanej nazwie: {wav_file.name}\")\n",
    "\n",
    "# Utworzenie DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"\\nUtworzono DataFrame z {len(df)} wierszami\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61083ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"canary_nemo_transcript.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea236df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e627c68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przygotowano 4481 par do porównania\n",
      "   phraseNumber                  normalized_text  \\\n",
      "0             1          lubię czytać przed snem   \n",
      "1            10   kupiłem nową szafę do sypialni   \n",
      "2            11     nie zachowuj się jak żigolak   \n",
      "3            12       mój teść zawsze służy radą   \n",
      "4            13  interesuje mnie historia polski   \n",
      "\n",
      "                     ai_normalized  \n",
      "0          lubię czytać przed snem  \n",
      "1   kupiłem nową szafę do sypialni  \n",
      "2     nie zachowuj się jak żigolek  \n",
      "3        mój też zawsze służy radą  \n",
      "4  interesuje mnie historia polski  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Inicjalizacja klienta OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalizuje tekst: usuwa interpunkcję i zamienia na małe litery\"\"\"\n",
    "    # Usuń znaki interpunkcyjne\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Zamień na małe litery i usuń zbędne spacje\n",
    "    text = ' '.join(text.lower().split())\n",
    "    return text\n",
    "\n",
    "# Przygotowanie danych - normalizacja transkryptów AI\n",
    "df['ai_normalized'] = df['transcript'].apply(normalize_text)\n",
    "\n",
    "# Konwersja phraseNumber na int (jest stringiem z nazwy pliku)\n",
    "df['phraseNumber'] = df['phraseNumber'].astype(int)\n",
    "\n",
    "# Łączenie dataframes po numerze zdania\n",
    "# obj ma 'sentence' jako indeks, więc resetujemy indeks\n",
    "obj_reset = obj.reset_index()\n",
    "comparison_df = df.merge(\n",
    "    obj_reset[['sentence', 'normalized_text']], \n",
    "    left_on='phraseNumber', \n",
    "    right_on='sentence',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Przygotowano {len(comparison_df)} par do porównania\")\n",
    "print(comparison_df[['phraseNumber', 'normalized_text', 'ai_normalized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4078bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dopasowanie 1:1: 2945 / 4481 (65.72%)\n",
      "\n",
      "Przykłady niedopasowanych:\n",
      "\n",
      "GT:  nie zachowuj się jak żigolak\n",
      "AI:  nie zachowuj się jak żigolek\n",
      "\n",
      "GT:  mój teść zawsze służy radą\n",
      "AI:  mój też zawsze służy radą\n",
      "\n",
      "GT:  sporadycznie chodzę na siłownię\n",
      "AI:  sporadycznie chodzę na siłowinę\n",
      "\n",
      "GT:  nie waśńmy się ze sobą\n",
      "AI:  nie waśnijmy się ze sobą\n",
      "\n",
      "GT:  zima to czas jeżdżenia na sankach\n",
      "AI:  zima to czas jazdzenia na sankach\n",
      "\n",
      "GT:  egipcjanie uważali ibisy za święte\n",
      "AI:  egipcjanie uważali ibisy za święta\n",
      "\n",
      "GT:  miasto tętni życiem nawet w nocy\n",
      "AI:  miasto ten dni życia nawet w nocy\n",
      "\n",
      "GT:  gorzka czekolada jest idealna na deser\n",
      "AI:  górzka czekolada jest idealna na deser\n",
      "\n",
      "GT:  ten dżin potrafi spełniać życzenia\n",
      "AI:  ten gen potrafi spełniać życzenia\n",
      "\n",
      "GT:  podczas medytacji można wejść w trans\n",
      "AI:  podczas medytacji można wejść w trance\n"
     ]
    }
   ],
   "source": [
    "# Porównanie 1:1 (exact match)\n",
    "comparison_df['1_1_match'] = comparison_df['normalized_text'] == comparison_df['ai_normalized']\n",
    "\n",
    "print(f\"Dopasowanie 1:1: {comparison_df['1_1_match'].sum()} / {len(comparison_df)} ({comparison_df['1_1_match'].mean()*100:.2f}%)\")\n",
    "print(\"\\nPrzykłady niedopasowanych:\")\n",
    "mismatches = comparison_df[~comparison_df['1_1_match']][['normalized_text', 'ai_normalized']].head(10)\n",
    "for idx, row in mismatches.iterrows():\n",
    "    print(f\"\\nGT:  {row['normalized_text']}\")\n",
    "    print(f\"AI:  {row['ai_normalized']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b48d943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generowanie embeddingów dla ground truth...\n",
      "  Ground truth: 10/4481\n",
      "  Ground truth: 20/4481\n",
      "  Ground truth: 30/4481\n",
      "  Ground truth: 40/4481\n",
      "  Ground truth: 50/4481\n",
      "  Ground truth: 60/4481\n",
      "  Ground truth: 70/4481\n",
      "  Ground truth: 80/4481\n",
      "  Ground truth: 90/4481\n",
      "  Ground truth: 100/4481\n",
      "  Ground truth: 110/4481\n",
      "  Ground truth: 120/4481\n",
      "  Ground truth: 130/4481\n",
      "  Ground truth: 140/4481\n",
      "  Ground truth: 150/4481\n",
      "  Ground truth: 160/4481\n",
      "  Ground truth: 170/4481\n",
      "  Ground truth: 180/4481\n",
      "  Ground truth: 190/4481\n",
      "  Ground truth: 200/4481\n",
      "  Ground truth: 210/4481\n",
      "  Ground truth: 220/4481\n",
      "  Ground truth: 230/4481\n",
      "  Ground truth: 240/4481\n",
      "  Ground truth: 250/4481\n",
      "  Ground truth: 260/4481\n",
      "  Ground truth: 270/4481\n",
      "  Ground truth: 280/4481\n",
      "  Ground truth: 290/4481\n",
      "  Ground truth: 300/4481\n",
      "  Ground truth: 310/4481\n",
      "  Ground truth: 320/4481\n",
      "  Ground truth: 330/4481\n",
      "  Ground truth: 340/4481\n",
      "  Ground truth: 350/4481\n",
      "  Ground truth: 360/4481\n",
      "  Ground truth: 370/4481\n",
      "  Ground truth: 380/4481\n",
      "  Ground truth: 390/4481\n",
      "  Ground truth: 400/4481\n",
      "  Ground truth: 410/4481\n",
      "  Ground truth: 420/4481\n",
      "  Ground truth: 430/4481\n",
      "  Ground truth: 440/4481\n",
      "  Ground truth: 450/4481\n",
      "  Ground truth: 460/4481\n",
      "  Ground truth: 470/4481\n",
      "  Ground truth: 480/4481\n",
      "  Ground truth: 490/4481\n",
      "  Ground truth: 500/4481\n",
      "  Ground truth: 510/4481\n",
      "  Ground truth: 520/4481\n",
      "  Ground truth: 530/4481\n",
      "  Ground truth: 540/4481\n",
      "  Ground truth: 550/4481\n",
      "  Ground truth: 560/4481\n",
      "  Ground truth: 570/4481\n",
      "  Ground truth: 580/4481\n",
      "  Ground truth: 590/4481\n",
      "  Ground truth: 600/4481\n",
      "  Ground truth: 610/4481\n",
      "  Ground truth: 620/4481\n",
      "  Ground truth: 630/4481\n",
      "  Ground truth: 640/4481\n",
      "  Ground truth: 650/4481\n",
      "  Ground truth: 660/4481\n",
      "  Ground truth: 670/4481\n",
      "  Ground truth: 680/4481\n",
      "  Ground truth: 690/4481\n",
      "  Ground truth: 700/4481\n",
      "  Ground truth: 710/4481\n",
      "  Ground truth: 720/4481\n",
      "  Ground truth: 730/4481\n",
      "  Ground truth: 740/4481\n",
      "  Ground truth: 750/4481\n",
      "  Ground truth: 760/4481\n",
      "  Ground truth: 770/4481\n",
      "  Ground truth: 780/4481\n",
      "  Ground truth: 790/4481\n",
      "  Ground truth: 800/4481\n",
      "  Ground truth: 810/4481\n",
      "  Ground truth: 820/4481\n",
      "  Ground truth: 830/4481\n",
      "  Ground truth: 840/4481\n",
      "  Ground truth: 850/4481\n",
      "  Ground truth: 860/4481\n",
      "  Ground truth: 870/4481\n",
      "  Ground truth: 880/4481\n",
      "  Ground truth: 890/4481\n",
      "  Ground truth: 900/4481\n",
      "  Ground truth: 910/4481\n",
      "  Ground truth: 920/4481\n",
      "  Ground truth: 930/4481\n",
      "  Ground truth: 940/4481\n",
      "  Ground truth: 950/4481\n",
      "  Ground truth: 960/4481\n",
      "  Ground truth: 970/4481\n",
      "  Ground truth: 980/4481\n",
      "  Ground truth: 990/4481\n",
      "  Ground truth: 1000/4481\n",
      "  Ground truth: 1010/4481\n",
      "  Ground truth: 1020/4481\n",
      "  Ground truth: 1030/4481\n",
      "  Ground truth: 1040/4481\n",
      "  Ground truth: 1050/4481\n",
      "  Ground truth: 1060/4481\n",
      "  Ground truth: 1070/4481\n",
      "  Ground truth: 1080/4481\n",
      "  Ground truth: 1090/4481\n",
      "  Ground truth: 1100/4481\n",
      "  Ground truth: 1110/4481\n",
      "  Ground truth: 1120/4481\n",
      "  Ground truth: 1130/4481\n",
      "  Ground truth: 1140/4481\n",
      "  Ground truth: 1150/4481\n",
      "  Ground truth: 1160/4481\n",
      "  Ground truth: 1170/4481\n",
      "  Ground truth: 1180/4481\n",
      "  Ground truth: 1190/4481\n",
      "  Ground truth: 1200/4481\n",
      "  Ground truth: 1210/4481\n",
      "  Ground truth: 1220/4481\n",
      "  Ground truth: 1230/4481\n",
      "  Ground truth: 1240/4481\n",
      "  Ground truth: 1250/4481\n",
      "  Ground truth: 1260/4481\n",
      "  Ground truth: 1270/4481\n",
      "  Ground truth: 1280/4481\n",
      "  Ground truth: 1290/4481\n",
      "  Ground truth: 1300/4481\n",
      "  Ground truth: 1310/4481\n",
      "  Ground truth: 1320/4481\n",
      "  Ground truth: 1330/4481\n",
      "  Ground truth: 1340/4481\n",
      "  Ground truth: 1350/4481\n",
      "  Ground truth: 1360/4481\n",
      "  Ground truth: 1370/4481\n",
      "  Ground truth: 1380/4481\n",
      "  Ground truth: 1390/4481\n",
      "  Ground truth: 1400/4481\n",
      "  Ground truth: 1410/4481\n",
      "  Ground truth: 1420/4481\n",
      "  Ground truth: 1430/4481\n",
      "  Ground truth: 1440/4481\n",
      "  Ground truth: 1450/4481\n",
      "  Ground truth: 1460/4481\n",
      "  Ground truth: 1470/4481\n",
      "  Ground truth: 1480/4481\n",
      "  Ground truth: 1490/4481\n",
      "  Ground truth: 1500/4481\n",
      "  Ground truth: 1510/4481\n",
      "  Ground truth: 1520/4481\n",
      "  Ground truth: 1530/4481\n",
      "  Ground truth: 1540/4481\n",
      "  Ground truth: 1550/4481\n",
      "  Ground truth: 1560/4481\n",
      "  Ground truth: 1570/4481\n",
      "  Ground truth: 1580/4481\n",
      "  Ground truth: 1590/4481\n",
      "  Ground truth: 1600/4481\n",
      "  Ground truth: 1610/4481\n",
      "  Ground truth: 1620/4481\n",
      "  Ground truth: 1630/4481\n",
      "  Ground truth: 1640/4481\n",
      "  Ground truth: 1650/4481\n",
      "  Ground truth: 1660/4481\n",
      "  Ground truth: 1670/4481\n",
      "  Ground truth: 1680/4481\n",
      "  Ground truth: 1690/4481\n",
      "  Ground truth: 1700/4481\n",
      "  Ground truth: 1710/4481\n",
      "  Ground truth: 1720/4481\n",
      "  Ground truth: 1730/4481\n",
      "  Ground truth: 1740/4481\n",
      "  Ground truth: 1750/4481\n",
      "  Ground truth: 1760/4481\n",
      "  Ground truth: 1770/4481\n",
      "  Ground truth: 1780/4481\n",
      "  Ground truth: 1790/4481\n",
      "  Ground truth: 1800/4481\n",
      "  Ground truth: 1810/4481\n",
      "  Ground truth: 1820/4481\n",
      "  Ground truth: 1830/4481\n",
      "  Ground truth: 1840/4481\n",
      "  Ground truth: 1850/4481\n",
      "  Ground truth: 1860/4481\n",
      "  Ground truth: 1870/4481\n",
      "  Ground truth: 1880/4481\n",
      "  Ground truth: 1890/4481\n",
      "  Ground truth: 1900/4481\n",
      "  Ground truth: 1910/4481\n",
      "  Ground truth: 1920/4481\n",
      "  Ground truth: 1930/4481\n",
      "  Ground truth: 1940/4481\n",
      "  Ground truth: 1950/4481\n",
      "  Ground truth: 1960/4481\n",
      "  Ground truth: 1970/4481\n",
      "  Ground truth: 1980/4481\n",
      "  Ground truth: 1990/4481\n",
      "  Ground truth: 2000/4481\n",
      "  Ground truth: 2010/4481\n",
      "  Ground truth: 2020/4481\n",
      "  Ground truth: 2030/4481\n",
      "  Ground truth: 2040/4481\n",
      "  Ground truth: 2050/4481\n",
      "  Ground truth: 2060/4481\n",
      "  Ground truth: 2070/4481\n",
      "  Ground truth: 2080/4481\n",
      "  Ground truth: 2090/4481\n",
      "  Ground truth: 2100/4481\n",
      "  Ground truth: 2110/4481\n",
      "  Ground truth: 2120/4481\n",
      "  Ground truth: 2130/4481\n",
      "  Ground truth: 2140/4481\n",
      "  Ground truth: 2150/4481\n",
      "  Ground truth: 2160/4481\n",
      "  Ground truth: 2170/4481\n",
      "  Ground truth: 2180/4481\n",
      "  Ground truth: 2190/4481\n",
      "  Ground truth: 2200/4481\n",
      "  Ground truth: 2210/4481\n",
      "  Ground truth: 2220/4481\n",
      "  Ground truth: 2230/4481\n",
      "  Ground truth: 2240/4481\n",
      "  Ground truth: 2250/4481\n",
      "  Ground truth: 2260/4481\n",
      "  Ground truth: 2270/4481\n",
      "  Ground truth: 2280/4481\n",
      "  Ground truth: 2290/4481\n",
      "  Ground truth: 2300/4481\n",
      "  Ground truth: 2310/4481\n",
      "  Ground truth: 2320/4481\n",
      "  Ground truth: 2330/4481\n",
      "  Ground truth: 2340/4481\n",
      "  Ground truth: 2350/4481\n",
      "  Ground truth: 2360/4481\n",
      "  Ground truth: 2370/4481\n",
      "  Ground truth: 2380/4481\n",
      "  Ground truth: 2390/4481\n",
      "  Ground truth: 2400/4481\n",
      "  Ground truth: 2410/4481\n",
      "  Ground truth: 2420/4481\n",
      "  Ground truth: 2430/4481\n",
      "  Ground truth: 2440/4481\n",
      "  Ground truth: 2450/4481\n",
      "  Ground truth: 2460/4481\n",
      "  Ground truth: 2470/4481\n",
      "  Ground truth: 2480/4481\n",
      "  Ground truth: 2490/4481\n",
      "  Ground truth: 2500/4481\n",
      "  Ground truth: 2510/4481\n",
      "  Ground truth: 2520/4481\n",
      "  Ground truth: 2530/4481\n",
      "  Ground truth: 2540/4481\n",
      "  Ground truth: 2550/4481\n",
      "  Ground truth: 2560/4481\n",
      "  Ground truth: 2570/4481\n",
      "  Ground truth: 2580/4481\n",
      "  Ground truth: 2590/4481\n",
      "  Ground truth: 2600/4481\n",
      "  Ground truth: 2610/4481\n",
      "  Ground truth: 2620/4481\n",
      "  Ground truth: 2630/4481\n",
      "  Ground truth: 2640/4481\n",
      "  Ground truth: 2650/4481\n",
      "  Ground truth: 2660/4481\n",
      "  Ground truth: 2670/4481\n",
      "  Ground truth: 2680/4481\n",
      "  Ground truth: 2690/4481\n",
      "  Ground truth: 2700/4481\n",
      "  Ground truth: 2710/4481\n",
      "  Ground truth: 2720/4481\n",
      "  Ground truth: 2730/4481\n",
      "  Ground truth: 2740/4481\n",
      "  Ground truth: 2750/4481\n",
      "  Ground truth: 2760/4481\n",
      "  Ground truth: 2770/4481\n",
      "  Ground truth: 2780/4481\n",
      "  Ground truth: 2790/4481\n",
      "  Ground truth: 2800/4481\n",
      "  Ground truth: 2810/4481\n",
      "  Ground truth: 2820/4481\n",
      "  Ground truth: 2830/4481\n",
      "  Ground truth: 2840/4481\n",
      "  Ground truth: 2850/4481\n",
      "  Ground truth: 2860/4481\n",
      "  Ground truth: 2870/4481\n",
      "  Ground truth: 2880/4481\n",
      "  Ground truth: 2890/4481\n",
      "  Ground truth: 2900/4481\n",
      "  Ground truth: 2910/4481\n",
      "  Ground truth: 2920/4481\n",
      "  Ground truth: 2930/4481\n",
      "  Ground truth: 2940/4481\n",
      "  Ground truth: 2950/4481\n",
      "  Ground truth: 2960/4481\n",
      "  Ground truth: 2970/4481\n",
      "  Ground truth: 2980/4481\n",
      "  Ground truth: 2990/4481\n",
      "  Ground truth: 3000/4481\n",
      "  Ground truth: 3010/4481\n",
      "  Ground truth: 3020/4481\n",
      "  Ground truth: 3030/4481\n",
      "  Ground truth: 3040/4481\n",
      "  Ground truth: 3050/4481\n",
      "  Ground truth: 3060/4481\n",
      "  Ground truth: 3070/4481\n",
      "  Ground truth: 3080/4481\n",
      "  Ground truth: 3090/4481\n",
      "  Ground truth: 3100/4481\n",
      "  Ground truth: 3110/4481\n",
      "  Ground truth: 3120/4481\n",
      "  Ground truth: 3130/4481\n",
      "  Ground truth: 3140/4481\n",
      "  Ground truth: 3150/4481\n",
      "  Ground truth: 3160/4481\n",
      "  Ground truth: 3170/4481\n",
      "  Ground truth: 3180/4481\n",
      "  Ground truth: 3190/4481\n",
      "  Ground truth: 3200/4481\n",
      "  Ground truth: 3210/4481\n",
      "  Ground truth: 3220/4481\n",
      "  Ground truth: 3230/4481\n",
      "  Ground truth: 3240/4481\n",
      "  Ground truth: 3250/4481\n",
      "  Ground truth: 3260/4481\n",
      "  Ground truth: 3270/4481\n",
      "  Ground truth: 3280/4481\n",
      "  Ground truth: 3290/4481\n",
      "  Ground truth: 3300/4481\n",
      "  Ground truth: 3310/4481\n",
      "  Ground truth: 3320/4481\n",
      "  Ground truth: 3330/4481\n",
      "  Ground truth: 3340/4481\n",
      "  Ground truth: 3350/4481\n",
      "  Ground truth: 3360/4481\n",
      "  Ground truth: 3370/4481\n",
      "  Ground truth: 3380/4481\n",
      "  Ground truth: 3390/4481\n",
      "  Ground truth: 3400/4481\n",
      "  Ground truth: 3410/4481\n",
      "  Ground truth: 3420/4481\n",
      "  Ground truth: 3430/4481\n",
      "  Ground truth: 3440/4481\n",
      "  Ground truth: 3450/4481\n",
      "  Ground truth: 3460/4481\n",
      "  Ground truth: 3470/4481\n",
      "  Ground truth: 3480/4481\n",
      "  Ground truth: 3490/4481\n",
      "  Ground truth: 3500/4481\n",
      "  Ground truth: 3510/4481\n",
      "  Ground truth: 3520/4481\n",
      "  Ground truth: 3530/4481\n",
      "  Ground truth: 3540/4481\n",
      "  Ground truth: 3550/4481\n",
      "  Ground truth: 3560/4481\n",
      "  Ground truth: 3570/4481\n",
      "  Ground truth: 3580/4481\n",
      "  Ground truth: 3590/4481\n",
      "  Ground truth: 3600/4481\n",
      "  Ground truth: 3610/4481\n",
      "  Ground truth: 3620/4481\n",
      "  Ground truth: 3630/4481\n",
      "  Ground truth: 3640/4481\n",
      "  Ground truth: 3650/4481\n",
      "  Ground truth: 3660/4481\n",
      "  Ground truth: 3670/4481\n",
      "  Ground truth: 3680/4481\n",
      "  Ground truth: 3690/4481\n",
      "  Ground truth: 3700/4481\n",
      "  Ground truth: 3710/4481\n",
      "  Ground truth: 3720/4481\n",
      "  Ground truth: 3730/4481\n",
      "  Ground truth: 3740/4481\n",
      "  Ground truth: 3750/4481\n",
      "  Ground truth: 3760/4481\n",
      "  Ground truth: 3770/4481\n",
      "  Ground truth: 3780/4481\n",
      "  Ground truth: 3790/4481\n",
      "  Ground truth: 3800/4481\n",
      "  Ground truth: 3810/4481\n",
      "  Ground truth: 3820/4481\n",
      "  Ground truth: 3830/4481\n",
      "  Ground truth: 3840/4481\n",
      "  Ground truth: 3850/4481\n",
      "  Ground truth: 3860/4481\n",
      "  Ground truth: 3870/4481\n",
      "  Ground truth: 3880/4481\n",
      "  Ground truth: 3890/4481\n",
      "  Ground truth: 3900/4481\n",
      "  Ground truth: 3910/4481\n",
      "  Ground truth: 3920/4481\n",
      "  Ground truth: 3930/4481\n",
      "  Ground truth: 3940/4481\n",
      "  Ground truth: 3950/4481\n",
      "  Ground truth: 3960/4481\n",
      "  Ground truth: 3970/4481\n",
      "  Ground truth: 3980/4481\n",
      "  Ground truth: 3990/4481\n",
      "  Ground truth: 4000/4481\n",
      "  Ground truth: 4010/4481\n",
      "  Ground truth: 4020/4481\n",
      "  Ground truth: 4030/4481\n",
      "  Ground truth: 4040/4481\n",
      "  Ground truth: 4050/4481\n",
      "  Ground truth: 4060/4481\n",
      "  Ground truth: 4070/4481\n",
      "  Ground truth: 4080/4481\n",
      "  Ground truth: 4090/4481\n",
      "  Ground truth: 4100/4481\n",
      "  Ground truth: 4110/4481\n",
      "  Ground truth: 4120/4481\n",
      "  Ground truth: 4130/4481\n",
      "  Ground truth: 4140/4481\n",
      "  Ground truth: 4150/4481\n",
      "  Ground truth: 4160/4481\n",
      "  Ground truth: 4170/4481\n",
      "  Ground truth: 4180/4481\n",
      "  Ground truth: 4190/4481\n",
      "  Ground truth: 4200/4481\n",
      "  Ground truth: 4210/4481\n",
      "  Ground truth: 4220/4481\n",
      "  Ground truth: 4230/4481\n",
      "  Ground truth: 4240/4481\n",
      "  Ground truth: 4250/4481\n",
      "  Ground truth: 4260/4481\n",
      "  Ground truth: 4270/4481\n",
      "  Ground truth: 4280/4481\n",
      "  Ground truth: 4290/4481\n",
      "  Ground truth: 4300/4481\n",
      "  Ground truth: 4310/4481\n",
      "  Ground truth: 4320/4481\n",
      "  Ground truth: 4330/4481\n",
      "  Ground truth: 4340/4481\n",
      "  Ground truth: 4350/4481\n",
      "  Ground truth: 4360/4481\n",
      "  Ground truth: 4370/4481\n",
      "  Ground truth: 4380/4481\n",
      "  Ground truth: 4390/4481\n",
      "  Ground truth: 4400/4481\n",
      "  Ground truth: 4410/4481\n",
      "  Ground truth: 4420/4481\n",
      "  Ground truth: 4430/4481\n",
      "  Ground truth: 4440/4481\n",
      "  Ground truth: 4450/4481\n",
      "  Ground truth: 4460/4481\n",
      "  Ground truth: 4470/4481\n",
      "  Ground truth: 4480/4481\n",
      "\n",
      "Generowanie embeddingów dla transkryptów AI...\n",
      "  AI: 10/4481\n",
      "  AI: 20/4481\n",
      "  AI: 30/4481\n",
      "  AI: 40/4481\n",
      "  AI: 50/4481\n",
      "  AI: 60/4481\n",
      "  AI: 70/4481\n",
      "  AI: 80/4481\n",
      "  AI: 90/4481\n",
      "  AI: 100/4481\n",
      "  AI: 110/4481\n",
      "  AI: 120/4481\n",
      "  AI: 130/4481\n",
      "  AI: 140/4481\n",
      "  AI: 150/4481\n",
      "  AI: 160/4481\n",
      "  AI: 170/4481\n",
      "  AI: 180/4481\n",
      "  AI: 190/4481\n",
      "  AI: 200/4481\n",
      "  AI: 210/4481\n",
      "  AI: 220/4481\n",
      "  AI: 230/4481\n",
      "  AI: 240/4481\n",
      "  AI: 250/4481\n",
      "  AI: 260/4481\n",
      "  AI: 270/4481\n",
      "  AI: 280/4481\n",
      "  AI: 290/4481\n",
      "  AI: 300/4481\n",
      "  AI: 310/4481\n",
      "  AI: 320/4481\n",
      "  AI: 330/4481\n",
      "  AI: 340/4481\n",
      "  AI: 350/4481\n",
      "  AI: 360/4481\n",
      "  AI: 370/4481\n",
      "  AI: 380/4481\n",
      "  AI: 390/4481\n",
      "  AI: 400/4481\n",
      "  AI: 410/4481\n",
      "  AI: 420/4481\n",
      "  AI: 430/4481\n",
      "  AI: 440/4481\n",
      "  AI: 450/4481\n",
      "  AI: 460/4481\n",
      "  AI: 470/4481\n",
      "  AI: 480/4481\n",
      "  AI: 490/4481\n",
      "  AI: 500/4481\n",
      "  AI: 510/4481\n",
      "  AI: 520/4481\n",
      "  AI: 530/4481\n",
      "  AI: 540/4481\n",
      "  AI: 550/4481\n",
      "  AI: 560/4481\n",
      "  AI: 570/4481\n",
      "  AI: 580/4481\n",
      "  AI: 590/4481\n",
      "  AI: 600/4481\n",
      "  AI: 610/4481\n",
      "  AI: 620/4481\n",
      "  AI: 630/4481\n",
      "  AI: 640/4481\n",
      "  AI: 650/4481\n",
      "  AI: 660/4481\n",
      "  AI: 670/4481\n",
      "  AI: 680/4481\n",
      "  AI: 690/4481\n",
      "  AI: 700/4481\n",
      "  AI: 710/4481\n",
      "  AI: 720/4481\n",
      "  AI: 730/4481\n",
      "  AI: 740/4481\n",
      "  AI: 750/4481\n",
      "  AI: 760/4481\n",
      "  AI: 770/4481\n",
      "  AI: 780/4481\n",
      "  AI: 790/4481\n",
      "  AI: 800/4481\n",
      "  AI: 810/4481\n",
      "  AI: 820/4481\n",
      "  AI: 830/4481\n",
      "  AI: 840/4481\n",
      "  AI: 850/4481\n",
      "  AI: 860/4481\n",
      "  AI: 870/4481\n",
      "  AI: 880/4481\n",
      "  AI: 890/4481\n",
      "  AI: 900/4481\n",
      "  AI: 910/4481\n",
      "  AI: 920/4481\n",
      "  AI: 930/4481\n",
      "  AI: 940/4481\n",
      "  AI: 950/4481\n",
      "  AI: 960/4481\n",
      "  AI: 970/4481\n",
      "  AI: 980/4481\n",
      "  AI: 990/4481\n",
      "  AI: 1000/4481\n",
      "  AI: 1010/4481\n",
      "  AI: 1020/4481\n",
      "  AI: 1030/4481\n",
      "  AI: 1040/4481\n",
      "  AI: 1050/4481\n",
      "  AI: 1060/4481\n",
      "  AI: 1070/4481\n",
      "  AI: 1080/4481\n",
      "  AI: 1090/4481\n",
      "  AI: 1100/4481\n",
      "  AI: 1110/4481\n",
      "  AI: 1120/4481\n",
      "  AI: 1130/4481\n",
      "  AI: 1140/4481\n",
      "  AI: 1150/4481\n",
      "  AI: 1160/4481\n",
      "  AI: 1170/4481\n",
      "  AI: 1180/4481\n",
      "  AI: 1190/4481\n",
      "  AI: 1200/4481\n",
      "  AI: 1210/4481\n",
      "  AI: 1220/4481\n",
      "  AI: 1230/4481\n",
      "  AI: 1240/4481\n",
      "  AI: 1250/4481\n",
      "  AI: 1260/4481\n",
      "  AI: 1270/4481\n",
      "  AI: 1280/4481\n",
      "  AI: 1290/4481\n",
      "  AI: 1300/4481\n",
      "  AI: 1310/4481\n",
      "  AI: 1320/4481\n",
      "  AI: 1330/4481\n",
      "  AI: 1340/4481\n",
      "  AI: 1350/4481\n",
      "  AI: 1360/4481\n",
      "  AI: 1370/4481\n",
      "  AI: 1380/4481\n",
      "  AI: 1390/4481\n",
      "  AI: 1400/4481\n",
      "  AI: 1410/4481\n",
      "  AI: 1420/4481\n",
      "  AI: 1430/4481\n",
      "  AI: 1440/4481\n",
      "  AI: 1450/4481\n",
      "  AI: 1460/4481\n",
      "  AI: 1470/4481\n",
      "  AI: 1480/4481\n",
      "  AI: 1490/4481\n",
      "  AI: 1500/4481\n",
      "  AI: 1510/4481\n",
      "  AI: 1520/4481\n",
      "  AI: 1530/4481\n",
      "  AI: 1540/4481\n",
      "  AI: 1550/4481\n",
      "  AI: 1560/4481\n",
      "  AI: 1570/4481\n",
      "  AI: 1580/4481\n",
      "  AI: 1590/4481\n",
      "  AI: 1600/4481\n",
      "  AI: 1610/4481\n",
      "  AI: 1620/4481\n",
      "  AI: 1630/4481\n",
      "  AI: 1640/4481\n",
      "  AI: 1650/4481\n",
      "  AI: 1660/4481\n",
      "  AI: 1670/4481\n",
      "  AI: 1680/4481\n",
      "  AI: 1690/4481\n",
      "  AI: 1700/4481\n",
      "  AI: 1710/4481\n",
      "  AI: 1720/4481\n",
      "  AI: 1730/4481\n",
      "  AI: 1740/4481\n",
      "  AI: 1750/4481\n",
      "  AI: 1760/4481\n",
      "  AI: 1770/4481\n",
      "  AI: 1780/4481\n",
      "  AI: 1790/4481\n",
      "  AI: 1800/4481\n",
      "  AI: 1810/4481\n",
      "  AI: 1820/4481\n",
      "  AI: 1830/4481\n",
      "  AI: 1840/4481\n",
      "  AI: 1850/4481\n",
      "  AI: 1860/4481\n",
      "  AI: 1870/4481\n",
      "  AI: 1880/4481\n",
      "  AI: 1890/4481\n",
      "  AI: 1900/4481\n",
      "  AI: 1910/4481\n",
      "  AI: 1920/4481\n",
      "  AI: 1930/4481\n",
      "  AI: 1940/4481\n",
      "  AI: 1950/4481\n",
      "  AI: 1960/4481\n",
      "  AI: 1970/4481\n",
      "  AI: 1980/4481\n",
      "  AI: 1990/4481\n",
      "  AI: 2000/4481\n",
      "  AI: 2010/4481\n",
      "  AI: 2020/4481\n",
      "  AI: 2030/4481\n",
      "  AI: 2040/4481\n",
      "  AI: 2050/4481\n",
      "  AI: 2060/4481\n",
      "  AI: 2070/4481\n",
      "  AI: 2080/4481\n",
      "  AI: 2090/4481\n",
      "  AI: 2100/4481\n",
      "  AI: 2110/4481\n",
      "  AI: 2120/4481\n",
      "  AI: 2130/4481\n",
      "  AI: 2140/4481\n",
      "  AI: 2150/4481\n",
      "  AI: 2160/4481\n",
      "  AI: 2170/4481\n",
      "  AI: 2180/4481\n",
      "  AI: 2190/4481\n",
      "  AI: 2200/4481\n",
      "  AI: 2210/4481\n",
      "  AI: 2220/4481\n",
      "  AI: 2230/4481\n",
      "  AI: 2240/4481\n",
      "  AI: 2250/4481\n",
      "  AI: 2260/4481\n",
      "  AI: 2270/4481\n",
      "  AI: 2280/4481\n",
      "  AI: 2290/4481\n",
      "  AI: 2300/4481\n",
      "  AI: 2310/4481\n",
      "  AI: 2320/4481\n",
      "  AI: 2330/4481\n",
      "  AI: 2340/4481\n",
      "  AI: 2350/4481\n",
      "  AI: 2360/4481\n",
      "  AI: 2370/4481\n",
      "  AI: 2380/4481\n",
      "  AI: 2390/4481\n",
      "  AI: 2400/4481\n",
      "  AI: 2410/4481\n",
      "  AI: 2420/4481\n",
      "  AI: 2430/4481\n",
      "  AI: 2440/4481\n",
      "  AI: 2450/4481\n",
      "  AI: 2460/4481\n",
      "  AI: 2470/4481\n",
      "  AI: 2480/4481\n",
      "  AI: 2490/4481\n",
      "  AI: 2500/4481\n",
      "  AI: 2510/4481\n",
      "  AI: 2520/4481\n",
      "  AI: 2530/4481\n",
      "  AI: 2540/4481\n",
      "  AI: 2550/4481\n",
      "  AI: 2560/4481\n",
      "  AI: 2570/4481\n",
      "  AI: 2580/4481\n",
      "  AI: 2590/4481\n",
      "  AI: 2600/4481\n",
      "  AI: 2610/4481\n",
      "  AI: 2620/4481\n",
      "  AI: 2630/4481\n",
      "  AI: 2640/4481\n",
      "  AI: 2650/4481\n",
      "  AI: 2660/4481\n",
      "  AI: 2670/4481\n",
      "  AI: 2680/4481\n",
      "  AI: 2690/4481\n",
      "  AI: 2700/4481\n",
      "  AI: 2710/4481\n",
      "  AI: 2720/4481\n",
      "  AI: 2730/4481\n",
      "  AI: 2740/4481\n",
      "  AI: 2750/4481\n",
      "  AI: 2760/4481\n",
      "  AI: 2770/4481\n",
      "  AI: 2780/4481\n",
      "  AI: 2790/4481\n",
      "  AI: 2800/4481\n",
      "  AI: 2810/4481\n",
      "  AI: 2820/4481\n",
      "  AI: 2830/4481\n",
      "  AI: 2840/4481\n",
      "  AI: 2850/4481\n",
      "  AI: 2860/4481\n",
      "  AI: 2870/4481\n",
      "  AI: 2880/4481\n",
      "  AI: 2890/4481\n",
      "  AI: 2900/4481\n",
      "  AI: 2910/4481\n",
      "  AI: 2920/4481\n",
      "  AI: 2930/4481\n",
      "  AI: 2940/4481\n",
      "  AI: 2950/4481\n",
      "  AI: 2960/4481\n",
      "  AI: 2970/4481\n",
      "  AI: 2980/4481\n",
      "  AI: 2990/4481\n",
      "  AI: 3000/4481\n",
      "  AI: 3010/4481\n",
      "  AI: 3020/4481\n",
      "  AI: 3030/4481\n",
      "  AI: 3040/4481\n",
      "  AI: 3050/4481\n",
      "  AI: 3060/4481\n",
      "  AI: 3070/4481\n",
      "  AI: 3080/4481\n",
      "  AI: 3090/4481\n",
      "  AI: 3100/4481\n",
      "  AI: 3110/4481\n",
      "  AI: 3120/4481\n",
      "  AI: 3130/4481\n",
      "  AI: 3140/4481\n",
      "  AI: 3150/4481\n",
      "  AI: 3160/4481\n",
      "  AI: 3170/4481\n",
      "  AI: 3180/4481\n",
      "  AI: 3190/4481\n",
      "  AI: 3200/4481\n",
      "  AI: 3210/4481\n",
      "  AI: 3220/4481\n",
      "  AI: 3230/4481\n",
      "  AI: 3240/4481\n",
      "  AI: 3250/4481\n",
      "  AI: 3260/4481\n",
      "  AI: 3270/4481\n",
      "  AI: 3280/4481\n",
      "  AI: 3290/4481\n",
      "  AI: 3300/4481\n",
      "  AI: 3310/4481\n",
      "  AI: 3320/4481\n",
      "  AI: 3330/4481\n",
      "  AI: 3340/4481\n",
      "  AI: 3350/4481\n",
      "  AI: 3360/4481\n",
      "  AI: 3370/4481\n",
      "  AI: 3380/4481\n",
      "  AI: 3390/4481\n",
      "  AI: 3400/4481\n",
      "  AI: 3410/4481\n",
      "  AI: 3420/4481\n",
      "  AI: 3430/4481\n",
      "  AI: 3440/4481\n",
      "  AI: 3450/4481\n",
      "  AI: 3460/4481\n",
      "  AI: 3470/4481\n",
      "  AI: 3480/4481\n",
      "  AI: 3490/4481\n",
      "  AI: 3500/4481\n",
      "  AI: 3510/4481\n",
      "  AI: 3520/4481\n",
      "  AI: 3530/4481\n",
      "  AI: 3540/4481\n",
      "  AI: 3550/4481\n",
      "  AI: 3560/4481\n",
      "  AI: 3570/4481\n",
      "  AI: 3580/4481\n",
      "  AI: 3590/4481\n",
      "  AI: 3600/4481\n",
      "  AI: 3610/4481\n",
      "  AI: 3620/4481\n",
      "  AI: 3630/4481\n",
      "  AI: 3640/4481\n",
      "  AI: 3650/4481\n",
      "  AI: 3660/4481\n",
      "  AI: 3670/4481\n",
      "  AI: 3680/4481\n",
      "  AI: 3690/4481\n",
      "  AI: 3700/4481\n",
      "  AI: 3710/4481\n",
      "  AI: 3720/4481\n",
      "  AI: 3730/4481\n",
      "  AI: 3740/4481\n",
      "  AI: 3750/4481\n",
      "  AI: 3760/4481\n",
      "  AI: 3770/4481\n",
      "  AI: 3780/4481\n",
      "  AI: 3790/4481\n",
      "  AI: 3800/4481\n",
      "  AI: 3810/4481\n",
      "  AI: 3820/4481\n",
      "  AI: 3830/4481\n",
      "  AI: 3840/4481\n",
      "  AI: 3850/4481\n",
      "  AI: 3860/4481\n",
      "  AI: 3870/4481\n",
      "  AI: 3880/4481\n",
      "  AI: 3890/4481\n",
      "  AI: 3900/4481\n",
      "  AI: 3910/4481\n",
      "  AI: 3920/4481\n",
      "  AI: 3930/4481\n",
      "  AI: 3940/4481\n",
      "  AI: 3950/4481\n",
      "  AI: 3960/4481\n",
      "  AI: 3970/4481\n",
      "  AI: 3980/4481\n",
      "  AI: 3990/4481\n",
      "  AI: 4000/4481\n",
      "  AI: 4010/4481\n",
      "  AI: 4020/4481\n",
      "  AI: 4030/4481\n",
      "  AI: 4040/4481\n",
      "  AI: 4050/4481\n",
      "  AI: 4060/4481\n",
      "  AI: 4070/4481\n",
      "  AI: 4080/4481\n",
      "  AI: 4090/4481\n",
      "  AI: 4100/4481\n",
      "  AI: 4110/4481\n",
      "  AI: 4120/4481\n",
      "  AI: 4130/4481\n",
      "  AI: 4140/4481\n",
      "  AI: 4150/4481\n",
      "  AI: 4160/4481\n",
      "  AI: 4170/4481\n",
      "  AI: 4180/4481\n",
      "  AI: 4190/4481\n",
      "  AI: 4200/4481\n",
      "  AI: 4210/4481\n",
      "  AI: 4220/4481\n",
      "  AI: 4230/4481\n",
      "  AI: 4240/4481\n",
      "  AI: 4250/4481\n",
      "  AI: 4260/4481\n",
      "  AI: 4270/4481\n",
      "  AI: 4280/4481\n",
      "  AI: 4290/4481\n",
      "  AI: 4300/4481\n",
      "  AI: 4310/4481\n",
      "  AI: 4320/4481\n",
      "  AI: 4330/4481\n",
      "  AI: 4340/4481\n",
      "  AI: 4350/4481\n",
      "  AI: 4360/4481\n",
      "  AI: 4370/4481\n",
      "  AI: 4380/4481\n",
      "  AI: 4390/4481\n",
      "  AI: 4400/4481\n",
      "  AI: 4410/4481\n",
      "  AI: 4420/4481\n",
      "  AI: 4430/4481\n",
      "  AI: 4440/4481\n",
      "  AI: 4450/4481\n",
      "  AI: 4460/4481\n",
      "  AI: 4470/4481\n",
      "  AI: 4480/4481\n",
      "\n",
      "Obliczanie podobieństwa cosinusowego...\n",
      "Średnie podobieństwo cosinusowe: 0.9528\n",
      "Minimalne podobieństwo: 0.1329\n",
      "Maksymalne podobieństwo: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"Pobiera embedding z OpenAI API\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Oblicza podobieństwo cosinusowe między dwoma wektorami\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Generowanie embeddingów dla wszystkich tekstów\n",
    "print(\"Generowanie embeddingów dla ground truth...\")\n",
    "gt_embeddings = []\n",
    "for i, text in enumerate(comparison_df['normalized_text'], 1):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"  Ground truth: {i}/{len(comparison_df)}\")\n",
    "    gt_embeddings.append(get_embedding(text))\n",
    "\n",
    "print(\"\\nGenerowanie embeddingów dla transkryptów AI...\")\n",
    "ai_embeddings = []\n",
    "for i, text in enumerate(comparison_df['ai_normalized'], 1):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"  AI: {i}/{len(comparison_df)}\")\n",
    "    ai_embeddings.append(get_embedding(text))\n",
    "\n",
    "print(\"\\nObliczanie podobieństwa cosinusowego...\")\n",
    "cos_similarities = []\n",
    "for gt_emb, ai_emb in zip(gt_embeddings, ai_embeddings):\n",
    "    cos_sim = cosine_similarity(gt_emb, ai_emb)\n",
    "    cos_similarities.append(cos_sim)\n",
    "\n",
    "comparison_df['cos_sim'] = cos_similarities\n",
    "print(f\"Średnie podobieństwo cosinusowe: {np.mean(cos_similarities):.4f}\")\n",
    "print(f\"Minimalne podobieństwo: {np.min(cos_similarities):.4f}\")\n",
    "print(f\"Maksymalne podobieństwo: {np.max(cos_similarities):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b34b2bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PODSUMOWANIE ANALIZY ===\n",
      "Całkowita liczba porównań: 4481\n",
      "Dokładne dopasowanie 1:1: 2945 (65.72%)\n",
      "Średnie podobieństwo cosinusowe: 0.9528\n",
      "\n",
      "Rozkład podobieństwa cosinusowego:\n",
      "count    4481.000000\n",
      "mean        0.952752\n",
      "std         0.093991\n",
      "min         0.132900\n",
      "25%         0.942173\n",
      "50%         0.999999\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: cos_sim, dtype: float64\n",
      "\n",
      "=== PIERWSZE 10 WIERSZY ===\n",
      "   phraseNumber speaker emotion                                       gt                                       ai  1_1_match   cos_sim\n",
      "0             1     EB0   anger                  lubię czytać przed snem                  lubię czytać przed snem       True  1.000000\n",
      "1            10     EB0   anger           kupiłem nową szafę do sypialni           kupiłem nową szafę do sypialni       True  1.000000\n",
      "2            11     EB0   anger             nie zachowuj się jak żigolak             nie zachowuj się jak żigolek      False  0.972274\n",
      "3            12     EB0   anger               mój teść zawsze służy radą                mój też zawsze służy radą      False  0.820867\n",
      "4            13     EB0   anger          interesuje mnie historia polski          interesuje mnie historia polski       True  0.999999\n",
      "5            14     EB0   anger          ten miesiąc minął bardzo szybko          ten miesiąc minął bardzo szybko       True  0.999999\n",
      "6            15     EB0   anger          sporadycznie chodzę na siłownię          sporadycznie chodzę na siłowinę      False  0.834612\n",
      "7            16     EB0   anger          racja ten pomysł jest najlepszy          racja ten pomysł jest najlepszy       True  1.000000\n",
      "8            17     EB0   anger  chcę przeczytać ten artykuł jeszcze raz  chcę przeczytać ten artykuł jeszcze raz       True  0.996753\n",
      "9            18     EB0   anger       kwiecień to czwarty miesiąc w roku       kwiecień to czwarty miesiąc w roku       True  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie finalnego dataframe z wynikami\n",
    "results_df = pd.DataFrame({\n",
    "    'gt': comparison_df['normalized_text'],\n",
    "    'ai': comparison_df['ai_normalized'],\n",
    "    '1_1_match': comparison_df['1_1_match'],\n",
    "    'cos_sim': comparison_df['cos_sim']\n",
    "})\n",
    "\n",
    "# Dodatkowe kolumny dla kontekstu\n",
    "results_df['phraseNumber'] = comparison_df['phraseNumber'].values\n",
    "results_df['speaker'] = comparison_df['speaker'].values\n",
    "results_df['emotion'] = comparison_df['emotion'].values\n",
    "\n",
    "# Reorder columns\n",
    "results_df = results_df[['phraseNumber', 'speaker', 'emotion', 'gt', 'ai', '1_1_match', 'cos_sim']]\n",
    "\n",
    "print(f\"\\n=== PODSUMOWANIE ANALIZY ===\")\n",
    "print(f\"Całkowita liczba porównań: {len(results_df)}\")\n",
    "print(f\"Dokładne dopasowanie 1:1: {results_df['1_1_match'].sum()} ({results_df['1_1_match'].mean()*100:.2f}%)\")\n",
    "print(f\"Średnie podobieństwo cosinusowe: {results_df['cos_sim'].mean():.4f}\")\n",
    "print(f\"\\nRozkład podobieństwa cosinusowego:\")\n",
    "print(results_df['cos_sim'].describe())\n",
    "\n",
    "print(\"\\n=== PIERWSZE 10 WIERSZY ===\")\n",
    "print(results_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4229830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki zapisane do pliku: comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Zapisanie wyników do pliku CSV\n",
    "results_df.to_csv(\"comparison_results.csv\", index=False)\n",
    "print(\"Wyniki zapisane do pliku: comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff95c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRZYPADKI Z NISKIM PODOBIEŃSTWEM (<0.9) ===\n",
      "Znaleziono 876 przypadków\n",
      "\n",
      "Phrase: 48 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.1329 | 1:1 Match: False\n",
      "GT:  moja dziewczyna świętuje urodziny w sobotę\n",
      "AI:  król był bardzo sprawiedliwym człowiekiem\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 49 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.1705 | 1:1 Match: False\n",
      "GT:  niektórzy powiedzą że to państwo z kartonu\n",
      "AI:  moja dziewczyna świętuje urodziny w sobotę\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 52 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2262 | 1:1 Match: False\n",
      "GT:  na złamaną kończynę często zakłada się gips\n",
      "AI:  strzelę to znak zodiaku następujący po skorpionie\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 50 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2301 | 1:1 Match: False\n",
      "GT:  w muzeum można zobaczyć szkielet dinozaura\n",
      "AI:  niektórzy powiedzą że to państwo z kartonu\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 53 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2453 | 1:1 Match: False\n",
      "GT:  kitel to strój który noszą lekarze\n",
      "AI:  na złamaną giełdzinę często zakłada się gips\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 46 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2474 | 1:1 Match: False\n",
      "GT:  żołwica to dawne określenie na siostrę męża\n",
      "AI:  postanowiłem wynająć samochód na wakacje\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 60 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2635 | 1:1 Match: False\n",
      "GT:  podczas wakacji udało mi się zobaczyć delfiny\n",
      "AI:  kupiłem nowy słownik języka hiszpańskiego\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 45 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2680 | 1:1 Match: False\n",
      "GT:  postanowiłem wynająć samochód na wakacje\n",
      "AI:  tęsknota to uczucie które każdy z nas zna\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 42 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2692 | 1:1 Match: False\n",
      "GT:  przyjaciel to ktoś kto zawsze jest po mojej stronie\n",
      "AI:  w parku rośnie ogromne drzewo\n",
      "--------------------------------------------------------------------------------\n",
      "Phrase: 47 | Speaker: EB0 | Emotion: surprised\n",
      "Cos Sim: 0.2747 | 1:1 Match: False\n",
      "GT:  król był bardzo sprawiedliwym człowiekiem\n",
      "AI:  żółwica to dawne określenie na siostrę męża\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analiza przypadków z niskim podobieństwem cosinusowym\n",
    "low_similarity = results_df[results_df['cos_sim'] < 0.9].sort_values('cos_sim')\n",
    "print(f\"\\n=== PRZYPADKI Z NISKIM PODOBIEŃSTWEM (<0.9) ===\")\n",
    "print(f\"Znaleziono {len(low_similarity)} przypadków\\n\")\n",
    "\n",
    "for idx, row in low_similarity.head(10).iterrows():\n",
    "    print(f\"Phrase: {row['phraseNumber']} | Speaker: {row['speaker']} | Emotion: {row['emotion']}\")\n",
    "    print(f\"Cos Sim: {row['cos_sim']:.4f} | 1:1 Match: {row['1_1_match']}\")\n",
    "    print(f\"GT:  {row['gt']}\")\n",
    "    print(f\"AI:  {row['ai']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla EB0_surprised_* jest jakieś przesunięcie adnotacji - nieistotne w tym momencie, już wiem jaka jest charakterystyka błędów"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
