{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ad4019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mim/asr-tests/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2026-01-08 09:59:38 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.\n",
      "OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.\n",
      "No exporters were provided. This means that no telemetry data will be collected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 09:59:49 nemo_logging:393] Tokenizer CanaryBPETokenizer initialized with 16384 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 09:59:49 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    skip_missing_manifest_entries: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    prompt_format: canary2\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.01\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: true\n",
      "    max_tps: null\n",
      "    bucket_duration_bins: null\n",
      "    bucket_batch_size: null\n",
      "    num_buckets: null\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2026-01-08 09:59:49 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    prompt_format: canary2\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: true\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 09:59:49 nemo_logging:393] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting class at nemo.collections.asr.modules.transformer.get_nemo_transformer: Located non-class of type 'function' while loading 'nemo.collections.asr.modules.transformer.get_nemo_transformer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 10:00:04 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 16384 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 10:00:09 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    skip_missing_manifest_entries: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    text_field: answer\n",
      "    batch_duration: null\n",
      "    max_tps: null\n",
      "    use_bucketing: true\n",
      "    bucket_duration_bins: null\n",
      "    bucket_batch_size: null\n",
      "    num_buckets: null\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2026-01-08 10:00:09 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 10:00:09 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2026-01-08 10:00:17 nemo_logging:393] Model EncDecCTCModelBPE was successfully restored from /home/mim/.cache/huggingface/hub/models--nvidia--canary-1b-v2/snapshots/87bc52657add533cd0156b3fc1aef027280754bf/canary-1b-v2.nemo.\n",
      "[NeMo I 2026-01-08 10:00:19 nemo_logging:393] Model EncDecMultiTaskModel was successfully restored from /home/mim/.cache/huggingface/hub/models--nvidia--canary-1b-v2/snapshots/87bc52657add533cd0156b3fc1aef027280754bf/canary-1b-v2.nemo.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.models import ASRModel\n",
    "asr_ast_model = ASRModel.from_pretrained(model_name=\"nvidia/canary-1b-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba7d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:   nemo v1.0.1\n",
      "Cache: /home/mim/audb/nemo/1.0.1/d3b62a9b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "import audb\n",
    "db = audb.load(\"nemo\", version=\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d6695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: nemo\n",
      "description: 'NEMO is a polish dataset with emotional speech. It contains over 3 hours\n",
      "  of emotional speech in 6 categories: anger, fear, happiness, sadness, surprise and\n",
      "  neutral. The audios were created by nine speakers.'\n",
      "source: https://aclanthology.org/2024.lrec-main.1059\n",
      "usage: research\n",
      "languages: [pol]\n",
      "author: Christop, Iwona\n",
      "license: CC-BY-NC-SA-4.0\n",
      "license_url: https://creativecommons.org/licenses/by-nc-sa/4.0/\n",
      "schemes:\n",
      "  age: {dtype: int}\n",
      "  emotion:\n",
      "    dtype: str\n",
      "    labels: [anger, sadness, surprise, happiness, fear, neutral]\n",
      "  gender:\n",
      "    dtype: str\n",
      "    labels: [male, female]\n",
      "  normalized_text:\n",
      "    dtype: str\n",
      "    labels: [ucho wykrywa dźwięki o różnej częstotliwości, interesuje mnie historia\n",
      "        polski, człowiek zaczyna umierać już w momencie narodzin, kupiłem nową szafę\n",
      "        do sypialni, mleko jest źródłem wapnia i innych składników odżywczych, „ród\n",
      "        smoka” to serial telewizyjny, strzelec to znak zodiaku następujący po skorpionie,\n",
      "      myślmy pozytywnie i skupmy się na dobrych rzeczach w naszym życiu, otrzymałem\n",
      "        piękną pocztówkę z widokiem na góry, nie waśńmy się ze sobą, aby upiec ciasto\n",
      "        muszę kupić mączkę, egipcjanie uważali ibisy za święte, postanowiłem wynająć\n",
      "        samochód na wakacje, w wolnym czasie lubię czytać książki, moja ciocia jest\n",
      "        bardzo pomocna, ten pomysł trąci brakiem realizmu, woda w basenie jest bardzo\n",
      "        ciepła, gorzka czekolada jest idealna na deser, dokarmcie koty wychodząc z\n",
      "        domu, piesek wszedł do rzeki żeby popływać, relaksujące piosnki poprawiają\n",
      "        nastrój, jedz inaczej aby polepszyć swoje zdrowie, na złamaną kończynę często\n",
      "        zakłada się gips, żołwica to dawne określenie na siostrę męża, niania odegrała\n",
      "        w moim życiu ważną rolę, ten miesiąc minął bardzo szybko, do dzisiejszego\n",
      "        obiadu potrzebuje małego garnczka, dziunia nie jesteś moim szefem, lubię czytać\n",
      "        przed snem, piłka nożna to moja pasja, woda jest podstawowym składnikiem życia\n",
      "        na ziemi, podczas medytacji można wejść w trans, twoje słowo ma dla mnie wielkie\n",
      "        znaczenie, podczas remontu odkryliśmy starodawny mur, dopełniacz jest jednym\n",
      "        z przypadków gramatycznych w języku polskim, nie zachowuj się jak żigolak,\n",
      "      w bankach można założyć konto osobiste oszczędnościowe lub kredytowe, baza wojskowa\n",
      "        jest strategicznym punktem dla armii, miłość jest jednym z najpiękniejszych\n",
      "        uczuć, chcę przeczytać ten artykuł jeszcze raz, kupiłem nowy słownik języka\n",
      "        hiszpańskiego, sziwa oznacza żałobę po zmarłym, tęsknota to uczucie które\n",
      "        każdy z nas zna, zawsze stawiam przed rzeczownikami właściwy rodzajnik, rtęć\n",
      "        jest jednym z pierwiastków chemicznych, w muzeum można zobaczyć szkielet dinozaura,\n",
      "      bastion był kiedyś ważnym elementem obrony miasta, po operacji nie mam żadnych\n",
      "        blizn, moim ulubionym sosem do pizzy jest sos czosnkowy, czerwiec kojarzy\n",
      "        się z zakończeniem roku szkolnego, w niedzielę szkoła jest zamknięta, dzieci\n",
      "        muszą dużo jeść, miasto tętni życiem nawet w nocy, na targach rzemieślniczych\n",
      "        można zobaczyć wiele unikatowych produktów, mój teść zawsze służy radą, przez\n",
      "        most na rzece można szybko dotrzeć do miasta, każdy taniec ma swój własny\n",
      "        rytm, kwiecień to czwarty miesiąc w roku, zima to czas jeżdżenia na sankach,\n",
      "      w parku rośnie ogromne drzewo, chodźmy w tango, chodzę do szkoły prawie codziennie,\n",
      "      pan janek jest naszym nowym sąsiadem, zupa pomidorowa to moje ulubione danie,\n",
      "      w grudniu często pada śnieg, w dzieciństwie uwielbiałem klechdy, moja teściowa\n",
      "        czasem przyjeżdża do nas w weekend, kontrświadczenie za udzieloną pożyczkę\n",
      "        było bardzo wysokie, jabłko jest bogatym źródłem witamin i składników odżywczych,\n",
      "      marzec kojarzy się z wiosennymi promieniami słońca, zamek w malborku jest jednym\n",
      "        z najpiękniejszych w polsce, moje dziecko umie już mówić kilka słów, niektórzy\n",
      "        powiedzą że to państwo z kartonu, przyjaciel to ktoś kto zawsze jest po mojej\n",
      "        stronie, moja wizja na przyszłość jest jasna i wyraźna, chorał gregoriański\n",
      "        jest wykonywany podczas uroczystych nabożeństw, ten źrebak jest wychowany\n",
      "        zgodnie z najlepszymi standardami, król był bardzo sprawiedliwym człowiekiem,\n",
      "      racja ten pomysł jest najlepszy, w lipcu wyjeżdżam z rodziną na wakacje nad\n",
      "        morze, kitel to strój który noszą lekarze, sporadycznie chodzę na siłownię,\n",
      "      moja dziewczyna świętuje urodziny w sobotę, przestań go judzić, ta liczba wydaje\n",
      "        się być błędna sprawdź jeszcze raz, w październiku zaczyna się jesień, podczas\n",
      "        wakacji udało mi się zobaczyć delfiny, ten dżin potrafi spełniać życzenia,\n",
      "      pamiętaj że nadzieja umiera ostatnia, życie jest pełne niespodzianek]\n",
      "  raw_text:\n",
      "    dtype: str\n",
      "    labels: [Ucho wykrywa dźwięki o różnej częstotliwości., Interesuje mnie historia\n",
      "        Polski., Człowiek zaczyna umierać już w momencie narodzin., Kupiłem nową szafę\n",
      "        do sypialni., Mleko jest źródłem wapnia i innych składników odżywczych., „Ród\n",
      "        smoka” to serial telewizyjny., Strzelec to znak zodiaku następujący po Skorpionie.,\n",
      "      Myślmy pozytywnie i skupmy się na dobrych rzeczach w naszym życiu., Otrzymałem\n",
      "        piękną pocztówkę z widokiem na góry., Nie waśńmy się ze sobą., 'Aby upiec\n",
      "        ciasto, muszę kupić mączkę.', Egipcjanie uważali ibisy za święte., Postanowiłem\n",
      "        wynająć samochód na wakacje., W wolnym czasie lubię czytać książki., Moja\n",
      "        ciocia jest bardzo pomocna., Ten pomysł trąci brakiem realizmu., Woda w basenie\n",
      "        jest bardzo ciepła., Gorzka czekolada jest idealna na deser., Dokarmcie koty\n",
      "        wychodząc z domu., Piesek wszedł do rzeki żeby popływać., Relaksujące piosnki\n",
      "        poprawiają nastrój., Jedz inaczej aby polepszyć swoje zdrowie., Na złamaną\n",
      "        kończynę często zakłada się gips., „Żołwica” to dawne określenie na siostrę\n",
      "        męża., Niania odegrała w moim życiu ważną rolę., Ten miesiąc minął bardzo\n",
      "        szybko., Do dzisiejszego obiadu potrzebuje małego garnczka., 'Dziunia, nie\n",
      "        jesteś moim szefem.', Lubię czytać przed snem., Piłka nożna to moja pasja.,\n",
      "      Woda jest podstawowym składnikiem życia na Ziemi., Podczas medytacji można wejść\n",
      "        w trans., Twoje słowo ma dla mnie wielkie znaczenie., Podczas remontu odkryliśmy\n",
      "        starodawny mur., Dopełniacz jest jednym z przypadków gramatycznych w języku\n",
      "        polskim., Nie zachowuj się jak żigolak., 'W bankach można założyć konto osobiste,\n",
      "        oszczędnościowe lub kredytowe.', Baza wojskowa jest strategicznym punktem\n",
      "        dla armii., Miłość jest jednym z najpiękniejszych uczuć., Chcę przeczytać\n",
      "        ten artykuł jeszcze raz., Kupiłem nowy słownik języka hiszpańskiego., Sziwa\n",
      "        oznacza żałobę po zmarłym., 'Tęsknota to uczucie, które każdy z nas zna.',\n",
      "      Zawsze stawiam przed rzeczownikami właściwy rodzajnik., Rtęć jest jednym z pierwiastków\n",
      "        chemicznych., W muzeum można zobaczyć szkielet dinozaura., Bastion był kiedyś\n",
      "        ważnym elementem obrony miasta., Po operacji nie mam żadnych blizn., Moim\n",
      "        ulubionym sosem do pizzy jest sos czosnkowy., Czerwiec kojarzy się z zakończeniem\n",
      "        roku szkolnego., W niedzielę szkoła jest zamknięta., Dzieci muszą dużo jeść.,\n",
      "      'Miasto tętni życiem, nawet w nocy.', Na targach rzemieślniczych można zobaczyć\n",
      "        wiele unikatowych produktów., Mój teść zawsze służy radą., Przez most na rzece\n",
      "        można szybko dotrzeć do miasta., Każdy taniec ma swój własny rytm., Kwiecień\n",
      "        to czwarty miesiąc w roku., Zima to czas jeżdżenia na sankach., W parku rośnie\n",
      "        ogromne drzewo., Chodźmy w tango., Chodzę do szkoły prawie codziennie., Pan\n",
      "        Janek jest naszym nowym sąsiadem., Zupa pomidorowa to moje ulubione danie.,\n",
      "      W grudniu często pada śnieg., W dzieciństwie uwielbiałem klechdy., Moja teściowa\n",
      "        czasem przyjeżdża do nas w weekend., Kontrświadczenie za udzieloną pożyczkę\n",
      "        było bardzo wysokie., Jabłko jest bogatym źródłem witamin i składników odżywczych.,\n",
      "      Marzec kojarzy się z wiosennymi promieniami słońca., Zamek w Malborku jest jednym\n",
      "        z najpiękniejszych w Polsce., Moje dziecko umie już mówić kilka słów., 'Niektórzy\n",
      "        powiedzą, że to państwo z kartonu.', 'Przyjaciel to ktoś, kto zawsze jest\n",
      "        po mojej stronie.', Moja wizja na przyszłość jest jasna i wyraźna., Chorał\n",
      "        gregoriański jest wykonywany podczas uroczystych nabożeństw., Ten źrebak jest\n",
      "        wychowany zgodnie z najlepszymi standardami., Król był bardzo sprawiedliwym\n",
      "        człowiekiem., 'Racja, ten pomysł jest najlepszy.', W lipcu wyjeżdżam z rodziną\n",
      "        na wakacje nad morze., 'Kitel to strój, który noszą lekarze.', Sporadycznie\n",
      "        chodzę na siłownię., Moja dziewczyna świętuje urodziny w sobotę., Przestań\n",
      "        go judzić., 'Ta liczba wydaje się być błędna, sprawdź jeszcze raz.', W październiku\n",
      "        zaczyna się jesień., Podczas wakacji udało mi się zobaczyć delfiny., Ten dżin\n",
      "        potrafi spełniać życzenia., 'Pamiętaj, że nadzieja umiera ostatnia.', Życie\n",
      "        jest pełne niespodzianek.]\n",
      "  sentence: {dtype: int, labels: sentence}\n",
      "  speaker: {dtype: object, labels: speaker}\n",
      "tables:\n",
      "  emotion.categories.test.gold_standard:\n",
      "    type: filewise\n",
      "    columns:\n",
      "      emotion: {scheme_id: emotion}\n",
      "  files:\n",
      "    type: filewise\n",
      "    columns:\n",
      "      speaker: {scheme_id: speaker}\n",
      "      sentence: {scheme_id: sentence}\n",
      "misc_tables:\n",
      "  sentence:\n",
      "    levels: {sentence: int}\n",
      "    columns:\n",
      "      raw_text: {scheme_id: raw_text}\n",
      "      normalized_text: {scheme_id: normalized_text}\n",
      "  speaker:\n",
      "    levels: {speaker: object}\n",
      "    columns:\n",
      "      gender: {scheme_id: gender}\n",
      "      age: {scheme_id: age}\n",
      "audb:\n",
      "  root: /home/mim/audb/nemo/1.0.1/d3b62a9b\n",
      "  version: 1.0.1\n",
      "  flavor: {bit_depth: null, channels: null, format: null, mixdown: false, sampling_rate: null}\n",
      "  complete: true\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aca11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mim/audb/nemo/1.0.1/d3b62a9b\n",
      "Liczba plików WAV: 4481\n",
      "[PosixPath('/home/mim/audb/nemo/1.0.1/d3b62a9b/audios/EB0_fear_58.wav'), PosixPath('/home/mim/audb/nemo/1.0.1/d3b62a9b/audios/KS0_neutral_38.wav'), PosixPath('/home/mim/audb/nemo/1.0.1/d3b62a9b/audios/EB0_sadness_28.wav'), PosixPath('/home/mim/audb/nemo/1.0.1/d3b62a9b/audios/IC0_happiness_38.wav'), PosixPath('/home/mim/audb/nemo/1.0.1/d3b62a9b/audios/KD0_surprised_52.wav')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root = Path(db.root)\n",
    "\n",
    "# pliki audio zwykle są w katalogu 'audio' lub 'files'\n",
    "audio_files = list(root.rglob(\"*.wav\"))  # znajdź wszystkie WAV\n",
    "\n",
    "print(root)\n",
    "\n",
    "print(f\"Liczba plików WAV: {len(audio_files)}\")\n",
    "print(audio_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f740809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 10:24:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-08 10:24:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 1it [00:14, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warszawa, jako niekwestionowany i wieloaspektowo rozwinięty ośrodek, który od stuleci pełni rolę zarówno głównego centrum naukowego z licznymi instytucjami badawczymi, jak i bogatego w dziedzictwo kulturowe miasta tętniącego wydarzeniami artystycznymi, politycznie wpływowego poprzez siedziby kluczowych organów państwowych, a równocześnie znaczącego ekonomicznie dzięki skupieniu przedsiębiorstw i rynków kapitałowych, jawi się jako metropolia o wyjątkowej złożoności funkcjonalnej i społecznej.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = asr_ast_model.transcribe(['../sample_audio.wav'], source_lang='pl', target_lang='pl')\n",
    "print(output[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b20422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                   raw_text  \\\n",
      "sentence                                                      \n",
      "64            Ucho wykrywa dźwięki o różnej częstotliwości.   \n",
      "13                         Interesuje mnie historia Polski.   \n",
      "70        Człowiek zaczyna umierać już w momencie narodzin.   \n",
      "10                          Kupiłem nową szafę do sypialni.   \n",
      "79        Mleko jest źródłem wapnia i innych składników ...   \n",
      "...                                                     ...   \n",
      "29                       W październiku zaczyna się jesień.   \n",
      "60           Podczas wakacji udało mi się zobaczyć delfiny.   \n",
      "26                      Ten dżin potrafi spełniać życzenia.   \n",
      "32                   Pamiętaj, że nadzieja umiera ostatnia.   \n",
      "7                           Życie jest pełne niespodzianek.   \n",
      "\n",
      "                                            normalized_text  \n",
      "sentence                                                     \n",
      "64             ucho wykrywa dźwięki o różnej częstotliwości  \n",
      "13                          interesuje mnie historia polski  \n",
      "70         człowiek zaczyna umierać już w momencie narodzin  \n",
      "10                           kupiłem nową szafę do sypialni  \n",
      "79        mleko jest źródłem wapnia i innych składników ...  \n",
      "...                                                     ...  \n",
      "29                        w październiku zaczyna się jesień  \n",
      "60            podczas wakacji udało mi się zobaczyć delfiny  \n",
      "26                       ten dżin potrafi spełniać życzenia  \n",
      "32                     pamiętaj że nadzieja umiera ostatnia  \n",
      "7                            życie jest pełne niespodzianek  \n",
      "\n",
      "[90 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = f\"{root}/db.sentence.pkl\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:  # rb = read binary\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "print(type(obj))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb05e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{root}/audios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-07 12:53:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 4481 plików WAV\n",
      "[1/4481] Przetwarzanie: EB0_anger_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.27it/s]\n",
      "[NeMo W 2026-01-07 12:53:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/4481] Przetwarzanie: EB0_anger_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.00s/it]\n",
      "[NeMo W 2026-01-07 12:53:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/4481] Przetwarzanie: EB0_anger_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.30it/s]\n",
      "[NeMo W 2026-01-07 12:53:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/4481] Przetwarzanie: EB0_anger_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.16it/s]\n",
      "[NeMo W 2026-01-07 12:53:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/4481] Przetwarzanie: EB0_anger_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.43it/s]\n",
      "[NeMo W 2026-01-07 12:53:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/4481] Przetwarzanie: EB0_anger_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.22it/s]\n",
      "[NeMo W 2026-01-07 12:53:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/4481] Przetwarzanie: EB0_anger_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.23it/s]\n",
      "[NeMo W 2026-01-07 12:53:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/4481] Przetwarzanie: EB0_anger_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.10it/s]\n",
      "[NeMo W 2026-01-07 12:53:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/4481] Przetwarzanie: EB0_anger_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.06it/s]\n",
      "[NeMo W 2026-01-07 12:53:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/4481] Przetwarzanie: EB0_anger_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:53:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/4481] Przetwarzanie: EB0_anger_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:53:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/4481] Przetwarzanie: EB0_anger_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.28it/s]\n",
      "[NeMo W 2026-01-07 12:53:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/4481] Przetwarzanie: EB0_anger_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.25it/s]\n",
      "[NeMo W 2026-01-07 12:53:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/4481] Przetwarzanie: EB0_anger_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:53:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/4481] Przetwarzanie: EB0_anger_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.06s/it]\n",
      "[NeMo W 2026-01-07 12:53:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/4481] Przetwarzanie: EB0_anger_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.29it/s]\n",
      "[NeMo W 2026-01-07 12:53:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/4481] Przetwarzanie: EB0_anger_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.20it/s]\n",
      "[NeMo W 2026-01-07 12:53:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/4481] Przetwarzanie: EB0_anger_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.01it/s]\n",
      "[NeMo W 2026-01-07 12:53:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/4481] Przetwarzanie: EB0_anger_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.13it/s]\n",
      "[NeMo W 2026-01-07 12:53:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/4481] Przetwarzanie: EB0_anger_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.07it/s]\n",
      "[NeMo W 2026-01-07 12:53:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/4481] Przetwarzanie: EB0_anger_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:53:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/4481] Przetwarzanie: EB0_anger_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:53:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/4481] Przetwarzanie: EB0_anger_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.38it/s]\n",
      "[NeMo W 2026-01-07 12:53:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/4481] Przetwarzanie: EB0_anger_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.02it/s]\n",
      "[NeMo W 2026-01-07 12:53:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/4481] Przetwarzanie: EB0_anger_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.10it/s]\n",
      "[NeMo W 2026-01-07 12:53:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/4481] Przetwarzanie: EB0_anger_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:53:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/4481] Przetwarzanie: EB0_anger_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.15it/s]\n",
      "[NeMo W 2026-01-07 12:53:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/4481] Przetwarzanie: EB0_anger_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.14it/s]\n",
      "[NeMo W 2026-01-07 12:53:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/4481] Przetwarzanie: EB0_anger_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:53:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/4481] Przetwarzanie: EB0_anger_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.13it/s]\n",
      "[NeMo W 2026-01-07 12:53:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/4481] Przetwarzanie: EB0_anger_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:53:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/4481] Przetwarzanie: EB0_anger_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:53:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/4481] Przetwarzanie: EB0_anger_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.02it/s]\n",
      "[NeMo W 2026-01-07 12:53:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/4481] Przetwarzanie: EB0_anger_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.36it/s]\n",
      "[NeMo W 2026-01-07 12:53:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/4481] Przetwarzanie: EB0_anger_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:53:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36/4481] Przetwarzanie: EB0_anger_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.26it/s]\n",
      "[NeMo W 2026-01-07 12:53:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/4481] Przetwarzanie: EB0_anger_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.15s/it]\n",
      "[NeMo W 2026-01-07 12:53:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/4481] Przetwarzanie: EB0_anger_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.05s/it]\n",
      "[NeMo W 2026-01-07 12:53:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39/4481] Przetwarzanie: EB0_anger_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.06s/it]\n",
      "[NeMo W 2026-01-07 12:53:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/4481] Przetwarzanie: EB0_anger_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.11s/it]\n",
      "[NeMo W 2026-01-07 12:53:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/4481] Przetwarzanie: EB0_anger_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.33s/it]\n",
      "[NeMo W 2026-01-07 12:53:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42/4481] Przetwarzanie: EB0_anger_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.08it/s]\n",
      "[NeMo W 2026-01-07 12:53:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/4481] Przetwarzanie: EB0_anger_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.11s/it]\n",
      "[NeMo W 2026-01-07 12:53:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44/4481] Przetwarzanie: EB0_anger_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.07s/it]\n",
      "[NeMo W 2026-01-07 12:53:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/4481] Przetwarzanie: EB0_anger_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.34it/s]\n",
      "[NeMo W 2026-01-07 12:53:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46/4481] Przetwarzanie: EB0_anger_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:53:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/4481] Przetwarzanie: EB0_anger_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.18s/it]\n",
      "[NeMo W 2026-01-07 12:53:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/4481] Przetwarzanie: EB0_anger_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.10s/it]\n",
      "[NeMo W 2026-01-07 12:53:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49/4481] Przetwarzanie: EB0_anger_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.09it/s]\n",
      "[NeMo W 2026-01-07 12:53:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/4481] Przetwarzanie: EB0_anger_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.20it/s]\n",
      "[NeMo W 2026-01-07 12:53:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51/4481] Przetwarzanie: EB0_anger_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.10it/s]\n",
      "[NeMo W 2026-01-07 12:53:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:53:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52/4481] Przetwarzanie: EB0_anger_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.08it/s]\n",
      "[NeMo W 2026-01-07 12:54:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53/4481] Przetwarzanie: EB0_anger_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.03it/s]\n",
      "[NeMo W 2026-01-07 12:54:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54/4481] Przetwarzanie: EB0_anger_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.24s/it]\n",
      "[NeMo W 2026-01-07 12:54:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55/4481] Przetwarzanie: EB0_anger_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.12s/it]\n",
      "[NeMo W 2026-01-07 12:54:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/4481] Przetwarzanie: EB0_anger_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:54:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57/4481] Przetwarzanie: EB0_anger_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:54:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58/4481] Przetwarzanie: EB0_anger_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.07it/s]\n",
      "[NeMo W 2026-01-07 12:54:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/4481] Przetwarzanie: EB0_anger_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.12it/s]\n",
      "[NeMo W 2026-01-07 12:54:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/4481] Przetwarzanie: EB0_anger_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.12s/it]\n",
      "[NeMo W 2026-01-07 12:54:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61/4481] Przetwarzanie: EB0_anger_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.19s/it]\n",
      "[NeMo W 2026-01-07 12:54:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62/4481] Przetwarzanie: EB0_anger_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.10s/it]\n",
      "[NeMo W 2026-01-07 12:54:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63/4481] Przetwarzanie: EB0_anger_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.10s/it]\n",
      "[NeMo W 2026-01-07 12:54:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64/4481] Przetwarzanie: EB0_anger_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:54:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65/4481] Przetwarzanie: EB0_anger_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.33s/it]\n",
      "[NeMo W 2026-01-07 12:54:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66/4481] Przetwarzanie: EB0_anger_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.05s/it]\n",
      "[NeMo W 2026-01-07 12:54:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/4481] Przetwarzanie: EB0_anger_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.10it/s]\n",
      "[NeMo W 2026-01-07 12:54:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68/4481] Przetwarzanie: EB0_anger_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.19s/it]\n",
      "[NeMo W 2026-01-07 12:54:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69/4481] Przetwarzanie: EB0_anger_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:54:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70/4481] Przetwarzanie: EB0_anger_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:54:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71/4481] Przetwarzanie: EB0_anger_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.15s/it]\n",
      "[NeMo W 2026-01-07 12:54:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/4481] Przetwarzanie: EB0_anger_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.23s/it]\n",
      "[NeMo W 2026-01-07 12:54:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73/4481] Przetwarzanie: EB0_anger_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.12s/it]\n",
      "[NeMo W 2026-01-07 12:54:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74/4481] Przetwarzanie: EB0_anger_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.14s/it]\n",
      "[NeMo W 2026-01-07 12:54:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75/4481] Przetwarzanie: EB0_anger_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.23s/it]\n",
      "[NeMo W 2026-01-07 12:54:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/4481] Przetwarzanie: EB0_anger_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.23s/it]\n",
      "[NeMo W 2026-01-07 12:54:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77/4481] Przetwarzanie: EB0_anger_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:54:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78/4481] Przetwarzanie: EB0_anger_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.28it/s]\n",
      "[NeMo W 2026-01-07 12:54:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79/4481] Przetwarzanie: EB0_anger_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.22s/it]\n",
      "[NeMo W 2026-01-07 12:54:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80/4481] Przetwarzanie: EB0_anger_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.35s/it]\n",
      "[NeMo W 2026-01-07 12:54:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81/4481] Przetwarzanie: EB0_anger_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:54:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82/4481] Przetwarzanie: EB0_anger_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.23s/it]\n",
      "[NeMo W 2026-01-07 12:54:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83/4481] Przetwarzanie: EB0_anger_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.26s/it]\n",
      "[NeMo W 2026-01-07 12:54:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84/4481] Przetwarzanie: EB0_anger_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:54:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85/4481] Przetwarzanie: EB0_anger_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:54:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86/4481] Przetwarzanie: EB0_anger_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.24s/it]\n",
      "[NeMo W 2026-01-07 12:54:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87/4481] Przetwarzanie: EB0_anger_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.46s/it]\n",
      "[NeMo W 2026-01-07 12:54:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88/4481] Przetwarzanie: EB0_anger_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.39s/it]\n",
      "[NeMo W 2026-01-07 12:54:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/4481] Przetwarzanie: EB0_anger_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.21it/s]\n",
      "[NeMo W 2026-01-07 12:54:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/4481] Przetwarzanie: EB0_anger_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.48s/it]\n",
      "[NeMo W 2026-01-07 12:54:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91/4481] Przetwarzanie: EB0_fear_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.29it/s]\n",
      "[NeMo W 2026-01-07 12:54:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92/4481] Przetwarzanie: EB0_fear_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:54:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93/4481] Przetwarzanie: EB0_fear_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.13it/s]\n",
      "[NeMo W 2026-01-07 12:54:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/4481] Przetwarzanie: EB0_fear_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.22it/s]\n",
      "[NeMo W 2026-01-07 12:54:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95/4481] Przetwarzanie: EB0_fear_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.39it/s]\n",
      "[NeMo W 2026-01-07 12:54:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96/4481] Przetwarzanie: EB0_fear_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.24it/s]\n",
      "[NeMo W 2026-01-07 12:54:51 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:51 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97/4481] Przetwarzanie: EB0_fear_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.11it/s]\n",
      "[NeMo W 2026-01-07 12:54:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98/4481] Przetwarzanie: EB0_fear_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.00it/s]\n",
      "[NeMo W 2026-01-07 12:54:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/4481] Przetwarzanie: EB0_fear_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:54:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/4481] Przetwarzanie: EB0_fear_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:54:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101/4481] Przetwarzanie: EB0_fear_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:54:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102/4481] Przetwarzanie: EB0_fear_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.29it/s]\n",
      "[NeMo W 2026-01-07 12:54:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103/4481] Przetwarzanie: EB0_fear_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.23it/s]\n",
      "[NeMo W 2026-01-07 12:54:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104/4481] Przetwarzanie: EB0_fear_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.14s/it]\n",
      "[NeMo W 2026-01-07 12:54:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:54:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105/4481] Przetwarzanie: EB0_fear_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.13s/it]\n",
      "[NeMo W 2026-01-07 12:55:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106/4481] Przetwarzanie: EB0_fear_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.15it/s]\n",
      "[NeMo W 2026-01-07 12:55:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107/4481] Przetwarzanie: EB0_fear_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.01it/s]\n",
      "[NeMo W 2026-01-07 12:55:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108/4481] Przetwarzanie: EB0_fear_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:55:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109/4481] Przetwarzanie: EB0_fear_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:55:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110/4481] Przetwarzanie: EB0_fear_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:55:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/4481] Przetwarzanie: EB0_fear_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.00it/s]\n",
      "[NeMo W 2026-01-07 12:55:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112/4481] Przetwarzanie: EB0_fear_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.00it/s]\n",
      "[NeMo W 2026-01-07 12:55:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113/4481] Przetwarzanie: EB0_fear_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.29it/s]\n",
      "[NeMo W 2026-01-07 12:55:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114/4481] Przetwarzanie: EB0_fear_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.06s/it]\n",
      "[NeMo W 2026-01-07 12:55:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115/4481] Przetwarzanie: EB0_fear_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:55:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116/4481] Przetwarzanie: EB0_fear_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.05s/it]\n",
      "[NeMo W 2026-01-07 12:55:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117/4481] Przetwarzanie: EB0_fear_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.11it/s]\n",
      "[NeMo W 2026-01-07 12:55:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118/4481] Przetwarzanie: EB0_fear_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:55:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119/4481] Przetwarzanie: EB0_fear_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.14s/it]\n",
      "[NeMo W 2026-01-07 12:55:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120/4481] Przetwarzanie: EB0_fear_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.08it/s]\n",
      "[NeMo W 2026-01-07 12:55:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121/4481] Przetwarzanie: EB0_fear_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.20s/it]\n",
      "[NeMo W 2026-01-07 12:55:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122/4481] Przetwarzanie: EB0_fear_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.05s/it]\n",
      "[NeMo W 2026-01-07 12:55:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123/4481] Przetwarzanie: EB0_fear_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:55:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124/4481] Przetwarzanie: EB0_fear_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.33it/s]\n",
      "[NeMo W 2026-01-07 12:55:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125/4481] Przetwarzanie: EB0_fear_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:55:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126/4481] Przetwarzanie: EB0_fear_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:55:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127/4481] Przetwarzanie: EB0_fear_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.29s/it]\n",
      "[NeMo W 2026-01-07 12:55:23 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:23 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128/4481] Przetwarzanie: EB0_fear_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.22s/it]\n",
      "[NeMo W 2026-01-07 12:55:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129/4481] Przetwarzanie: EB0_fear_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.21s/it]\n",
      "[NeMo W 2026-01-07 12:55:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130/4481] Przetwarzanie: EB0_fear_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.32s/it]\n",
      "[NeMo W 2026-01-07 12:55:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131/4481] Przetwarzanie: EB0_fear_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.68s/it]\n",
      "[NeMo W 2026-01-07 12:55:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132/4481] Przetwarzanie: EB0_fear_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.30s/it]\n",
      "[NeMo W 2026-01-07 12:55:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133/4481] Przetwarzanie: EB0_fear_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.51s/it]\n",
      "[NeMo W 2026-01-07 12:55:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134/4481] Przetwarzanie: EB0_fear_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:55:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135/4481] Przetwarzanie: EB0_fear_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.01it/s]\n",
      "[NeMo W 2026-01-07 12:55:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136/4481] Przetwarzanie: EB0_fear_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.29s/it]\n",
      "[NeMo W 2026-01-07 12:55:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137/4481] Przetwarzanie: EB0_fear_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.71s/it]\n",
      "[NeMo W 2026-01-07 12:55:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/4481] Przetwarzanie: EB0_fear_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.64s/it]\n",
      "[NeMo W 2026-01-07 12:55:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139/4481] Przetwarzanie: EB0_fear_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.48s/it]\n",
      "[NeMo W 2026-01-07 12:55:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140/4481] Przetwarzanie: EB0_fear_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.25s/it]\n",
      "[NeMo W 2026-01-07 12:55:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141/4481] Przetwarzanie: EB0_fear_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.54s/it]\n",
      "[NeMo W 2026-01-07 12:55:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142/4481] Przetwarzanie: EB0_fear_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.31s/it]\n",
      "[NeMo W 2026-01-07 12:55:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143/4481] Przetwarzanie: EB0_fear_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:55:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144/4481] Przetwarzanie: EB0_fear_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.87s/it]\n",
      "[NeMo W 2026-01-07 12:55:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145/4481] Przetwarzanie: EB0_fear_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.71s/it]\n",
      "[NeMo W 2026-01-07 12:55:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/4481] Przetwarzanie: EB0_fear_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:55:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147/4481] Przetwarzanie: EB0_fear_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:55:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148/4481] Przetwarzanie: EB0_fear_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.52s/it]\n",
      "[NeMo W 2026-01-07 12:55:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149/4481] Przetwarzanie: EB0_fear_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.16s/it]\n",
      "[NeMo W 2026-01-07 12:55:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150/4481] Przetwarzanie: EB0_fear_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.38s/it]\n",
      "[NeMo W 2026-01-07 12:55:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151/4481] Przetwarzanie: EB0_fear_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.20s/it]\n",
      "[NeMo W 2026-01-07 12:55:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152/4481] Przetwarzanie: EB0_fear_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.19s/it]\n",
      "[NeMo W 2026-01-07 12:55:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:55:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153/4481] Przetwarzanie: EB0_fear_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.13s/it]\n",
      "[NeMo W 2026-01-07 12:56:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/4481] Przetwarzanie: EB0_fear_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.30s/it]\n",
      "[NeMo W 2026-01-07 12:56:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155/4481] Przetwarzanie: EB0_fear_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.50s/it]\n",
      "[NeMo W 2026-01-07 12:56:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156/4481] Przetwarzanie: EB0_fear_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.30s/it]\n",
      "[NeMo W 2026-01-07 12:56:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157/4481] Przetwarzanie: EB0_fear_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:56:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158/4481] Przetwarzanie: EB0_fear_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.42s/it]\n",
      "[NeMo W 2026-01-07 12:56:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159/4481] Przetwarzanie: EB0_fear_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.26s/it]\n",
      "[NeMo W 2026-01-07 12:56:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160/4481] Przetwarzanie: EB0_fear_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:56:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161/4481] Przetwarzanie: EB0_fear_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.26s/it]\n",
      "[NeMo W 2026-01-07 12:56:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162/4481] Przetwarzanie: EB0_fear_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.52s/it]\n",
      "[NeMo W 2026-01-07 12:56:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163/4481] Przetwarzanie: EB0_fear_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.36s/it]\n",
      "[NeMo W 2026-01-07 12:56:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164/4481] Przetwarzanie: EB0_fear_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:56:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165/4481] Przetwarzanie: EB0_fear_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.45s/it]\n",
      "[NeMo W 2026-01-07 12:56:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166/4481] Przetwarzanie: EB0_fear_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.50s/it]\n",
      "[NeMo W 2026-01-07 12:56:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167/4481] Przetwarzanie: EB0_fear_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.66s/it]\n",
      "[NeMo W 2026-01-07 12:56:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168/4481] Przetwarzanie: EB0_fear_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:56:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169/4481] Przetwarzanie: EB0_fear_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:56:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170/4481] Przetwarzanie: EB0_fear_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.53s/it]\n",
      "[NeMo W 2026-01-07 12:56:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171/4481] Przetwarzanie: EB0_fear_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.42s/it]\n",
      "[NeMo W 2026-01-07 12:56:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172/4481] Przetwarzanie: EB0_fear_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.46s/it]\n",
      "[NeMo W 2026-01-07 12:56:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173/4481] Przetwarzanie: EB0_fear_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.44s/it]\n",
      "[NeMo W 2026-01-07 12:56:28 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:28 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174/4481] Przetwarzanie: EB0_fear_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.78s/it]\n",
      "[NeMo W 2026-01-07 12:56:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/4481] Przetwarzanie: EB0_fear_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.70s/it]\n",
      "[NeMo W 2026-01-07 12:56:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176/4481] Przetwarzanie: EB0_fear_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.60s/it]\n",
      "[NeMo W 2026-01-07 12:56:33 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:33 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[177/4481] Przetwarzanie: EB0_fear_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.72s/it]\n",
      "[NeMo W 2026-01-07 12:56:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178/4481] Przetwarzanie: EB0_fear_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.63s/it]\n",
      "[NeMo W 2026-01-07 12:56:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179/4481] Przetwarzanie: EB0_fear_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:56:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180/4481] Przetwarzanie: EB0_fear_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.61s/it]\n",
      "[NeMo W 2026-01-07 12:56:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181/4481] Przetwarzanie: EB0_happiness_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.02it/s]\n",
      "[NeMo W 2026-01-07 12:56:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/4481] Przetwarzanie: EB0_happiness_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.19s/it]\n",
      "[NeMo W 2026-01-07 12:56:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183/4481] Przetwarzanie: EB0_happiness_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:56:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184/4481] Przetwarzanie: EB0_happiness_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.10s/it]\n",
      "[NeMo W 2026-01-07 12:56:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[185/4481] Przetwarzanie: EB0_happiness_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.09it/s]\n",
      "[NeMo W 2026-01-07 12:56:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186/4481] Przetwarzanie: EB0_happiness_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.07it/s]\n",
      "[NeMo W 2026-01-07 12:56:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187/4481] Przetwarzanie: EB0_happiness_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.03it/s]\n",
      "[NeMo W 2026-01-07 12:56:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/4481] Przetwarzanie: EB0_happiness_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.06s/it]\n",
      "[NeMo W 2026-01-07 12:56:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189/4481] Przetwarzanie: EB0_happiness_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.20s/it]\n",
      "[NeMo W 2026-01-07 12:56:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190/4481] Przetwarzanie: EB0_happiness_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.17s/it]\n",
      "[NeMo W 2026-01-07 12:56:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191/4481] Przetwarzanie: EB0_happiness_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.29s/it]\n",
      "[NeMo W 2026-01-07 12:56:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192/4481] Przetwarzanie: EB0_happiness_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.07it/s]\n",
      "[NeMo W 2026-01-07 12:56:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193/4481] Przetwarzanie: EB0_happiness_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.24s/it]\n",
      "[NeMo W 2026-01-07 12:56:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194/4481] Przetwarzanie: EB0_happiness_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.30s/it]\n",
      "[NeMo W 2026-01-07 12:56:55 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:55 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195/4481] Przetwarzanie: EB0_happiness_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.37s/it]\n",
      "[NeMo W 2026-01-07 12:56:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196/4481] Przetwarzanie: EB0_happiness_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.07s/it]\n",
      "[NeMo W 2026-01-07 12:56:58 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:58 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197/4481] Przetwarzanie: EB0_happiness_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:56:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:56:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198/4481] Przetwarzanie: EB0_happiness_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.17s/it]\n",
      "[NeMo W 2026-01-07 12:57:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199/4481] Przetwarzanie: EB0_happiness_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.16s/it]\n",
      "[NeMo W 2026-01-07 12:57:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/4481] Przetwarzanie: EB0_happiness_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.05s/it]\n",
      "[NeMo W 2026-01-07 12:57:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201/4481] Przetwarzanie: EB0_happiness_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:57:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202/4481] Przetwarzanie: EB0_happiness_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.24s/it]\n",
      "[NeMo W 2026-01-07 12:57:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203/4481] Przetwarzanie: EB0_happiness_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.23it/s]\n",
      "[NeMo W 2026-01-07 12:57:06 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:06 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204/4481] Przetwarzanie: EB0_happiness_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.12s/it]\n",
      "[NeMo W 2026-01-07 12:57:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205/4481] Przetwarzanie: EB0_happiness_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:57:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206/4481] Przetwarzanie: EB0_happiness_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.10s/it]\n",
      "[NeMo W 2026-01-07 12:57:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207/4481] Przetwarzanie: EB0_happiness_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.07it/s]\n",
      "[NeMo W 2026-01-07 12:57:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208/4481] Przetwarzanie: EB0_happiness_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:57:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209/4481] Przetwarzanie: EB0_happiness_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.21s/it]\n",
      "[NeMo W 2026-01-07 12:57:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210/4481] Przetwarzanie: EB0_happiness_36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.06it/s]\n",
      "[NeMo W 2026-01-07 12:57:13 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:13 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211/4481] Przetwarzanie: EB0_happiness_37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.26s/it]\n",
      "[NeMo W 2026-01-07 12:57:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212/4481] Przetwarzanie: EB0_happiness_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.06s/it]\n",
      "[NeMo W 2026-01-07 12:57:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213/4481] Przetwarzanie: EB0_happiness_39.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.07s/it]\n",
      "[NeMo W 2026-01-07 12:57:17 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:17 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214/4481] Przetwarzanie: EB0_happiness_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.17it/s]\n",
      "[NeMo W 2026-01-07 12:57:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[215/4481] Przetwarzanie: EB0_happiness_40.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:57:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216/4481] Przetwarzanie: EB0_happiness_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:57:20 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:20 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217/4481] Przetwarzanie: EB0_happiness_42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.31s/it]\n",
      "[NeMo W 2026-01-07 12:57:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218/4481] Przetwarzanie: EB0_happiness_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.21s/it]\n",
      "[NeMo W 2026-01-07 12:57:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219/4481] Przetwarzanie: EB0_happiness_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.15s/it]\n",
      "[NeMo W 2026-01-07 12:57:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220/4481] Przetwarzanie: EB0_happiness_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.23s/it]\n",
      "[NeMo W 2026-01-07 12:57:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221/4481] Przetwarzanie: EB0_happiness_46.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.51s/it]\n",
      "[NeMo W 2026-01-07 12:57:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222/4481] Przetwarzanie: EB0_happiness_47.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:57:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223/4481] Przetwarzanie: EB0_happiness_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.37s/it]\n",
      "[NeMo W 2026-01-07 12:57:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224/4481] Przetwarzanie: EB0_happiness_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.26s/it]\n",
      "[NeMo W 2026-01-07 12:57:30 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:30 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225/4481] Przetwarzanie: EB0_happiness_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.13it/s]\n",
      "[NeMo W 2026-01-07 12:57:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226/4481] Przetwarzanie: EB0_happiness_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.19s/it]\n",
      "[NeMo W 2026-01-07 12:57:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227/4481] Przetwarzanie: EB0_happiness_51.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:57:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228/4481] Przetwarzanie: EB0_happiness_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.38s/it]\n",
      "[NeMo W 2026-01-07 12:57:35 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:35 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229/4481] Przetwarzanie: EB0_happiness_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.08s/it]\n",
      "[NeMo W 2026-01-07 12:57:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230/4481] Przetwarzanie: EB0_happiness_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.02it/s]\n",
      "[NeMo W 2026-01-07 12:57:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231/4481] Przetwarzanie: EB0_happiness_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.12s/it]\n",
      "[NeMo W 2026-01-07 12:57:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232/4481] Przetwarzanie: EB0_happiness_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.07s/it]\n",
      "[NeMo W 2026-01-07 12:57:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233/4481] Przetwarzanie: EB0_happiness_57.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.18s/it]\n",
      "[NeMo W 2026-01-07 12:57:41 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:41 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234/4481] Przetwarzanie: EB0_happiness_58.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.47s/it]\n",
      "[NeMo W 2026-01-07 12:57:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235/4481] Przetwarzanie: EB0_happiness_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:57:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236/4481] Przetwarzanie: EB0_happiness_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.21s/it]\n",
      "[NeMo W 2026-01-07 12:57:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237/4481] Przetwarzanie: EB0_happiness_60.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.38s/it]\n",
      "[NeMo W 2026-01-07 12:57:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238/4481] Przetwarzanie: EB0_happiness_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.22s/it]\n",
      "[NeMo W 2026-01-07 12:57:48 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:48 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239/4481] Przetwarzanie: EB0_happiness_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.01s/it]\n",
      "[NeMo W 2026-01-07 12:57:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240/4481] Przetwarzanie: EB0_happiness_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.28s/it]\n",
      "[NeMo W 2026-01-07 12:57:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[241/4481] Przetwarzanie: EB0_happiness_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.37s/it]\n",
      "[NeMo W 2026-01-07 12:57:52 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:52 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242/4481] Przetwarzanie: EB0_happiness_65.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.45s/it]\n",
      "[NeMo W 2026-01-07 12:57:53 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:53 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243/4481] Przetwarzanie: EB0_happiness_66.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.28s/it]\n",
      "[NeMo W 2026-01-07 12:57:54 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:54 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244/4481] Przetwarzanie: EB0_happiness_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.22s/it]\n",
      "[NeMo W 2026-01-07 12:57:56 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:56 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245/4481] Przetwarzanie: EB0_happiness_68.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.62s/it]\n",
      "[NeMo W 2026-01-07 12:57:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246/4481] Przetwarzanie: EB0_happiness_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.33s/it]\n",
      "[NeMo W 2026-01-07 12:57:59 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:57:59 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247/4481] Przetwarzanie: EB0_happiness_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:58:00 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:00 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248/4481] Przetwarzanie: EB0_happiness_70.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.32s/it]\n",
      "[NeMo W 2026-01-07 12:58:01 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:01 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249/4481] Przetwarzanie: EB0_happiness_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.30s/it]\n",
      "[NeMo W 2026-01-07 12:58:02 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:02 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250/4481] Przetwarzanie: EB0_happiness_72.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.21s/it]\n",
      "[NeMo W 2026-01-07 12:58:04 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:04 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251/4481] Przetwarzanie: EB0_happiness_73.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.31s/it]\n",
      "[NeMo W 2026-01-07 12:58:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252/4481] Przetwarzanie: EB0_happiness_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.44s/it]\n",
      "[NeMo W 2026-01-07 12:58:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253/4481] Przetwarzanie: EB0_happiness_75.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.27s/it]\n",
      "[NeMo W 2026-01-07 12:58:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254/4481] Przetwarzanie: EB0_happiness_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.50s/it]\n",
      "[NeMo W 2026-01-07 12:58:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255/4481] Przetwarzanie: EB0_happiness_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.31s/it]\n",
      "[NeMo W 2026-01-07 12:58:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256/4481] Przetwarzanie: EB0_happiness_78.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:58:12 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:12 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257/4481] Przetwarzanie: EB0_happiness_79.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.63s/it]\n",
      "[NeMo W 2026-01-07 12:58:14 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:14 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258/4481] Przetwarzanie: EB0_happiness_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.09it/s]\n",
      "[NeMo W 2026-01-07 12:58:15 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:15 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259/4481] Przetwarzanie: EB0_happiness_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.37s/it]\n",
      "[NeMo W 2026-01-07 12:58:16 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:16 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260/4481] Przetwarzanie: EB0_happiness_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.53s/it]\n",
      "[NeMo W 2026-01-07 12:58:18 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:18 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261/4481] Przetwarzanie: EB0_happiness_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.47s/it]\n",
      "[NeMo W 2026-01-07 12:58:19 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:19 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262/4481] Przetwarzanie: EB0_happiness_83.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.43s/it]\n",
      "[NeMo W 2026-01-07 12:58:21 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:21 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263/4481] Przetwarzanie: EB0_happiness_84.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.57s/it]\n",
      "[NeMo W 2026-01-07 12:58:22 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:22 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264/4481] Przetwarzanie: EB0_happiness_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.77s/it]\n",
      "[NeMo W 2026-01-07 12:58:24 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:24 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[265/4481] Przetwarzanie: EB0_happiness_86.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.63s/it]\n",
      "[NeMo W 2026-01-07 12:58:26 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:26 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266/4481] Przetwarzanie: EB0_happiness_87.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.41s/it]\n",
      "[NeMo W 2026-01-07 12:58:27 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:27 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[267/4481] Przetwarzanie: EB0_happiness_88.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.69s/it]\n",
      "[NeMo W 2026-01-07 12:58:29 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:29 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[268/4481] Przetwarzanie: EB0_happiness_89.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.65s/it]\n",
      "[NeMo W 2026-01-07 12:58:31 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:31 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269/4481] Przetwarzanie: EB0_happiness_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:58:32 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:32 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270/4481] Przetwarzanie: EB0_happiness_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.82s/it]\n",
      "[NeMo W 2026-01-07 12:58:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[271/4481] Przetwarzanie: EB0_neutral_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.19it/s]\n",
      "[NeMo W 2026-01-07 12:58:34 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:34 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[272/4481] Przetwarzanie: EB0_neutral_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.06s/it]\n",
      "[NeMo W 2026-01-07 12:58:36 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:36 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273/4481] Przetwarzanie: EB0_neutral_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.11it/s]\n",
      "[NeMo W 2026-01-07 12:58:37 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:37 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274/4481] Przetwarzanie: EB0_neutral_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.02s/it]\n",
      "[NeMo W 2026-01-07 12:58:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275/4481] Przetwarzanie: EB0_neutral_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.28it/s]\n",
      "[NeMo W 2026-01-07 12:58:38 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:38 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[276/4481] Przetwarzanie: EB0_neutral_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.21it/s]\n",
      "[NeMo W 2026-01-07 12:58:39 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:39 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[277/4481] Przetwarzanie: EB0_neutral_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.04it/s]\n",
      "[NeMo W 2026-01-07 12:58:40 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:40 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[278/4481] Przetwarzanie: EB0_neutral_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.22s/it]\n",
      "[NeMo W 2026-01-07 12:58:42 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:42 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[279/4481] Przetwarzanie: EB0_neutral_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.24s/it]\n",
      "[NeMo W 2026-01-07 12:58:43 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:43 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280/4481] Przetwarzanie: EB0_neutral_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.12s/it]\n",
      "[NeMo W 2026-01-07 12:58:44 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:44 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281/4481] Przetwarzanie: EB0_neutral_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.35s/it]\n",
      "[NeMo W 2026-01-07 12:58:45 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:45 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282/4481] Przetwarzanie: EB0_neutral_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:00,  1.05it/s]\n",
      "[NeMo W 2026-01-07 12:58:46 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:46 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[283/4481] Przetwarzanie: EB0_neutral_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.04s/it]\n",
      "[NeMo W 2026-01-07 12:58:47 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:47 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284/4481] Przetwarzanie: EB0_neutral_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.39s/it]\n",
      "[NeMo W 2026-01-07 12:58:49 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:49 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285/4481] Przetwarzanie: EB0_neutral_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.54s/it]\n",
      "[NeMo W 2026-01-07 12:58:50 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: enable_chunking,trim_silence\n",
      "[NeMo W 2026-01-07 12:58:50 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286/4481] Przetwarzanie: EB0_neutral_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Folder z plikami audio\n",
    "audio_folder = Path(path)\n",
    "\n",
    "# Lista do przechowywania wyników\n",
    "results = []\n",
    "\n",
    "# Iteracja przez wszystkie pliki WAV\n",
    "wav_files = sorted(audio_folder.glob(\"*.wav\"))\n",
    "print(f\"Znaleziono {len(wav_files)} plików WAV\")\n",
    "\n",
    "for i, wav_file in enumerate(wav_files, 1):\n",
    "    # Parsowanie nazwy pliku: speaker_emotion_phraseNumber.wav\n",
    "    filename = wav_file.stem  # nazwa bez rozszerzenia\n",
    "    \n",
    "    # Rozdzielenie na części (speaker, emotion, phraseNumber)\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        speaker = parts[0]\n",
    "        emotion = parts[1]\n",
    "        phrase_number = parts[2]\n",
    "        \n",
    "        # Transkrypcja audio\n",
    "        print(f\"[{i}/{len(wav_files)}] Przetwarzanie: {wav_file.name}\")\n",
    "        try:\n",
    "            output = asr_ast_model.transcribe(\n",
    "                [str(wav_file)], \n",
    "                source_lang='pl', \n",
    "                target_lang='pl'\n",
    "            )\n",
    "            transcript = output[0].text\n",
    "            \n",
    "            # Dodanie do wyników\n",
    "            results.append({\n",
    "                'phraseNumber': phrase_number,\n",
    "                'speaker': speaker,\n",
    "                'emotion': emotion,\n",
    "                'transcript': transcript\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  Błąd przy przetwarzaniu {wav_file.name}: {e}\")\n",
    "            results.append({\n",
    "                'phraseNumber': phrase_number,\n",
    "                'speaker': speaker,\n",
    "                'emotion': emotion,\n",
    "                'transcript': f\"ERROR: {e}\"\n",
    "            })\n",
    "    else:\n",
    "        print(f\"  Pominięto plik o nieoczekiwanej nazwie: {wav_file.name}\")\n",
    "\n",
    "# Utworzenie DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"\\nUtworzono DataFrame z {len(df)} wierszami\")\n",
    "print(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
